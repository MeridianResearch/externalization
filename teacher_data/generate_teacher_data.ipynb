{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b72ac18-1889-451b-8335-22ac81882390",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import gzip\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from datetime import datetime\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from shared_utils.data import CSVPromptDataset\n",
    "from shared_utils.load import get_tokenizer, configs_from_yaml\n",
    "from shared_utils.generate import generate_text\n",
    "\n",
    "from early_exit.util import get_model\n",
    "\n",
    "from early_exit.patching import replace_attention_layers, set_transformer_early_exit_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "254bcc66-c33b-49f2-bbc1-9505e3a3781a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_exit_samples = 4\n",
    "device = \"cuda\"\n",
    "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "model_config_path = \"../config_deepseek.yaml\"\n",
    "dataset_path = \"../results_and_data/early_exit_sft_dataset/test/data.csv\"\n",
    "prompt_config_path = \"../results_and_data/early_exit_sft_dataset/test/prompt_config.json\"\n",
    "batch_size = 1\n",
    "chunk_size = 100 #for saving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f6dc04e-5a54-4c68-b480-6d05fe5859c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_dir = \"teacher_generated_data\"\n",
    "output_dir = \"/workspace/data/teacher_generated_data_gzip\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1023f2ed-3622-4b0c-91d6-9beed3da3195",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer(model_name)\n",
    "config = configs_from_yaml(model_config_path, tokenizer.eos_token_id)\n",
    "model = get_model(model_name, config['model'], device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14744edc-b011-4cc4-8bb8-19d5af046092",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CSVPromptDataset(dataset_path, prompt_config_path)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, collate_fn=dataset.collate_fn, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe64f03e-5bce-45a6-9fca-826ba9b7cb60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replacing layer model.layers.0\n",
      "replacing layer model.layers.1\n",
      "replacing layer model.layers.2\n",
      "replacing layer model.layers.3\n",
      "replacing layer model.layers.4\n",
      "replacing layer model.layers.5\n",
      "replacing layer model.layers.6\n",
      "replacing layer model.layers.7\n",
      "replacing layer model.layers.8\n",
      "replacing layer model.layers.9\n",
      "replacing layer model.layers.10\n",
      "replacing layer model.layers.11\n",
      "replacing layer model.layers.12\n",
      "replacing layer model.layers.13\n",
      "replacing layer model.layers.14\n",
      "replacing layer model.layers.15\n",
      "replacing layer model.layers.16\n",
      "replacing layer model.layers.17\n",
      "replacing layer model.layers.18\n",
      "replacing layer model.layers.19\n",
      "replacing layer model.layers.20\n",
      "replacing layer model.layers.21\n",
      "replacing layer model.layers.22\n",
      "replacing layer model.layers.23\n",
      "replacing layer model.layers.24\n",
      "replacing layer model.layers.25\n",
      "replacing layer model.layers.26\n",
      "replacing layer model.layers.27\n",
      "address this hack!\n",
      "trainable params: 2,179,072 || all params: 1,779,310,108 || trainable%: 0.1225\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): DynamicallyTypedModelWithReadout(\n",
       "      (model): Qwen2Model(\n",
       "        (embed_tokens): Embedding(151936, 1536)\n",
       "        (layers): ModuleList(\n",
       "          (0-27): 28 x DynamicallyTypedLayerWithExit(\n",
       "            (self_attn): Qwen2Attention(\n",
       "              (q_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (early_exiter): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (early_exiter): Linear(in_features=1536, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (early_exiter): Linear(in_features=8, out_features=1536, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1536, out_features=256, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (early_exiter): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (early_exiter): Linear(in_features=1536, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (early_exiter): Linear(in_features=8, out_features=256, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1536, out_features=256, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (early_exiter): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (early_exiter): Linear(in_features=1536, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (early_exiter): Linear(in_features=8, out_features=256, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (early_exiter): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (early_exiter): Linear(in_features=1536, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (early_exiter): Linear(in_features=8, out_features=1536, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (mlp): Qwen2MLP(\n",
       "              (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "              (up_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "              (down_proj): Linear(in_features=8960, out_features=1536, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "            (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "            (early_exit_decision_weights): Linear(in_features=1536, out_features=1, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (norm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "        (rotary_emb): Qwen2RotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=1536, out_features=151936, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = replace_attention_layers(model, config['lora'], device)\n",
    "model.eval() #not training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a41f58a8-68f9-42a3-8dab-c4182be27255",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_teacher_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f287e822-0f98-4ee6-b939-ec20d4ab3718",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_chunk_data = []\n",
    "chunk_idx = 0\n",
    "total_samples_processed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6325042e-624d-484b-9d90-167c8724bdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {\n",
    "    'model_name': model_name,\n",
    "    'dataset_path': dataset_path,\n",
    "    'prompt_config_path': prompt_config_path,\n",
    "    'config': config,\n",
    "    'chunk_size': chunk_size,\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'system_prompt': dataset.system_prompt,\n",
    "    'prefiller': dataset.prefiller\n",
    "}\n",
    "metadata_path = os.path.join(output_dir, \"metadata.pkl.gz\")\n",
    "with gzip.open(metadata_path, 'wb', compresslevel=6) as f:\n",
    "    pickle.dump(metadata, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68c0abd5-65c2-4e4a-bd9a-26d047eddef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_chunk(chunk_data, chunk_index, output_directory):\n",
    "    \"\"\"Save a chunk of data to disk with gzip compression\"\"\"\n",
    "    chunk_filename = os.path.join(output_directory, f\"chunk_{chunk_index:04d}.pkl.gz\")\n",
    "\n",
    "    # Convert all float32 tensors to float16 before saving\n",
    "    compressed_data = []\n",
    "    for sample in chunk_data:\n",
    "        compressed_sample = {}\n",
    "        for key, value in sample.items():\n",
    "            if isinstance(value, torch.Tensor) and value.dtype == torch.float32:\n",
    "                compressed_sample[key] = value.half()  # Convert to float16\n",
    "            else:\n",
    "                compressed_sample[key] = value\n",
    "        compressed_data.append(compressed_sample)\n",
    "    \n",
    "    with gzip.open(chunk_filename, 'wb', compresslevel=9) as f: #play with compresslevel, 6 is moderate\n",
    "        pickle.dump({\n",
    "            'chunk_idx': chunk_index,\n",
    "            'data': chunk_data,\n",
    "            'num_samples': len(chunk_data)\n",
    "        }, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    file_size_mb = os.path.getsize(chunk_filename) / (1024 * 1024)\n",
    "    print(f\"Saved chunk {chunk_index} with {len(chunk_data)} samples\")\n",
    "    print(f\"  File: {chunk_filename}\")\n",
    "    print(f\"  Size: {file_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efa77b4-1f18-493a-b955-945881f565fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1/13309 (Total samples: 0)\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, prompt_batch in enumerate(dataloader):\n",
    "    # Remove the testing limit if you want to process all data\n",
    "    #if total_samples_processed >= 30:\n",
    "    #    break\n",
    "    \n",
    "    if total_samples_processed % 50 == 0:\n",
    "        print(f\"Processing batch {total_samples_processed + 1}/{len(dataloader)} (Total samples: {total_samples_processed})\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Generate SFT targets\n",
    "        set_transformer_early_exit_mode(model, 'sft_teacher')\n",
    "        sft_teacher_response, (sft_teacher_generated_tokens, sft_teacher_final_layer_logprobs, gathered_early_exit_hidden_states) = \\\n",
    "            generate_text(\n",
    "                model=model, \n",
    "                prompt=prompt_batch.full_user_prompt, \n",
    "                system_prompt=dataset.system_prompt, \n",
    "                prefiller=dataset.prefiller, \n",
    "                tokenizer=tokenizer, \n",
    "                generation_config=config['generation'], \n",
    "                device=device\n",
    "            )\n",
    "        \n",
    "        # Compute early exit probabilities\n",
    "        early_output_log_probs = model.early_exit_hidden_state_readout(gathered_early_exit_hidden_states)\n",
    "        \n",
    "        # KL divergence calculations\n",
    "        teacher_expanded = sft_teacher_final_layer_logprobs.unsqueeze(1).exp()\n",
    "        early_output_probs = early_output_log_probs.exp()\n",
    "        eps = 1e-16\n",
    "        kl_div1 = - (teacher_expanded * (early_output_probs + eps).log()).sum(-1)\n",
    "        kl_div2 = (teacher_expanded * ((teacher_expanded + eps) / (early_output_probs + eps)).log()).sum(-1)\n",
    "        \n",
    "        # Store data for this batch\n",
    "        batch_data = {\n",
    "            'batch_idx': batch_idx, #in case shuffled, but don't think matters really\n",
    "            'prompt_idx': prompt_batch.idx[0] if hasattr(prompt_batch, 'idx') else batch_idx,\n",
    "            'full_user_prompt': prompt_batch.full_user_prompt,\n",
    "            'sft_teacher_response': sft_teacher_response, #full generated response text\n",
    "            'sft_teacher_generated_tokens': sft_teacher_generated_tokens.cpu(), #token IDs [batch, full_length]\n",
    "            'sft_teacher_final_layer_logprobs': sft_teacher_final_layer_logprobs.cpu(), #final layer logprobs [batch, gen_len, vocab]\n",
    "            'kl_div1_per_layer': kl_div1.cpu(), #cross-entropy KL divergence per layer to final [batch, num_layers, gen_len]\n",
    "            'kl_div2_per_layer': kl_div2.cpu(), #standard KL divergence per layer to final [batch, num_layers, gen_len]\n",
    "            'exitable_layer_idxs': model.exitable_layer_idxs.cpu(),\n",
    "        }\n",
    "        \n",
    "        current_chunk_data.append(batch_data)\n",
    "        total_samples_processed += 1\n",
    "        \n",
    "        # Save chunk if we've reached chunk_size\n",
    "        if len(current_chunk_data) >= chunk_size:\n",
    "            save_chunk(current_chunk_data, chunk_idx, output_dir)\n",
    "            current_chunk_data = []\n",
    "            chunk_idx += 1\n",
    "        \n",
    "        # Clear GPU memory\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "024f4f59-489e-4ee8-8129-f7fde70e9145",
   "metadata": {},
   "outputs": [],
   "source": [
    "if current_chunk_data:\n",
    "    print(f\"\\nSaving final chunk with {len(current_chunk_data)} samples...\")\n",
    "    save_chunk(current_chunk_data, chunk_idx, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64cd5bff-5da3-417b-8bd4-5be71f364860",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_teacher_data_chunks(output_dir, merged_filename=\"merged_teacher_data.pkl.gz\"):\n",
    "    \"\"\"\n",
    "    Merge all chunk files into a single file\n",
    "    \"\"\"\n",
    "    print(f\"Merging chunks from {output_dir}...\")\n",
    "    \n",
    "    #load metadata - now gzipped\n",
    "    metadata_path = os.path.join(output_dir, \"metadata.pkl.gz\")\n",
    "    with gzip.open(metadata_path, 'rb') as f:\n",
    "        metadata = pickle.load(f)\n",
    "    \n",
    "    #find all chunk files - now with .gz extension\n",
    "    chunk_files = sorted([f for f in os.listdir(output_dir) if f.startswith(\"chunk_\") and f.endswith(\".pkl.gz\")])\n",
    "    print(f\"Found {len(chunk_files)} chunk files to merge\")\n",
    "    \n",
    "    all_data = []\n",
    "    for chunk_file in chunk_files:\n",
    "        chunk_path = os.path.join(output_dir, chunk_file)\n",
    "        print(f\"  Loading {chunk_file}...\")\n",
    "        with gzip.open(chunk_path, 'rb') as f:\n",
    "            chunk_data = pickle.load(f)\n",
    "            all_data.extend(chunk_data['data'])\n",
    "            print(f\"    Loaded {len(chunk_data['data'])} samples\")\n",
    "    \n",
    "    #save merged data with gzip\n",
    "    merged_path = os.path.join(output_dir, merged_filename)\n",
    "    print(f\"\\nSaving merged data to {merged_path}...\")\n",
    "    with gzip.open(merged_path, 'wb', compresslevel=6) as f:\n",
    "        pickle.dump({\n",
    "            'teacher_data': all_data,\n",
    "            'metadata': {\n",
    "                **metadata,\n",
    "                'num_samples': len(all_data),\n",
    "                'num_chunks_merged': len(chunk_files)\n",
    "            }\n",
    "        }, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    file_size_mb = os.path.getsize(merged_path) / (1024 * 1024)\n",
    "    print(f\"Total samples: {len(all_data)}\")\n",
    "    print(f\"Merged file size: {file_size_mb:.2f} MB\")\n",
    "    print(f\"Saved to: {merged_path}\")\n",
    "    \n",
    "    #return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92698a3c-4a02-4398-be52-075d77cac62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging chunks from /workspace/data/teacher_generated_data_gzip_test...\n",
      "Found 3 chunk files to merge\n",
      "  Loading chunk_0000.pkl.gz...\n",
      "    Loaded 10 samples\n",
      "  Loading chunk_0001.pkl.gz...\n",
      "    Loaded 10 samples\n",
      "  Loading chunk_0002.pkl.gz...\n",
      "    Loaded 10 samples\n",
      "\n",
      "Saving merged data to /workspace/data/teacher_generated_data_gzip_test/merged_teacher_data.pkl.gz...\n",
      "Total samples: 30\n",
      "Merged file size: 4672.37 MB\n",
      "Saved to: /workspace/data/teacher_generated_data_gzip_test/merged_teacher_data.pkl.gz\n"
     ]
    }
   ],
   "source": [
    "merge_teacher_data_chunks(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e1e274-010b-4fa4-9b4b-3a5f1f283c2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723a1cb3-a2f0-4a3a-9b46-7ea8b87cac5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
