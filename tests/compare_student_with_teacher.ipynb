{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57efb0a1-c255-44b2-96a7-33138cdb8b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from shared_utils.data import CSVPromptDataset\n",
    "from early_exit.util import get_model\n",
    "from shared_utils.load import get_tokenizer, configs_from_yaml\n",
    "from shared_utils.generate import generate_text\n",
    "\n",
    "from early_exit.patching import replace_attention_layers, set_transformer_early_exit_mode\n",
    "\n",
    "import wandb\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbd7a889-ee1c-4539-ae00-0aa158b1c039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD IN EXPERIMENT ARGS\n",
    "# num_epoch = 1                     # args.num_epoch\n",
    "num_exit_samples = 1                  # args.num_exit_samples\n",
    "device = \"cuda\"                    # args.device\n",
    "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"                    # args.model_name\n",
    "model_config_path = \"../config_deepseek.yaml\"                     # args.model_config_path\n",
    "dataset_path = \"../results_and_data/early_exit_sft_dataset/test/data.csv\"                  # args.dataset_path\n",
    "prompt_config_path = \"../results_and_data/early_exit_sft_dataset/test/prompt_config.json\"                    # args.prompt_config_path\n",
    "batch_size = 1                    # args.batch_size -- might want to sort out batching, but increasing num_exit_samples might be better + less effort\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfaa3e89-53e3-4d03-9d65-c5030157cf9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "address this hack!\n",
      "g++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
      "Copyright (C) 2021 Free Software Foundation, Inc.\n",
      "This is free software; see the source for copying conditions.  There is NO\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
      "\n",
      "trainable params: 2,179,072 || all params: 1,779,276,294 || trainable%: 0.1225\n"
     ]
    }
   ],
   "source": [
    "# LOAD IN THE MODEL AND TOKENIZER\n",
    "tokenizer = get_tokenizer(model_name)\n",
    "config = configs_from_yaml(model_config_path, tokenizer.eos_token_id)\n",
    "model = get_model(model_name, config['model'], device)\n",
    "\n",
    "# ENABLE EARLY EXITING\n",
    "model = replace_attention_layers(model, config['lora'], device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa962a18-8480-4531-8e4d-b0332b259206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transform_conversations currently only for Deepseek models!\n",
      "full_tokenize currently only for Deepseek models!\n",
      "prompt tokens shape: torch.Size([1, 20])\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Explain the concept of recursion in programming.\"\n",
    "system_prompt = \"You are a helpful programming tutor.\"\n",
    "prefiller = \"\"\n",
    "\n",
    "config['generation']['max_new_tokens'] = 20\n",
    "set_transformer_early_exit_mode(model, 'sft_teacher')\n",
    "\n",
    "with torch.no_grad():\n",
    "    sft_teacher_response, (sft_teacher_generated_tokens, \n",
    "                          sft_teacher_final_layer_logprobs, \n",
    "                          gathered_early_exit_hidden_states) = generate_text(\n",
    "        model=model,\n",
    "        prompt=prompt,\n",
    "        system_prompt=system_prompt,\n",
    "        prefiller=prefiller,\n",
    "        tokenizer=tokenizer,\n",
    "        generation_config=config['generation'],\n",
    "        device=device\n",
    "    )\n",
    "    sft_teacher_generated_tokens = sft_teacher_generated_tokens[:, :-1]\n",
    "    early_output_log_probs = model.early_exit_hidden_state_readout(gathered_early_exit_hidden_states)\n",
    "    \n",
    "    early_exit_probs = model.early_exit_target_probs(\n",
    "        early_output_log_probs=early_output_log_probs,\n",
    "        teacher_final_layer_log_probs=sft_teacher_final_layer_logprobs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b4157f27-525c-413e-a3c1-1ff5ac549a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    batch, gen_len, elayers = early_exit_probs.shape \n",
    "    sampled_early_exit_layer_idxs_early_with_sample_dim = torch.distributions.Categorical(probs = early_exit_probs).sample((num_exit_samples,))     # [samples, batch, generation length] \n",
    "    sampled_early_exit_layer_idxs_early = sampled_early_exit_layer_idxs_early_with_sample_dim.reshape(batch * num_exit_samples, gen_len)            # [batch * samples, generation length]\n",
    "    sampled_early_exit_layer_idxs = model.exitable_layer_idxs[sampled_early_exit_layer_idxs_early.cpu()]                                            # [batch * samples, generation length]\n",
    "       \n",
    "    full_len = sft_teacher_generated_tokens.shape[1]\n",
    "    repeated_sft_teacher_generated_tokens = sft_teacher_generated_tokens.expand(num_exit_samples * batch, full_len)   \n",
    "    set_transformer_early_exit_mode(model, 'sft_student')\n",
    "    \n",
    "    # Create prescribed exit layer idxs filled with torch.inf (always exit on last layer)\n",
    "    batch_samples, seq_len = repeated_sft_teacher_generated_tokens.shape\n",
    "    sft_student_output_scores, collected_exit_logits = model(repeated_sft_teacher_generated_tokens,\\\n",
    "                                                             prescribed_exit_layer_idxs=sampled_early_exit_layer_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "64eacca6-fa54-402f-8e3f-91402e5c70bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sft_student_output = sft_student_output_scores.logits.squeeze()[20:]\n",
    "teacher_final_output = sft_teacher_final_layer_logprobs\n",
    "\n",
    "student_probs = F.softmax(sft_student_output, dim=-1)\n",
    "teacher_final_probs = F.softmax(teacher_final_output.squeeze(), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c80b86e5-c38b-4b79-b040-377cdb6ba080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.4202e-08, -3.5804e-08, -4.5235e-09, -2.0964e-08,  2.4629e-05,\n",
       "        -6.3737e-09, -2.6751e-08,  2.8074e-09,  1.2900e-03,  8.6235e-08,\n",
       "         1.0610e-06, -1.1635e-07,  1.4002e-06,  2.8356e-06,  1.0371e-06,\n",
       "         1.0161e-06,  1.0043e-06,  6.6714e+00,  9.5087e-04], device='cuda:0')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps = 1e-16\n",
    "token_logits_kl_div = (student_probs * ((student_probs + eps) / (teacher_final_probs + eps)).log()).sum(-1)   # [batch * samples, gen len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0ad47ac0-8d1d-42d8-940b-ccdb216052c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student Token</th>\n",
       "      <th>Student Prob</th>\n",
       "      <th>Teacher Token</th>\n",
       "      <th>Teacher Prob</th>\n",
       "      <th>Prescribed exit layer</th>\n",
       "      <th>KL divergence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>,</td>\n",
       "      <td>1.00</td>\n",
       "      <td>,</td>\n",
       "      <td>1.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>so</td>\n",
       "      <td>0.78</td>\n",
       "      <td>so</td>\n",
       "      <td>0.78</td>\n",
       "      <td>inf</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I</td>\n",
       "      <td>0.93</td>\n",
       "      <td>I</td>\n",
       "      <td>0.93</td>\n",
       "      <td>inf</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>need</td>\n",
       "      <td>0.65</td>\n",
       "      <td>need</td>\n",
       "      <td>0.65</td>\n",
       "      <td>inf</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to</td>\n",
       "      <td>1.00</td>\n",
       "      <td>to</td>\n",
       "      <td>1.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>explain</td>\n",
       "      <td>0.75</td>\n",
       "      <td>explain</td>\n",
       "      <td>0.75</td>\n",
       "      <td>inf</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>recursion</td>\n",
       "      <td>0.50</td>\n",
       "      <td>recursion</td>\n",
       "      <td>0.50</td>\n",
       "      <td>inf</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>in</td>\n",
       "      <td>0.98</td>\n",
       "      <td>in</td>\n",
       "      <td>0.98</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>programming</td>\n",
       "      <td>1.00</td>\n",
       "      <td>programming</td>\n",
       "      <td>1.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>.</td>\n",
       "      <td>0.86</td>\n",
       "      <td>.</td>\n",
       "      <td>0.86</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Hmm</td>\n",
       "      <td>0.74</td>\n",
       "      <td>Hmm</td>\n",
       "      <td>0.74</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>,</td>\n",
       "      <td>0.99</td>\n",
       "      <td>,</td>\n",
       "      <td>0.99</td>\n",
       "      <td>inf</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>recursion</td>\n",
       "      <td>0.46</td>\n",
       "      <td>recursion</td>\n",
       "      <td>0.46</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>is</td>\n",
       "      <td>0.70</td>\n",
       "      <td>is</td>\n",
       "      <td>0.70</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>a</td>\n",
       "      <td>0.41</td>\n",
       "      <td>a</td>\n",
       "      <td>0.41</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>term</td>\n",
       "      <td>0.30</td>\n",
       "      <td>term</td>\n",
       "      <td>0.30</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>I</td>\n",
       "      <td>0.89</td>\n",
       "      <td>I</td>\n",
       "      <td>0.89</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>'ve</td>\n",
       "      <td>0.26</td>\n",
       "      <td>'ve</td>\n",
       "      <td>0.78</td>\n",
       "      <td>10.00</td>\n",
       "      <td>6.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>heard</td>\n",
       "      <td>0.95</td>\n",
       "      <td>heard</td>\n",
       "      <td>0.94</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Student Token  Student Prob Teacher Token  Teacher Prob  \\\n",
       "0              ,          1.00             ,          1.00   \n",
       "1             so          0.78            so          0.78   \n",
       "2              I          0.93             I          0.93   \n",
       "3           need          0.65          need          0.65   \n",
       "4             to          1.00            to          1.00   \n",
       "5        explain          0.75       explain          0.75   \n",
       "6      recursion          0.50     recursion          0.50   \n",
       "7             in          0.98            in          0.98   \n",
       "8    programming          1.00   programming          1.00   \n",
       "9              .          0.86             .          0.86   \n",
       "10           Hmm          0.74           Hmm          0.74   \n",
       "11             ,          0.99             ,          0.99   \n",
       "12     recursion          0.46     recursion          0.46   \n",
       "13            is          0.70            is          0.70   \n",
       "14             a          0.41             a          0.41   \n",
       "15          term          0.30          term          0.30   \n",
       "16             I          0.89             I          0.89   \n",
       "17           've          0.26           've          0.78   \n",
       "18         heard          0.95         heard          0.94   \n",
       "\n",
       "    Prescribed exit layer  KL divergence  \n",
       "0                     inf          -0.00  \n",
       "1                     inf          -0.00  \n",
       "2                     inf          -0.00  \n",
       "3                     inf          -0.00  \n",
       "4                   25.00           0.00  \n",
       "5                     inf          -0.00  \n",
       "6                     inf          -0.00  \n",
       "7                     inf           0.00  \n",
       "8                   25.00           0.00  \n",
       "9                     inf           0.00  \n",
       "10                    inf           0.00  \n",
       "11                    inf          -0.00  \n",
       "12                    inf           0.00  \n",
       "13                    inf           0.00  \n",
       "14                    inf           0.00  \n",
       "15                    inf           0.00  \n",
       "16                    inf           0.00  \n",
       "17                  10.00           6.67  \n",
       "18                    inf           0.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.options.display.float_format = \"{:.2f}\".format\n",
    "rows = []\n",
    "\n",
    "def get_prob_token(probs):\n",
    "    top_id = torch.argmax(probs).item()\n",
    "    top_prob = probs[top_id].item()\n",
    "    top_token = tokenizer.decode([top_id])\n",
    "    return top_prob, top_token\n",
    "\n",
    "for idx in range(len(student_probs)):\n",
    "    # Student\n",
    "    student_top_prob, student_top_token = get_prob_token(student_probs[idx])\n",
    "    # teacher_top_prob, teacher_top_token = get_prob_token(teacher_probs[idx])\n",
    "    \n",
    "    teacher_final_top_prob, teacher_final_top_token = get_prob_token(teacher_final_probs[idx])\n",
    "\n",
    "    \n",
    "    # model_top_prob, model_top_token = get_prob_token(model_probs[idx])\n",
    "    \n",
    "    # off_top_prob, off_top_token = get_prob_token(off_probs[idx])\n",
    "\n",
    "    rows.append({\n",
    "        # \"Position\": idx,\n",
    "        \"Student Token\": student_top_token,\n",
    "        \"Student Prob\": student_top_prob,\n",
    "        # \"Teacher Token\": teacher_top_token,\n",
    "        # \"Teacher Prob\": teacher_top_prob,\n",
    "        \"Teacher Token\": teacher_final_top_token,\n",
    "        \"Teacher Prob\": teacher_final_top_prob,\n",
    "        \"Prescribed exit layer\": sampled_early_exit_layer_idxs[0, idx].item(),\n",
    "        \"KL divergence\": token_logits_kl_div[idx].item()\n",
    "        # \"Model Token\": model_top_token,\n",
    "        # \"Model Prob\": model_top_prob,\n",
    "        # \"Off Token\": off_top_token,\n",
    "        # \"Off Prob\": off_top_prob\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "display(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
