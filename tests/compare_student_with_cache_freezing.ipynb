{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c46deb1-cd30-4077-9206-801840f9e8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disabled automatic differentiation\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import sys\n",
    "# sys.path.append(\"../../\")\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "# sys.path.append(\"..\")\n",
    "from early_exit.patching.method_patching import replace_attention_layers, set_transformer_early_exit_mode\n",
    "from shared_utils.generate import format_conversation, transform_conversations\n",
    "from early_exit.util import module_name_is_layer_base\n",
    "import numpy as np\n",
    "from early_exit.util import get_model\n",
    "from shared_utils.load import get_tokenizer, configs_from_yaml\n",
    "from shared_utils.generate import generate_text\n",
    "import random\n",
    "from early_exit_teacher.visualization import visualize_tokens_by_exit_layer, create_html_visualization\n",
    "from IPython.display import HTML, display\n",
    "from early_exit.util import module_name_is_layer_base\n",
    "torch.set_grad_enabled(False)\n",
    "print(\"Disabled automatic differentiation\")\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91650b72-36fa-4db2-82ce-63716ca6ae06",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf2996ea-6ffa-4780-ad19-9cc02985f239",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_with_kv_caching(set_early_exit_layer, show_visualization = True, show_df = True):\n",
    "    set_transformer_early_exit_mode(model, 'off')\n",
    "    generated_tokens = []\n",
    "    max_new_tokens = 10\n",
    "    generated = inputs[\"input_ids\"]\n",
    "    chosen_exit_layers = []\n",
    "    all_student_logits = []\n",
    "    all_teacher_logits = []\n",
    "    for step in range(max_new_tokens):  # generate 10 tokens\n",
    "        if step == 0:\n",
    "            student_outputs = model(generated, use_cache=True)\n",
    "            student_logits = student_outputs.logits\n",
    "            student_cache = student_outputs.past_key_values\n",
    "            teacher_outputs = model(generated, use_cache=True)\n",
    "            teacher_cache = teacher_outputs.past_key_values\n",
    "            teacher_logits = teacher_outputs.logits\n",
    "        else:\n",
    "            # Pass only the new token and the cache\n",
    "            student_outputs = model(\n",
    "                next_token,\n",
    "                past_key_values=student_cache,\n",
    "                use_cache=True,\n",
    "                output_hidden_states=True\n",
    "            )\n",
    "            early_exit_layer = set_early_exit_layer(step)\n",
    "            hidden_states = student_outputs.hidden_states\n",
    "            hidden_states = torch.stack(student_outputs.hidden_states)[1:]\n",
    "            student_logits = model.lm_head(hidden_states[early_exit_layer])\n",
    "            all_student_logits.append(student_logits)\n",
    "            student_cache = student_outputs.past_key_values  # updated with new token\n",
    "            # print(len(past_key_values))\n",
    "            for layer in range(early_exit_layer, 28):\n",
    "                student_cache[layer][0][:, :, -1] = student_cache[early_exit_layer][0][:, :, -1] # keys\n",
    "                student_cache[layer][1][:, :, -1] = student_cache[early_exit_layer][1][:, :, -1] # values\n",
    "            # print(len(student_cache), student_cache[0][0].shape)\n",
    "            \n",
    "            teacher_outputs = model(\n",
    "                next_token,\n",
    "                past_key_values=teacher_cache,\n",
    "                use_cache=True\n",
    "            )\n",
    "            teacher_cache = teacher_outputs.past_key_values\n",
    "            teacher_logits = teacher_outputs.logits\n",
    "            all_teacher_logits.append(teacher_logits)\n",
    "        # Take the most likely next token (greedy decoding here)\n",
    "        # next_token = torch.argmax(student_logits[:, -1, :], dim=-1).unsqueeze(-1)\n",
    "        next_token = torch.argmax(teacher_logits[:, -1, :], dim=-1).unsqueeze(-1)\n",
    "        if step > 0: \n",
    "            generated_tokens.append(next_token.item())\n",
    "            chosen_exit_layers.append(early_exit_layer)\n",
    "        else:\n",
    "            generated_tokens.append(next_token.item())\n",
    "            chosen_exit_layers.append(-1)\n",
    "        # Append to generated sequence\n",
    "        generated = torch.cat([generated, next_token], dim=-1)\n",
    "    \n",
    "    # print(tokenizer.decode(generated[0]))\n",
    "    all_student_logits = torch.concatenate(all_student_logits, axis = 0).transpose(0,1)\n",
    "    all_teacher_logits = torch.concatenate(all_teacher_logits, axis = 0).transpose(0,1)\n",
    "    # all_student_logits.shape\n",
    "    tokens = [tokenizer.decode([token]) for token in generated_tokens]\n",
    "    layers = [27 if item == 27 or item == -1 else item for item in chosen_exit_layers]\n",
    "    early_exit_layers = early_exit_layer_idxs.tolist()  # Convert tensor to list if needed\n",
    "    # Display the visualization\n",
    "    if show_visualization: display(visualize_tokens_by_exit_layer(tokens, layers, early_exit_layers, \n",
    "                                         title=\"Committed Early Exit Token Generation\"))\n",
    "    \n",
    "    chosen_exit_layers_tensor = torch.tensor(chosen_exit_layers[1:], device=device).unsqueeze(0).float()\n",
    "    chosen_exit_layers_tensor = torch.where(\n",
    "                        chosen_exit_layers_tensor == 27,\n",
    "                        torch.full_like(chosen_exit_layers_tensor, float('inf')),\n",
    "                        chosen_exit_layers_tensor\n",
    "                    )\n",
    "    repeated_sft_teacher_generated_tokens = generated[:, :-1]\n",
    "    \n",
    "    set_transformer_early_exit_mode(model, 'sft_student')\n",
    "    sft_student_output_scores, collected_exit_logits = model(repeated_sft_teacher_generated_tokens,\\\n",
    "                                                                 prescribed_exit_layer_idxs=chosen_exit_layers_tensor)\n",
    "    \n",
    "    sft_student_output = sft_student_output_scores.logits.squeeze()[20:]\n",
    "    kv_cache_output = all_student_logits.squeeze()\n",
    "    \n",
    "    student_probs = F.softmax(sft_student_output, dim=-1)\n",
    "    teacher_cache_probs = F.softmax(all_teacher_logits.squeeze(), dim=-1)\n",
    "    student_cache_probs = F.softmax(kv_cache_output, dim=-1)\n",
    "    \n",
    "    # model_outputs = model(repeated_sft_teacher_generated_tokens)\n",
    "    # model_probs = F.softmax(model_outputs.logits[0, 20:], dim = -1)\n",
    "    \n",
    "    # set_transformer_early_exit_mode(frozen_model, 'off')\n",
    "    # off_outputs = frozen_model(repeated_sft_teacher_generated_tokens)\n",
    "    # off_probs = F.softmax(off_outputs.logits[0, 20:], dim = -1)\n",
    "    \n",
    "    pd.options.display.float_format = \"{:.2f}\".format\n",
    "    rows = []\n",
    "    \n",
    "    def get_prob_token(probs):\n",
    "        top_id = torch.argmax(probs).item()\n",
    "        top_prob = probs[top_id].item()\n",
    "        top_token = tokenizer.decode([top_id])\n",
    "        return top_prob, top_token\n",
    "    \n",
    "    for idx in range(len(student_probs)):\n",
    "        # Student\n",
    "        student_top_prob, student_top_token = get_prob_token(student_probs[idx])\n",
    "        # teacher_top_prob, teacher_top_token = get_prob_token(teacher_probs[idx])\n",
    "        \n",
    "        student_cache_top_prob, student_cache_top_token = get_prob_token(student_cache_probs[idx])\n",
    "        teacher_cache_top_prob, teacher_cache_top_token = get_prob_token(teacher_cache_probs[idx])\n",
    "    \n",
    "        \n",
    "        # model_top_prob, model_top_token = get_prob_token(model_probs[idx])\n",
    "        \n",
    "        # off_top_prob, off_top_token = get_prob_token(off_probs[idx])\n",
    "    \n",
    "        rows.append({\n",
    "            # \"Position\": idx,\n",
    "            \"Student Token\": student_top_token,\n",
    "            \"Student Prob\": student_top_prob,\n",
    "            # \"Teacher Token\": teacher_top_token,\n",
    "            # \"Teacher Prob\": teacher_top_prob,\n",
    "            \"Student Cache Token\": student_cache_top_token,\n",
    "            \"Student Cache Prob\": student_cache_top_prob,\n",
    "            \"Teacher Cache Token\": teacher_cache_top_token,\n",
    "            \"Teacher Cache Prob\": teacher_cache_top_prob,\n",
    "            # \"Model Token\": model_top_token,\n",
    "            # \"Model Prob\": model_top_prob,\n",
    "            # \"Off Token\": off_top_token,\n",
    "            # \"Off Prob\": off_top_prob\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(rows)\n",
    "    if show_df: display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58ec9da5-fe38-4439-b4a7-91815662007c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\n",
      "Device: cuda\n",
      "address this hack!\n",
      "g++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
      "Copyright (C) 2021 Free Software Foundation, Inc.\n",
      "This is free software; see the source for copying conditions.  There is NO\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
      "\n",
      "trainable params: 2,179,072 || all params: 1,779,276,294 || trainable%: 0.1225\n",
      "Tokenizer loaded. Vocab size: 151643\n",
      "EOS token: <ï½œendâ–ofâ–sentenceï½œ> (ID: 151643)\n",
      "transform_conversations currently only for Deepseek models!\n"
     ]
    }
   ],
   "source": [
    "# Model configuration\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "\n",
    "print(f\"Loading model: {model_name}\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "tokenizer = get_tokenizer(model_name)\n",
    "model_config_path = \"/project/project_465001340/fair_stuff/externalization/config_deepseek.yaml\"   # args.model_config_path\n",
    "config = configs_from_yaml(model_config_path, tokenizer.eos_token_id)\n",
    "\n",
    "model = get_model(model_name, config['model'], device)\n",
    "model = replace_attention_layers(model, config['lora'], device)\n",
    "# set_transformer_early_exit_mode(model, 'off')\n",
    "\n",
    "# Load tokenizer\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "\n",
    "config['generation']['max_new_tokens'] = 10\n",
    "\n",
    "print(f\"Tokenizer loaded. Vocab size: {tokenizer.vocab_size}\")\n",
    "print(f\"EOS token: {tokenizer.eos_token} (ID: {tokenizer.eos_token_id})\")\n",
    "\n",
    "\n",
    "\n",
    "prompt = \"Explain the concept of recursion in programming.\"\n",
    "system_prompt = \"You are a helpful programming tutor.\"\n",
    "prefiller = \"\"\n",
    "\n",
    "pre_transformed_conversation = format_conversation(user_prompts = [prompt], system_prompt=system_prompt)\n",
    "formatted_prompt = transform_conversations(pre_transformed_conversation, prefiller)[0]\n",
    "inputs = tokenizer(formatted_prompt, return_tensors=\"pt\").to(device)\n",
    "input_ids = inputs.input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cd93364-492d-47ee-8f64-8e4068c9401c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from early_exit.util import module_name_is_layer_base\n",
    "early_exit_layer_idxs = []\n",
    "for name, module in model.named_modules():\n",
    "    if module_name_is_layer_base(name):\n",
    "        layer_idx = int(name.split('.')[-1])\n",
    "        early_exit_layer_idxs.append(layer_idx)\n",
    "\n",
    "early_exit_layer_idxs = torch.tensor(early_exit_layer_idxs, dtype = torch.int32)  # Add inf for final layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa387d7-1e1e-49e6-bcd6-a20eb753937c",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30b6070-3e49-4a74-b09d-fb87aaa775f5",
   "metadata": {},
   "source": [
    "### Comparing patching and cache freezing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03899711-a256-4542-8aa0-73b071d6d522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student Token</th>\n",
       "      <th>Student Prob</th>\n",
       "      <th>Student Cache Token</th>\n",
       "      <th>Student Cache Prob</th>\n",
       "      <th>Teacher Cache Token</th>\n",
       "      <th>Teacher Cache Prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>,</td>\n",
       "      <td>1.00</td>\n",
       "      <td>,</td>\n",
       "      <td>1.00</td>\n",
       "      <td>,</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>so</td>\n",
       "      <td>0.78</td>\n",
       "      <td>so</td>\n",
       "      <td>0.78</td>\n",
       "      <td>so</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I</td>\n",
       "      <td>0.93</td>\n",
       "      <td>I</td>\n",
       "      <td>0.93</td>\n",
       "      <td>I</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>need</td>\n",
       "      <td>0.65</td>\n",
       "      <td>need</td>\n",
       "      <td>0.65</td>\n",
       "      <td>need</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to</td>\n",
       "      <td>1.00</td>\n",
       "      <td>to</td>\n",
       "      <td>1.00</td>\n",
       "      <td>to</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>explain</td>\n",
       "      <td>0.75</td>\n",
       "      <td>explain</td>\n",
       "      <td>0.75</td>\n",
       "      <td>explain</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>recursion</td>\n",
       "      <td>0.50</td>\n",
       "      <td>recursion</td>\n",
       "      <td>0.50</td>\n",
       "      <td>recursion</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>in</td>\n",
       "      <td>0.98</td>\n",
       "      <td>in</td>\n",
       "      <td>0.98</td>\n",
       "      <td>in</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>programming</td>\n",
       "      <td>1.00</td>\n",
       "      <td>programming</td>\n",
       "      <td>1.00</td>\n",
       "      <td>programming</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Student Token  Student Prob Student Cache Token  Student Cache Prob  \\\n",
       "0             ,          1.00                   ,                1.00   \n",
       "1            so          0.78                  so                0.78   \n",
       "2             I          0.93                   I                0.93   \n",
       "3          need          0.65                need                0.65   \n",
       "4            to          1.00                  to                1.00   \n",
       "5       explain          0.75             explain                0.75   \n",
       "6     recursion          0.50           recursion                0.50   \n",
       "7            in          0.98                  in                0.98   \n",
       "8   programming          1.00         programming                1.00   \n",
       "\n",
       "  Teacher Cache Token  Teacher Cache Prob  \n",
       "0                   ,                1.00  \n",
       "1                  so                0.78  \n",
       "2                   I                0.93  \n",
       "3                need                0.65  \n",
       "4                  to                1.00  \n",
       "5             explain                0.75  \n",
       "6           recursion                0.50  \n",
       "7                  in                0.98  \n",
       "8         programming                1.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def set_early_exit_layer(step):\n",
    "    return 27\n",
    "compare_with_kv_caching(set_early_exit_layer, show_visualization=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84c8f56c-baa2-46c6-bb67-acb1b012b67d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"font-family: Arial, sans-serif; margin: 20px; padding: 20px; \n",
       "                background-color: #f9f9f9; border-radius: 10px;\">\n",
       "        <h3 style=\"text-align: center; color: #333; margin-bottom: 20px;\">Committed Early Exit Token Generation</h3>\n",
       "        \n",
       "        <!-- Legend -->\n",
       "        <div style=\"display: flex; justify-content: center; gap: 15px; \n",
       "                    margin: 20px 0; padding: 15px; background-color: #fff; \n",
       "                    border-radius: 5px; flex-wrap: wrap; border: 1px solid #ddd;\">\n",
       "    \n",
       "                <div style=\"display: flex; align-items: center; gap: 8px;\">\n",
       "                    <div style=\"width: 25px; height: 15px; background-color: #6f91f2; \n",
       "                                border: 1px solid #333; border-radius: 3px;\"></div>\n",
       "                    <span style=\"font-size: 14px;\">Layer 25</span>\n",
       "                </div>\n",
       "            \n",
       "                <div style=\"display: flex; align-items: center; gap: 8px;\">\n",
       "                    <div style=\"width: 25px; height: 15px; background-color: #3a4cc0; \n",
       "                                border: 1px solid #333; border-radius: 3px;\"></div>\n",
       "                    <span style=\"font-size: 14px;\">Final Layer</span>\n",
       "                </div>\n",
       "            \n",
       "        </div>\n",
       "        \n",
       "        <!-- Tokens -->\n",
       "        <div style=\"line-height: 2.5; word-wrap: break-word; padding: 15px; \n",
       "                    background-color: #fff; border-radius: 5px; border: 1px solid #ddd;\">\n",
       "    <span style=\"display: inline-block; padding: 4px 8px; margin: 2px; \n",
       "                                      border-radius: 4px; border: 1px solid #666; \n",
       "                                      font-family: monospace; font-size: 13px; \n",
       "                                      background-color: #3a4cc0; color: white; \n",
       "                                      font-weight: bold; max-width: 200px; \n",
       "                                      overflow-wrap: break-word; vertical-align: middle;\">Okay</span><span style=\"display: inline-block; padding: 4px 8px; margin: 2px; \n",
       "                                      border-radius: 4px; border: 1px solid #666; \n",
       "                                      font-family: monospace; font-size: 13px; \n",
       "                                      background-color: #6f91f2; color: black; \n",
       "                                      font-weight: bold; max-width: 200px; \n",
       "                                      overflow-wrap: break-word; vertical-align: middle;\">,</span><span style=\"display: inline-block; padding: 4px 8px; margin: 2px; \n",
       "                                      border-radius: 4px; border: 1px solid #666; \n",
       "                                      font-family: monospace; font-size: 13px; \n",
       "                                      background-color: #6f91f2; color: black; \n",
       "                                      font-weight: bold; max-width: 200px; \n",
       "                                      overflow-wrap: break-word; vertical-align: middle;\"> so</span><span style=\"display: inline-block; padding: 4px 8px; margin: 2px; \n",
       "                                      border-radius: 4px; border: 1px solid #666; \n",
       "                                      font-family: monospace; font-size: 13px; \n",
       "                                      background-color: #6f91f2; color: black; \n",
       "                                      font-weight: bold; max-width: 200px; \n",
       "                                      overflow-wrap: break-word; vertical-align: middle;\"> I</span><span style=\"display: inline-block; padding: 4px 8px; margin: 2px; \n",
       "                                      border-radius: 4px; border: 1px solid #666; \n",
       "                                      font-family: monospace; font-size: 13px; \n",
       "                                      background-color: #6f91f2; color: black; \n",
       "                                      font-weight: bold; max-width: 200px; \n",
       "                                      overflow-wrap: break-word; vertical-align: middle;\"> need</span><span style=\"display: inline-block; padding: 4px 8px; margin: 2px; \n",
       "                                      border-radius: 4px; border: 1px solid #666; \n",
       "                                      font-family: monospace; font-size: 13px; \n",
       "                                      background-color: #3a4cc0; color: white; \n",
       "                                      font-weight: bold; max-width: 200px; \n",
       "                                      overflow-wrap: break-word; vertical-align: middle;\"> to</span><span style=\"display: inline-block; padding: 4px 8px; margin: 2px; \n",
       "                                      border-radius: 4px; border: 1px solid #666; \n",
       "                                      font-family: monospace; font-size: 13px; \n",
       "                                      background-color: #3a4cc0; color: white; \n",
       "                                      font-weight: bold; max-width: 200px; \n",
       "                                      overflow-wrap: break-word; vertical-align: middle;\"> explain</span><span style=\"display: inline-block; padding: 4px 8px; margin: 2px; \n",
       "                                      border-radius: 4px; border: 1px solid #666; \n",
       "                                      font-family: monospace; font-size: 13px; \n",
       "                                      background-color: #3a4cc0; color: white; \n",
       "                                      font-weight: bold; max-width: 200px; \n",
       "                                      overflow-wrap: break-word; vertical-align: middle;\"> recursion</span><span style=\"display: inline-block; padding: 4px 8px; margin: 2px; \n",
       "                                      border-radius: 4px; border: 1px solid #666; \n",
       "                                      font-family: monospace; font-size: 13px; \n",
       "                                      background-color: #3a4cc0; color: white; \n",
       "                                      font-weight: bold; max-width: 200px; \n",
       "                                      overflow-wrap: break-word; vertical-align: middle;\"> in</span><span style=\"display: inline-block; padding: 4px 8px; margin: 2px; \n",
       "                                      border-radius: 4px; border: 1px solid #666; \n",
       "                                      font-family: monospace; font-size: 13px; \n",
       "                                      background-color: #3a4cc0; color: white; \n",
       "                                      font-weight: bold; max-width: 200px; \n",
       "                                      overflow-wrap: break-word; vertical-align: middle;\"> programming</span>\n",
       "        </div>\n",
       "        \n",
       "        <!-- Statistics -->\n",
       "        <div style=\"margin-top: 15px; padding: 10px; background-color: #e8f4fd; \n",
       "                    border-radius: 5px; font-family: monospace; font-size: 13px;\">\n",
       "    Total tokens: 10 | Layer 25: 4 (40.0%) | Final: 6 (60.0%)\n",
       "        </div>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student Token</th>\n",
       "      <th>Student Prob</th>\n",
       "      <th>Student Cache Token</th>\n",
       "      <th>Student Cache Prob</th>\n",
       "      <th>Teacher Cache Token</th>\n",
       "      <th>Teacher Cache Prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>,</td>\n",
       "      <td>0.91</td>\n",
       "      <td>ï¿½</td>\n",
       "      <td>0.97</td>\n",
       "      <td>,</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>so</td>\n",
       "      <td>0.99</td>\n",
       "      <td>so</td>\n",
       "      <td>1.00</td>\n",
       "      <td>so</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I</td>\n",
       "      <td>1.00</td>\n",
       "      <td>I</td>\n",
       "      <td>1.00</td>\n",
       "      <td>I</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>need</td>\n",
       "      <td>1.00</td>\n",
       "      <td>need</td>\n",
       "      <td>1.00</td>\n",
       "      <td>need</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to</td>\n",
       "      <td>1.00</td>\n",
       "      <td>to</td>\n",
       "      <td>1.00</td>\n",
       "      <td>to</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>explain</td>\n",
       "      <td>0.74</td>\n",
       "      <td>explain</td>\n",
       "      <td>0.73</td>\n",
       "      <td>explain</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>recursion</td>\n",
       "      <td>0.49</td>\n",
       "      <td>recursion</td>\n",
       "      <td>0.49</td>\n",
       "      <td>recursion</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>in</td>\n",
       "      <td>0.98</td>\n",
       "      <td>in</td>\n",
       "      <td>0.98</td>\n",
       "      <td>in</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>programming</td>\n",
       "      <td>1.00</td>\n",
       "      <td>programming</td>\n",
       "      <td>1.00</td>\n",
       "      <td>programming</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Student Token  Student Prob Student Cache Token  Student Cache Prob  \\\n",
       "0             ,          0.91                   ï¿½                0.97   \n",
       "1            so          0.99                  so                1.00   \n",
       "2             I          1.00                   I                1.00   \n",
       "3          need          1.00                need                1.00   \n",
       "4            to          1.00                  to                1.00   \n",
       "5       explain          0.74             explain                0.73   \n",
       "6     recursion          0.49           recursion                0.49   \n",
       "7            in          0.98                  in                0.98   \n",
       "8   programming          1.00         programming                1.00   \n",
       "\n",
       "  Teacher Cache Token  Teacher Cache Prob  \n",
       "0                   ,                1.00  \n",
       "1                  so                0.78  \n",
       "2                   I                0.93  \n",
       "3                need                0.65  \n",
       "4                  to                1.00  \n",
       "5             explain                0.75  \n",
       "6           recursion                0.50  \n",
       "7                  in                0.98  \n",
       "8         programming                1.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def set_early_exit_layer(step):\n",
    "    if step < 5 : return 25\n",
    "    return 27\n",
    "compare_with_kv_caching(set_early_exit_layer, show_visualization=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e16f412-32b5-4a2d-8eec-f25acfa8efe6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Some fishy behaviour in the hidden states when exit is set to inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23d27864-8808-4e4c-acc2-30443a2bc22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transform_conversations currently only for Deepseek models!\n",
      "full_tokenize currently only for Deepseek models!\n",
      "prompt tokens shape: torch.Size([1, 20])\n",
      "Hidden states sum at layer 0 =  1044.895263671875\n",
      "Hidden states sum at layer 1 =  1996.1414794921875\n",
      "Hidden states sum at layer 2 =  -792.9873046875\n",
      "Hidden states sum at layer 3 =  -911.42236328125\n",
      "Hidden states sum at layer 4 =  -720.83935546875\n",
      "Hidden states sum at layer 5 =  -1360.5087890625\n",
      "Hidden states sum at layer 6 =  -1305.57958984375\n",
      "Hidden states sum at layer 7 =  -1347.95068359375\n",
      "Hidden states sum at layer 8 =  -1332.1064453125\n",
      "Hidden states sum at layer 9 =  -2242.14453125\n",
      "Hidden states sum at layer 10 =  -1557.4140625\n",
      "Hidden states sum at layer 11 =  -2730.1396484375\n",
      "Hidden states sum at layer 12 =  -2832.1123046875\n",
      "Hidden states sum at layer 13 =  -2954.1328125\n",
      "Hidden states sum at layer 14 =  -3113.5185546875\n",
      "Hidden states sum at layer 15 =  -3228.89453125\n",
      "Hidden states sum at layer 16 =  -3381.65380859375\n",
      "Hidden states sum at layer 17 =  -2924.21875\n",
      "Hidden states sum at layer 18 =  -3123.2197265625\n",
      "Hidden states sum at layer 19 =  -2317.95458984375\n",
      "Hidden states sum at layer 20 =  -2095.2734375\n",
      "Hidden states sum at layer 21 =  -1226.60693359375\n",
      "Hidden states sum at layer 22 =  488.3076171875\n",
      "Hidden states sum at layer 23 =  -47.93359375\n",
      "Hidden states sum at layer 24 =  240.8662109375\n",
      "Hidden states sum at layer 25 =  -299.0615234375\n",
      "Hidden states sum at layer 26 =  1184.380859375\n",
      "Hidden states sum at layer 27 =  -6038.32373046875\n"
     ]
    }
   ],
   "source": [
    "set_transformer_early_exit_mode(model, 'sft_teacher')\n",
    "sft_teacher_response, (sft_teacher_generated_tokens, \n",
    "                          sft_teacher_final_layer_logprobs, \n",
    "                          gathered_early_exit_hidden_states) = generate_text(\n",
    "        model=model,\n",
    "        prompt=prompt,\n",
    "        system_prompt=system_prompt,\n",
    "        prefiller=prefiller,\n",
    "        tokenizer=tokenizer,\n",
    "        generation_config=config['generation'],\n",
    "        device=device\n",
    "    )\n",
    "repeated_sft_teacher_generated_tokens = sft_teacher_generated_tokens[:, :-1] # Removing the last token to match the log probs and hidden states shape\n",
    "chosen_exit_layers_tensor = torch.inf * torch.ones([1,9])\n",
    "set_transformer_early_exit_mode(model, 'off')\n",
    "model_outputs = model(repeated_sft_teacher_generated_tokens, output_hidden_states = True)\n",
    "set_transformer_early_exit_mode(model, 'sft_student')\n",
    "student_outputs = model(repeated_sft_teacher_generated_tokens, prescribed_exit_layer_idxs = chosen_exit_layers_tensor, output_hidden_states = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b0a9a2d-d39b-4c36-9dc5-308e5dda9f66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1044.8953, device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_hidden_states = student_outputs[0].hidden_states\n",
    "student_hidden_states[1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e94ad7cb-e23b-4a90-80d3-c2394ac69e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(T1,T2):\n",
    "    if (T1 == T2).all().item():\n",
    "        print(\"Input tensors are equal\")\n",
    "    else:\n",
    "        print(\"Input tensors are NOT equal\")\n",
    "        print(f\"Tensor 1 shape = {T1.shape}\")\n",
    "        print(f\"Tensor 1 sum = {T1.sum().item():.2f}\")\n",
    "        print(f\"Tensor 2 sum = {T2.sum().item():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0023a63b-246f-430a-b234-bc3b45d3c0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensors are equal\n"
     ]
    }
   ],
   "source": [
    "compare(student_outputs[0].logits, model_outputs.logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a631c815-0d9a-40d7-bf4d-738815ad36d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensors are equal\n"
     ]
    }
   ],
   "source": [
    "layer_idx = -1\n",
    "compare(student_outputs[0].hidden_states[layer_idx], model_outputs.hidden_states[layer_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0b4af14-3f14-4fe9-8ee7-7e069972ea5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensors are NOT equal\n",
      "Tensor 1 shape = torch.Size([1, 29, 1536])\n",
      "Tensor 1 sum = 71.16\n",
      "Tensor 2 sum = 1184.38\n"
     ]
    }
   ],
   "source": [
    "layer_idx = -2\n",
    "compare(student_outputs[0].hidden_states[layer_idx], model_outputs.hidden_states[layer_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "480addc0-81fa-49a4-b6af-2bb67c6a8ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensors are NOT equal\n",
      "Tensor 1 shape = torch.Size([1, 29, 1536])\n",
      "Tensor 1 sum = 307.93\n",
      "Tensor 2 sum = 1996.14\n"
     ]
    }
   ],
   "source": [
    "layer_idx = 2\n",
    "compare(student_outputs[0].hidden_states[layer_idx], model_outputs.hidden_states[layer_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4947a674-4384-43d4-ba7d-8dd3f845c6ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensors are NOT equal\n",
      "Tensor 1 shape = torch.Size([1, 29, 1536])\n",
      "Tensor 1 sum = 15.93\n",
      "Tensor 2 sum = 1044.90\n"
     ]
    }
   ],
   "source": [
    "layer_idx = 1\n",
    "compare(student_outputs[0].hidden_states[layer_idx], model_outputs.hidden_states[layer_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28c92427-13dc-4004-842e-af43d38df2c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "348.0264587402344"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_outputs[0].hidden_states[layer_idx][0, 1:].sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a94cba2-abe7-4128-8b9d-5e5771c413b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0da9a1d-c777-4ce2-8b78-11eb23f7e771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.6025,  0.0160, -0.0486,  ...,  0.2332, -0.1245,  0.1328],\n",
       "         [-0.5391,  0.0560,  0.0482,  ...,  0.1682, -0.0921,  0.1228],\n",
       "         [ 0.5053,  0.1660,  0.1476,  ..., -0.0733,  0.0822, -0.1387],\n",
       "         ...,\n",
       "         [ 0.3975,  0.1817,  0.3600,  ..., -0.2500,  0.1910,  0.0276],\n",
       "         [-0.3182,  0.0820, -0.1923,  ...,  0.0427,  0.1280, -0.0330],\n",
       "         [ 0.3402, -0.0126,  0.2853,  ..., -0.0889, -0.0360, -0.1134]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_outputs[0].hidden_states[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06d2b016-5491-4e0e-8e63-a8ca3ab6cbf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0275,  0.0029, -0.0052,  ...,  0.0306, -0.0159,  0.0216],\n",
       "         [-0.0242,  0.0099,  0.0051,  ...,  0.0217, -0.0115,  0.0197],\n",
       "         [ 0.0298,  0.0388,  0.0204,  ..., -0.0125,  0.0135, -0.0292],\n",
       "         ...,\n",
       "         [ 0.0260,  0.0471,  0.0552,  ..., -0.0471,  0.0349,  0.0064],\n",
       "         [-0.0226,  0.0231, -0.0320,  ...,  0.0087,  0.0254, -0.0084],\n",
       "         [ 0.0212, -0.0031,  0.0417,  ..., -0.0160, -0.0063, -0.0253]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_outputs.hidden_states[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "29974a63-d106-4d83-abcb-482b8c9e4904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1044.895263671875, 3032.7021484375)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_idx = 1\n",
    "model_outputs.hidden_states[layer_idx].sum().item(), model.base_model.model.model.norm(model_outputs.hidden_states[layer_idx]).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "42e2b68a-2413-4902-9264-e613469db4c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15.934192657470703, 126.9844970703125)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_outputs[0].hidden_states[layer_idx].sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1b02ac40-59e0-4894-9b33-3873f30de838",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File copied to ./modeling_qwen2.py\n"
     ]
    }
   ],
   "source": [
    "!python -c \"import transformers.models.qwen2.modeling_qwen2 as m; import inspect, shutil; shutil.copy2(inspect.getfile(m), './modeling_qwen2.py'); print('File copied to ./modeling_qwen2.py')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "792e2d4d-091a-495a-be35-5acb2cbc9ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ Full path: /usr/local/lib/python3.11/dist-packages/transformers/models/qwen2/modeling_qwen2.py\n",
      "ðŸ“ Directory: /usr/local/lib/python3.11/dist-packages/transformers/models/qwen2\n",
      "ðŸ“ Filename: modeling_qwen2.py\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/usr/local/lib/python3.11/dist-packages/transformers/models/qwen2/modeling_qwen2.py'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "def find_file_with_inspect():\n",
    "    \"\"\"Find the file using Python's inspect module\"\"\"\n",
    "    try:\n",
    "        import transformers.models.qwen2.modeling_qwen2 as qwen2_module\n",
    "        import inspect\n",
    "        \n",
    "        file_path = inspect.getfile(qwen2_module)\n",
    "        print(f\"ðŸ“ Full path: {file_path}\")\n",
    "        print(f\"ðŸ“ Directory: {os.path.dirname(file_path)}\")\n",
    "        print(f\"ðŸ“ Filename: {os.path.basename(file_path)}\")\n",
    "        \n",
    "        return file_path\n",
    "    except ImportError:\n",
    "        print(\"âŒ Could not import modeling_qwen2\")\n",
    "        return None\n",
    "find_file_with_inspect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "03e73b43-ad94-4112-85e5-4a2857022090",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = get_model(model_name, config['model'], device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8c3332a6-6b4a-41bc-91bb-84545489cc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_outputs = base_model(repeated_sft_teacher_generated_tokens, output_hidden_states = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "12e555a5-e30d-4e02-be14-4f577e96df07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1008.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_idx = 1\n",
    "base_model_outputs.hidden_states[layer_idx].sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "61fb8501-8619-4668-aa6d-5e71ef0d2f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden states sum at layer 0 =  1044.895263671875\n",
      "Hidden states sum at layer 1 =  1996.1414794921875\n",
      "Hidden states sum at layer 2 =  -792.9873046875\n",
      "Hidden states sum at layer 3 =  -911.42236328125\n",
      "Hidden states sum at layer 4 =  -720.83935546875\n",
      "Hidden states sum at layer 5 =  -1360.5087890625\n",
      "Hidden states sum at layer 6 =  -1305.57958984375\n",
      "Hidden states sum at layer 7 =  -1347.95068359375\n",
      "Hidden states sum at layer 8 =  -1332.1064453125\n",
      "Hidden states sum at layer 9 =  -2242.14453125\n",
      "Hidden states sum at layer 10 =  -1557.4140625\n",
      "Hidden states sum at layer 11 =  -2730.1396484375\n",
      "Hidden states sum at layer 12 =  -2832.1123046875\n",
      "Hidden states sum at layer 13 =  -2954.1328125\n",
      "Hidden states sum at layer 14 =  -3113.5185546875\n",
      "Hidden states sum at layer 15 =  -3228.89453125\n",
      "Hidden states sum at layer 16 =  -3381.65380859375\n",
      "Hidden states sum at layer 17 =  -2924.21875\n",
      "Hidden states sum at layer 18 =  -3123.2197265625\n",
      "Hidden states sum at layer 19 =  -2317.95458984375\n",
      "Hidden states sum at layer 20 =  -2095.2734375\n",
      "Hidden states sum at layer 21 =  -1226.60693359375\n",
      "Hidden states sum at layer 22 =  488.3076171875\n",
      "Hidden states sum at layer 23 =  -47.93359375\n",
      "Hidden states sum at layer 24 =  240.8662109375\n",
      "Hidden states sum at layer 25 =  -299.0615234375\n",
      "Hidden states sum at layer 26 =  1184.380859375\n",
      "Hidden states sum at layer 27 =  -6038.32373046875\n"
     ]
    }
   ],
   "source": [
    "set_transformer_early_exit_mode(model, 'sft_student')\n",
    "student_outputs = model.base_model.model(repeated_sft_teacher_generated_tokens, prescribed_exit_layer_idxs = chosen_exit_layers_tensor, output_hidden_states = True)\n",
    "# student_outputs.hidden_states[1].sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "00b46693-155c-4d8e-bc02-0a42a58f1585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(CausalLMOutputWithPast(loss=None, logits=tensor([[[ 3.7575,  3.1718,  4.4061,  ..., -5.3510, -5.3516, -5.3517],\n",
       "          [ 3.7474,  2.6098,  4.2445,  ..., -4.9174, -4.9179, -4.9179],\n",
       "          [ 6.6954,  4.5980, -1.3376,  ..., -0.2886, -0.2888, -0.2920],\n",
       "          ...,\n",
       "          [ 6.7107,  1.3286,  0.0712,  ...,  1.3508,  1.3503,  1.3473],\n",
       "          [14.4657,  5.3727,  3.5022,  ...,  0.0762,  0.0770,  0.0748],\n",
       "          [ 5.1411, -0.6737,  1.3859,  ...,  0.5440,  0.5444,  0.5413]]],\n",
       "        device='cuda:0'), past_key_values=<transformers.cache_utils.DynamicCache object at 0x14cd55d50990>, hidden_states=(tensor([[[-0.6025,  0.0160, -0.0486,  ...,  0.2332, -0.1245,  0.1328],\n",
       "          [-0.5391,  0.0560,  0.0482,  ...,  0.1682, -0.0921,  0.1228],\n",
       "          [ 0.5053,  0.1660,  0.1476,  ..., -0.0733,  0.0822, -0.1387],\n",
       "          ...,\n",
       "          [ 0.3975,  0.1817,  0.3600,  ..., -0.2500,  0.1910,  0.0276],\n",
       "          [-0.3182,  0.0820, -0.1923,  ...,  0.0427,  0.1280, -0.0330],\n",
       "          [ 0.3402, -0.0126,  0.2853,  ..., -0.0889, -0.0360, -0.1134]]],\n",
       "        device='cuda:0'), tensor([[[-0.0571, -0.0079, -0.0902,  ..., -0.2888, -0.1419,  0.0019],\n",
       "          [ 0.0532, -0.0160, -0.1093,  ..., -0.1995, -0.2218, -0.0316],\n",
       "          [-0.0131,  0.0257, -0.1378,  ..., -0.1846,  0.0186,  0.1073],\n",
       "          ...,\n",
       "          [-0.3931,  0.0165,  0.0138,  ..., -0.0397, -0.0652, -0.0212],\n",
       "          [ 0.2505,  0.0976,  0.0576,  ..., -0.0178,  0.0491,  0.1101],\n",
       "          [ 0.0484,  0.1109, -0.0019,  ...,  0.1556, -0.0271,  0.0485]]],\n",
       "        device='cuda:0'), tensor([[[-0.0772, -0.0554,  0.0523,  ...,  0.0163,  0.1351, -0.0557],\n",
       "          [-0.0558, -0.0509,  0.0405,  ...,  0.0076,  0.1151, -0.0451],\n",
       "          [ 0.1137, -0.0404, -0.8701,  ...,  0.2282,  0.3747, -0.3861],\n",
       "          ...,\n",
       "          [-0.6118,  0.1699, -0.0354,  ...,  0.1756, -0.1695,  0.1178],\n",
       "          [ 0.5138,  0.4086,  0.1579,  ..., -0.3510,  0.1181,  0.2756],\n",
       "          [ 0.1789,  0.2892, -0.1617,  ..., -0.3494,  0.0626,  0.2745]]],\n",
       "        device='cuda:0'), tensor([[[-5.6062e-03, -6.7946e-04,  6.8646e-02,  ...,  1.6914e-02,\n",
       "            1.2439e-02,  3.7186e-02],\n",
       "          [ 2.9400e-03,  1.9771e-03,  6.7515e-02,  ...,  1.5202e-02,\n",
       "            4.0235e-03,  4.1380e-02],\n",
       "          [ 1.8598e-01,  2.8363e-02, -5.8781e-01,  ..., -6.7173e-02,\n",
       "            3.4341e-01, -3.8204e-01],\n",
       "          ...,\n",
       "          [-7.6419e-01,  6.4422e-03, -1.8542e-01,  ...,  2.5818e-01,\n",
       "           -3.3217e-01, -1.7150e-02],\n",
       "          [ 7.1373e-01,  3.2222e-01,  3.3138e-01,  ..., -2.3611e-01,\n",
       "            8.8033e-02,  2.2804e-01],\n",
       "          [ 2.2170e-01,  2.5636e-01,  1.6390e-02,  ..., -1.4961e-01,\n",
       "            1.5143e-01,  3.3186e-01]]], device='cuda:0'), tensor([[[-4.1384e-03, -2.3716e-03,  1.0129e-01,  ...,  1.8170e-02,\n",
       "            1.5167e-02,  4.9645e-02],\n",
       "          [ 1.1187e-03,  4.2165e-04,  9.9836e-02,  ...,  1.6622e-02,\n",
       "            5.5377e-03,  5.5175e-02],\n",
       "          [ 1.1021e-01, -4.4733e-03, -3.3010e-01,  ..., -1.5288e-01,\n",
       "            4.4844e-01, -1.8034e-01],\n",
       "          ...,\n",
       "          [-5.0120e-01,  5.8843e-02, -8.2045e-02,  ...,  4.9231e-01,\n",
       "           -4.5056e-01, -1.9940e-01],\n",
       "          [ 4.1281e-01,  2.5521e-01,  5.7146e-01,  ..., -1.4637e-01,\n",
       "            3.5437e-02,  2.0882e-01],\n",
       "          [ 1.7445e-01,  4.3355e-01,  4.0556e-01,  ...,  2.6679e-01,\n",
       "            2.3240e-01,  4.1365e-01]]], device='cuda:0'), tensor([[[-1.0591e-02, -4.1201e-03,  8.6443e-02,  ...,  1.8219e-02,\n",
       "            1.3201e-02,  3.1574e-02],\n",
       "          [ 3.4744e-03, -2.7562e-04,  8.5166e-02,  ...,  1.6536e-02,\n",
       "            4.8146e-03,  3.5025e-02],\n",
       "          [ 2.6407e-01, -1.2441e-01, -2.7963e-01,  ..., -1.1179e-01,\n",
       "            2.8547e-01, -3.2527e-02],\n",
       "          ...,\n",
       "          [-1.4820e+00,  3.0356e-01,  1.0672e-01,  ...,  6.8192e-01,\n",
       "           -9.9063e-02, -3.1090e-01],\n",
       "          [ 1.0682e+00,  4.0903e-01,  3.3827e-01,  ..., -2.8859e-01,\n",
       "            1.1904e-01,  8.2844e-02],\n",
       "          [ 6.1805e-01,  2.7790e-01,  3.2208e-01,  ...,  3.7562e-01,\n",
       "            2.5215e-01,  1.1040e-01]]], device='cuda:0'), tensor([[[-1.6578e-02, -4.3401e-03,  9.4826e-02,  ...,  1.7529e-02,\n",
       "            1.1855e-02,  3.1879e-02],\n",
       "          [ 4.7565e-03, -1.6995e-03,  9.3366e-02,  ...,  1.6262e-02,\n",
       "            4.9650e-03,  3.5291e-02],\n",
       "          [ 1.3064e-01,  2.9865e-02, -5.7624e-02,  ..., -1.4856e-01,\n",
       "            1.8240e-01, -1.6694e-02],\n",
       "          ...,\n",
       "          [-2.3788e+00,  1.5522e-01,  6.0342e-02,  ...,  6.6447e-01,\n",
       "           -8.9572e-02, -2.6747e-01],\n",
       "          [ 1.5819e+00,  2.8633e-01,  6.7988e-01,  ..., -7.1771e-02,\n",
       "            2.9270e-02,  3.3734e-02],\n",
       "          [ 8.8753e-01,  6.4001e-02,  5.1334e-01,  ...,  4.2883e-01,\n",
       "            3.1203e-01, -5.0956e-02]]], device='cuda:0'), tensor([[[-1.5223e-03, -4.2933e-03,  1.0148e-01,  ...,  2.2738e-02,\n",
       "            1.1328e-02,  3.4598e-02],\n",
       "          [ 4.4843e-04, -8.1470e-04,  9.9896e-02,  ...,  2.1040e-02,\n",
       "            5.1625e-03,  3.8258e-02],\n",
       "          [ 5.9294e-03,  1.4485e-01,  4.6201e-02,  ..., -7.9191e-02,\n",
       "            5.8324e-02,  7.1144e-03],\n",
       "          ...,\n",
       "          [-2.0021e-01,  3.1139e-01, -3.6169e-02,  ...,  6.7476e-01,\n",
       "            6.7200e-02, -3.1856e-01],\n",
       "          [ 1.0012e-01,  2.9895e-02,  4.8942e-01,  ...,  8.0487e-03,\n",
       "            2.1336e-01,  1.7288e-01],\n",
       "          [ 9.0399e-02,  2.4781e-01,  3.2856e-01,  ...,  4.8074e-01,\n",
       "            3.8615e-01, -1.5061e-01]]], device='cuda:0'), tensor([[[-0.0028, -0.0052,  0.1548,  ...,  0.0326,  0.0218,  0.0575],\n",
       "          [ 0.0009, -0.0007,  0.1521,  ...,  0.0306,  0.0102,  0.0635],\n",
       "          [-0.0286,  0.2424, -0.1314,  ...,  0.0429,  0.0553, -0.0533],\n",
       "          ...,\n",
       "          [-0.3749,  0.4044, -0.0571,  ...,  0.1612, -0.0475, -0.3484],\n",
       "          [ 0.1597,  0.2763,  0.1499,  ..., -0.1527,  0.1578,  0.1140],\n",
       "          [ 0.2000,  0.3483,  0.2106,  ...,  0.3280,  0.5553, -0.3168]]],\n",
       "        device='cuda:0'), tensor([[[-0.0034, -0.0064,  0.1301,  ...,  0.0312,  0.0234,  0.0636],\n",
       "          [ 0.0013, -0.0019,  0.1282,  ...,  0.0293,  0.0113,  0.0702],\n",
       "          [ 0.0103,  0.2494,  0.1283,  ..., -0.0502,  0.0848, -0.0055],\n",
       "          ...,\n",
       "          [-0.4159,  0.3130, -0.3422,  ...,  0.3656,  0.1959, -0.7487],\n",
       "          [ 0.1519,  0.1638,  0.3933,  ...,  0.0609, -0.0232,  0.0980],\n",
       "          [ 0.3335,  0.0110, -0.3504,  ...,  0.3867,  0.3650, -0.1447]]],\n",
       "        device='cuda:0'), tensor([[[-1.3377e-03, -1.0390e-02,  1.7326e-01,  ...,  3.6156e-02,\n",
       "            2.8444e-02,  8.6590e-02],\n",
       "          [ 5.6578e-04, -4.6812e-03,  1.7083e-01,  ...,  3.4228e-02,\n",
       "            1.4446e-02,  9.5512e-02],\n",
       "          [ 5.0182e-03,  3.3992e-01, -7.5995e-02,  ...,  9.5289e-02,\n",
       "            2.1777e-01,  1.9307e-02],\n",
       "          ...,\n",
       "          [-1.6333e-01,  5.0741e-01, -3.0050e-01,  ..., -1.0570e-01,\n",
       "            1.3639e-01, -5.5130e-01],\n",
       "          [ 5.2857e-02, -4.4740e-01,  8.6720e-01,  ..., -2.8943e-01,\n",
       "           -2.0560e-01, -2.8556e-02],\n",
       "          [ 1.0987e-01, -2.0885e-01, -7.1502e-01,  ..., -2.1391e-01,\n",
       "            6.4648e-01, -6.6829e-02]]], device='cuda:0'), tensor([[[-1.0466e-03, -1.1102e-02,  1.5766e-01,  ...,  3.1592e-02,\n",
       "            2.5172e-02,  8.7017e-02],\n",
       "          [ 3.9766e-04, -5.5541e-03,  1.5565e-01,  ...,  2.9942e-02,\n",
       "            1.3469e-02,  9.5900e-02],\n",
       "          [ 3.7453e-03,  1.0511e-01,  2.0985e-02,  ...,  3.7138e-02,\n",
       "            1.8083e-01,  1.3658e-01],\n",
       "          ...,\n",
       "          [-1.3520e-01, -1.1907e-02, -1.2545e-01,  ...,  5.6971e-01,\n",
       "            5.0314e-01, -7.5077e-01],\n",
       "          [ 2.8766e-02, -2.8043e-01,  5.7272e-01,  ..., -1.8434e-01,\n",
       "           -2.5486e-01,  1.6416e-01],\n",
       "          [ 7.9854e-02, -2.2180e-01, -1.5276e-01,  ...,  3.6088e-01,\n",
       "            5.5006e-01, -2.8109e-01]]], device='cuda:0'), tensor([[[-0.0118, -0.0079,  0.2032,  ...,  0.0354,  0.0303,  0.0738],\n",
       "          [ 0.0039, -0.0020,  0.2012,  ...,  0.0333,  0.0159,  0.0812],\n",
       "          [-0.0592,  0.1494, -0.0842,  ..., -0.1025,  0.2568,  0.1598],\n",
       "          ...,\n",
       "          [-1.5587, -0.3427, -1.0013,  ...,  0.5506,  0.6906, -0.0781],\n",
       "          [ 0.3663, -0.1487, -0.1238,  ..., -0.4081, -0.0783,  0.0239],\n",
       "          [ 0.7317, -0.3137, -0.6698,  ..., -0.0653,  0.6637, -0.2172]]],\n",
       "        device='cuda:0'), tensor([[[-9.9620e-04, -5.2169e-03,  1.6191e-01,  ...,  3.0104e-02,\n",
       "            2.6872e-02,  8.5229e-02],\n",
       "          [ 4.0504e-04,  5.7547e-04,  1.6087e-01,  ...,  2.8420e-02,\n",
       "            1.3304e-02,  9.3673e-02],\n",
       "          [-2.7933e-03,  2.2266e-01,  1.3345e-01,  ..., -1.5633e-01,\n",
       "            2.9967e-01,  1.2376e-01],\n",
       "          ...,\n",
       "          [-1.2691e-01, -2.3410e-03, -8.4167e-01,  ...,  2.7455e-03,\n",
       "            4.1522e-01, -3.2997e-01],\n",
       "          [ 2.6503e-02, -2.5636e-02,  7.1510e-02,  ..., -3.1357e-01,\n",
       "           -1.8079e-01,  1.8062e-01],\n",
       "          [ 6.0051e-02,  2.9776e-01,  9.4426e-03,  ..., -1.3806e-01,\n",
       "            4.5708e-01,  1.4855e-01]]], device='cuda:0'), tensor([[[-1.3754e-03, -1.5681e-03,  2.8140e-01,  ...,  3.8781e-02,\n",
       "            2.6760e-02,  1.1343e-01],\n",
       "          [ 5.8572e-04,  6.1838e-03,  2.8033e-01,  ...,  3.6789e-02,\n",
       "            1.3127e-02,  1.2449e-01],\n",
       "          [-1.2702e-02,  1.9114e-01,  3.8829e-01,  ..., -5.0249e-02,\n",
       "            3.2950e-01,  2.1726e-01],\n",
       "          ...,\n",
       "          [-1.5624e-01,  1.4658e-01, -1.2215e+00,  ...,  2.1105e-01,\n",
       "            3.6002e-01, -2.2766e-01],\n",
       "          [ 3.4668e-02, -1.5784e-01,  4.5497e-01,  ..., -1.3532e-01,\n",
       "           -1.9047e-01,  3.9774e-01],\n",
       "          [ 9.2815e-02,  5.5973e-01,  3.4211e-01,  ..., -1.6370e-01,\n",
       "            3.8001e-01,  5.9660e-01]]], device='cuda:0'), tensor([[[-8.8239e-04,  1.3562e-05,  1.8288e-01,  ...,  2.9120e-02,\n",
       "            3.0071e-02,  1.2259e-01],\n",
       "          [ 3.4018e-04,  8.0715e-03,  1.8271e-01,  ...,  2.7357e-02,\n",
       "            1.4936e-02,  1.3458e-01],\n",
       "          [-7.6311e-03,  1.2565e-01,  4.7102e-01,  ..., -7.9278e-02,\n",
       "            3.4175e-01,  7.3811e-02],\n",
       "          ...,\n",
       "          [-1.0188e-01,  4.1878e-01, -5.2522e-01,  ...,  8.5137e-02,\n",
       "            5.5717e-01,  2.8040e-02],\n",
       "          [ 1.9838e-02,  2.3602e-01,  5.7097e-01,  ..., -1.3729e-01,\n",
       "           -2.0309e-01, -1.9102e-02],\n",
       "          [ 5.6988e-02,  2.2217e-01,  7.0584e-01,  ..., -3.2902e-01,\n",
       "            8.1022e-02,  3.0059e-01]]], device='cuda:0'), tensor([[[-1.4320e-03,  1.0504e-03,  2.6593e-01,  ...,  3.7447e-02,\n",
       "            3.8116e-02,  1.1498e-01],\n",
       "          [ 4.9931e-04,  1.0533e-02,  2.6581e-01,  ...,  3.5335e-02,\n",
       "            1.9344e-02,  1.2611e-01],\n",
       "          [-1.5151e-02,  4.1877e-02,  6.6455e-01,  ..., -9.6237e-04,\n",
       "            4.6201e-01,  1.1033e-01],\n",
       "          ...,\n",
       "          [-1.5068e-01,  1.1678e-01, -8.0913e-01,  ...,  3.3832e-01,\n",
       "            8.5309e-01,  5.0277e-01],\n",
       "          [ 1.7450e-02, -1.0759e-01,  2.4316e-01,  ..., -1.2296e-01,\n",
       "            1.1256e-01,  1.4958e-02],\n",
       "          [ 7.4077e-02, -2.9923e-01,  1.3550e+00,  ..., -3.9037e-01,\n",
       "            5.1596e-01,  2.7244e-01]]], device='cuda:0'), tensor([[[-2.5929e-03,  3.1799e-03,  1.8032e-01,  ...,  3.3434e-02,\n",
       "            3.1143e-02,  1.0310e-01],\n",
       "          [ 7.6347e-04,  1.1439e-02,  1.8052e-01,  ...,  3.1647e-02,\n",
       "            1.4305e-02,  1.1323e-01],\n",
       "          [-1.7462e-02,  1.9377e-01,  4.4734e-01,  ...,  6.4381e-02,\n",
       "            2.1566e-01,  1.4896e-01],\n",
       "          ...,\n",
       "          [-2.4003e-01,  3.8440e-01, -9.4953e-01,  ...,  4.6507e-01,\n",
       "            7.6883e-01,  5.1464e-01],\n",
       "          [ 4.3821e-02,  3.7699e-01,  2.6350e-01,  ..., -2.3814e-02,\n",
       "           -3.3350e-02,  9.4485e-02],\n",
       "          [ 1.1111e-01, -4.9926e-02,  1.1361e+00,  ..., -1.4556e-01,\n",
       "            2.8318e-01,  4.0631e-01]]], device='cuda:0'), tensor([[[-1.7802e-03,  2.3049e-03,  2.1267e-01,  ...,  3.1362e-02,\n",
       "            2.6625e-02,  8.8718e-02],\n",
       "          [ 6.1132e-04,  1.0142e-02,  2.1381e-01,  ...,  2.9667e-02,\n",
       "            1.0991e-02,  9.7497e-02],\n",
       "          [-8.2071e-03,  6.2092e-02,  9.0731e-01,  ...,  1.1524e-01,\n",
       "            2.4746e-01, -2.3762e-03],\n",
       "          ...,\n",
       "          [-1.7438e-01,  4.8515e-01, -1.0093e+00,  ...,  3.3824e-01,\n",
       "            5.4135e-01,  7.2343e-01],\n",
       "          [ 2.7304e-02,  2.3372e-01,  5.0800e-01,  ..., -1.2141e-01,\n",
       "           -6.5252e-02,  3.4528e-01],\n",
       "          [ 8.1995e-02, -4.4227e-02,  1.5561e+00,  ..., -7.8563e-02,\n",
       "           -6.6560e-02,  2.8187e-01]]], device='cuda:0'), tensor([[[-0.0048,  0.0046,  0.2261,  ...,  0.0300,  0.0293,  0.0957],\n",
       "          [ 0.0024,  0.0131,  0.2278,  ...,  0.0281,  0.0139,  0.1051],\n",
       "          [-0.0186,  0.2504,  1.0934,  ...,  0.3554,  0.1644, -0.0708],\n",
       "          ...,\n",
       "          [-0.4579, -0.1155, -0.8441,  ...,  0.2192,  0.6044,  0.2858],\n",
       "          [ 0.0472,  0.3035,  0.1829,  ..., -0.3254,  0.1146,  0.2706],\n",
       "          [ 0.1862,  0.3360,  2.2696,  ..., -0.2260, -0.0729,  0.2651]]],\n",
       "        device='cuda:0'), tensor([[[-0.0066,  0.0050,  0.2300,  ...,  0.0343,  0.0306,  0.0770],\n",
       "          [ 0.0033,  0.0111,  0.2321,  ...,  0.0322,  0.0147,  0.0849],\n",
       "          [-0.0843, -0.1571,  1.1577,  ...,  0.2868,  0.0834,  0.1302],\n",
       "          ...,\n",
       "          [-0.7787, -0.3179, -1.1946,  ...,  0.4284,  0.5366, -0.0881],\n",
       "          [ 0.1100,  0.1361,  0.6962,  ..., -0.7074,  0.0938,  0.2357],\n",
       "          [ 0.1915,  0.0947,  2.7908,  ..., -0.7136, -0.2369, -0.0551]]],\n",
       "        device='cuda:0'), tensor([[[-4.4459e-03,  7.2617e-03,  2.3671e-01,  ...,  3.3475e-02,\n",
       "            2.3742e-02,  6.5226e-02],\n",
       "          [ 1.8171e-03,  1.3179e-02,  2.3941e-01,  ...,  3.1510e-02,\n",
       "            8.2392e-03,  7.1703e-02],\n",
       "          [-7.1275e-02, -2.0851e-01,  1.1116e+00,  ...,  3.3684e-01,\n",
       "           -1.2584e-01, -1.0109e-01],\n",
       "          ...,\n",
       "          [-4.5866e-01, -2.7199e-01, -5.1408e-01,  ...,  3.7983e-01,\n",
       "            3.1689e-01,  9.4362e-02],\n",
       "          [ 3.0325e-02,  8.0430e-02,  1.3220e+00,  ..., -6.1822e-01,\n",
       "            1.0127e-01,  2.0652e-01],\n",
       "          [ 7.2947e-02, -4.0680e-02,  3.1513e+00,  ..., -7.2825e-01,\n",
       "            8.9735e-02, -1.3430e-01]]], device='cuda:0'), tensor([[[-1.7752e-02,  4.6957e-03,  2.3985e-01,  ...,  2.7339e-02,\n",
       "            1.8485e-02,  6.4863e-02],\n",
       "          [ 2.5101e-03,  1.0159e-02,  2.4271e-01,  ...,  2.5626e-02,\n",
       "            3.8040e-03,  7.1224e-02],\n",
       "          [-1.5398e-01,  2.2377e-01,  9.6607e-01,  ...,  1.1932e-01,\n",
       "           -4.3502e-01, -1.4595e-01],\n",
       "          ...,\n",
       "          [-1.7123e+00,  2.8695e-01, -1.1748e+00,  ...,  2.4376e-01,\n",
       "            3.8256e-01, -2.2654e-01],\n",
       "          [ 7.0821e-01,  1.1532e-01,  8.7101e-01,  ..., -3.9924e-01,\n",
       "            7.7372e-02, -2.2699e-01],\n",
       "          [ 4.7340e-01,  4.3925e-01,  2.6482e+00,  ..., -7.2687e-01,\n",
       "           -2.9999e-01, -3.4731e-01]]], device='cuda:0'), tensor([[[-2.2185e-02,  1.5868e-03,  2.9775e-01,  ...,  3.4810e-02,\n",
       "            1.4747e-02,  5.9736e-02],\n",
       "          [ 1.6535e-04,  6.0123e-03,  3.0165e-01,  ...,  3.3343e-02,\n",
       "            9.0107e-04,  6.5369e-02],\n",
       "          [ 3.8142e-02,  2.7655e-01,  1.1390e+00,  ..., -1.3228e-01,\n",
       "           -4.1110e-01, -3.1629e-01],\n",
       "          ...,\n",
       "          [-1.8644e+00,  4.1742e-01, -1.6776e+00,  ...,  8.6741e-02,\n",
       "            1.6128e-01, -7.6624e-01],\n",
       "          [ 6.6239e-01,  8.0664e-02,  8.4926e-01,  ..., -5.8034e-01,\n",
       "            2.8465e-01, -5.4183e-01],\n",
       "          [ 2.6500e-01,  1.7222e-01,  3.6389e+00,  ..., -1.1516e+00,\n",
       "           -2.9824e-01, -7.5503e-01]]], device='cuda:0'), tensor([[[-3.6329e-02, -1.9847e-03,  2.5242e-01,  ...,  3.0543e-02,\n",
       "            1.2513e-02,  5.1813e-02],\n",
       "          [-7.6590e-03,  2.0306e-03,  2.5522e-01,  ...,  2.8940e-02,\n",
       "           -2.8129e-03,  5.6946e-02],\n",
       "          [-2.1019e-01, -1.2550e-01,  1.3145e+00,  ..., -1.9195e-01,\n",
       "           -2.0121e-01, -1.4571e-01],\n",
       "          ...,\n",
       "          [-2.4690e+00,  3.7653e-01, -9.2629e-01,  ...,  6.4549e-02,\n",
       "            1.7813e-01, -8.0926e-01],\n",
       "          [ 4.5705e-01,  2.5398e-01,  6.4416e-01,  ..., -4.7600e-01,\n",
       "            4.4263e-01, -5.0418e-01],\n",
       "          [ 2.7767e-01,  2.7830e-01,  2.1125e+00,  ..., -8.8675e-01,\n",
       "           -5.6764e-01, -9.8561e-01]]], device='cuda:0'), tensor([[[-5.5207e-02, -9.7996e-04,  1.6423e-01,  ...,  2.2556e-02,\n",
       "            4.9920e-03,  3.8331e-02],\n",
       "          [-1.4768e-02,  2.0308e-03,  1.6445e-01,  ...,  2.1180e-02,\n",
       "           -8.1362e-03,  4.2301e-02],\n",
       "          [-2.5179e-01, -1.3306e-01,  8.7068e-01,  ..., -2.1693e-01,\n",
       "           -6.9382e-02, -6.1719e-02],\n",
       "          ...,\n",
       "          [-2.8928e+00,  3.5336e-01, -6.4673e-01,  ...,  1.4482e-01,\n",
       "            2.4425e-02, -5.3852e-01],\n",
       "          [ 6.8263e-01,  2.1416e-01,  3.7701e-01,  ..., -1.8917e-01,\n",
       "            2.0604e-01, -1.8638e-01],\n",
       "          [ 3.5397e-01,  2.1343e-01,  1.4298e+00,  ..., -5.1598e-01,\n",
       "           -5.4561e-01, -5.6826e-01]]], device='cuda:0'), tensor([[[-7.2888e-02,  4.3693e-03,  4.0391e-01,  ...,  2.0207e-02,\n",
       "           -5.0230e-04,  3.2224e-02],\n",
       "          [-1.1730e-02,  7.3833e-03,  4.0499e-01,  ...,  1.8875e-02,\n",
       "           -1.1559e-02,  3.5701e-02],\n",
       "          [-1.9542e-01, -7.3032e-02,  2.4061e+00,  ..., -1.7660e-01,\n",
       "           -6.5504e-02, -3.0704e-02],\n",
       "          ...,\n",
       "          [-3.5778e+00,  2.8791e-01, -1.1486e+00,  ..., -5.5460e-02,\n",
       "            3.4427e-02, -4.3596e-01],\n",
       "          [ 2.3366e-01,  1.2223e-01,  9.1666e-01,  ..., -2.2517e-01,\n",
       "            1.6041e-01, -1.2274e-01],\n",
       "          [ 3.8643e-01,  2.9271e-01,  2.7144e+00,  ..., -5.3593e-01,\n",
       "           -3.3624e-01, -3.6946e-01]]], device='cuda:0'), tensor([[[-3.5828e-01,  1.0867e-02,  6.9157e-01,  ..., -1.0717e-02,\n",
       "            1.9277e-03,  9.5269e-02],\n",
       "          [-2.7044e-01,  1.7480e-02,  7.1998e-01,  ..., -1.7743e-02,\n",
       "           -1.9907e-02,  1.0542e-01],\n",
       "          [-2.9340e-01, -1.1470e-01,  2.4239e+00,  ..., -1.6107e-01,\n",
       "           -6.7532e-02,  6.4372e-02],\n",
       "          ...,\n",
       "          [-2.9404e+00,  2.3935e-01, -1.9692e-01,  ..., -2.1648e-01,\n",
       "            1.0612e-01, -4.4074e-01],\n",
       "          [ 2.4754e-01,  2.9444e-02,  1.3403e+00,  ..., -3.5400e-01,\n",
       "            2.4520e-01, -5.5026e-02],\n",
       "          [-1.9060e-01,  1.8024e-01,  2.5840e+00,  ..., -5.8717e-01,\n",
       "           -2.7124e-01, -6.7890e-02]]], device='cuda:0'), tensor([[[ 1.8242, -2.6348,  1.8128,  ...,  0.1478,  2.3423,  0.9424],\n",
       "          [ 2.3714, -2.4943,  1.8002,  ...,  0.0254,  1.8833,  0.8723],\n",
       "          [-0.9379, -1.6615,  0.8829,  ..., -1.6242,  1.4676,  0.6740],\n",
       "          ...,\n",
       "          [-0.1322,  1.2105, -1.5012,  ..., -0.7358,  1.2516, -1.8464],\n",
       "          [ 0.5014, -0.1602,  0.0721,  ..., -1.9322,  2.9715, -0.4337],\n",
       "          [ 1.2823,  0.8889,  0.8016,  ..., -3.1028, -1.2115,  0.5592]]],\n",
       "        device='cuda:0')), attentions=None),\n",
       " tensor([[[-2.9591e-03,  7.1069e-01, -7.4328e-01, -2.5930e-01, -1.7928e+00,\n",
       "            5.6814e-02],\n",
       "          [-2.5181e-02,  1.1490e+00, -1.5012e+00, -3.1997e+00, -6.6213e-01,\n",
       "            1.0686e+00],\n",
       "          [-2.8474e-02,  1.7111e+00,  4.5250e-01, -9.1697e-01, -9.8163e-01,\n",
       "           -1.6183e+00],\n",
       "          [ 2.0428e-02,  1.6862e-01, -2.4081e-01, -1.9833e+00,  2.7587e-01,\n",
       "           -5.1500e+00],\n",
       "          [ 5.6937e-04, -1.3400e-01, -1.7555e-01, -1.0502e+00, -2.2006e+00,\n",
       "           -9.3972e+00],\n",
       "          [-2.2305e-02, -1.9003e-01, -9.0724e-01, -3.4598e+00, -1.0494e+00,\n",
       "           -7.0263e+00],\n",
       "          [-1.5381e-04,  1.0132e+00, -5.4454e-01, -3.6532e-01,  4.6133e-01,\n",
       "           -3.3747e+00],\n",
       "          [ 3.9389e-03, -6.2499e-01, -9.6101e-01,  1.3096e+00, -3.6093e+00,\n",
       "           -1.5233e+00],\n",
       "          [-2.1208e-02,  4.1536e-01, -9.1981e-01, -1.1916e-01, -1.5002e+00,\n",
       "           -4.8772e-01]]], device='cuda:0'))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6427054d-5739-497e-8c80-56ba972ffce6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
