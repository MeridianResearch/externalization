{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c46deb1-cd30-4077-9206-801840f9e8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disabled automatic differentiation\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import sys\n",
    "# sys.path.append(\"../../\")\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "# sys.path.append(\"..\")\n",
    "from early_exit.patching.method_patching import replace_attention_layers, set_transformer_early_exit_mode\n",
    "from shared_utils.generate import format_conversation, transform_conversations\n",
    "from early_exit.util import module_name_is_layer_base\n",
    "import numpy as np\n",
    "from early_exit.util import get_model\n",
    "from shared_utils.load import get_tokenizer, configs_from_yaml\n",
    "from shared_utils.generate import generate_text\n",
    "import random\n",
    "from early_exit_teacher.visualization import visualize_tokens_by_exit_layer, create_html_visualization\n",
    "from IPython.display import HTML, display\n",
    "from early_exit.util import module_name_is_layer_base\n",
    "torch.set_grad_enabled(False)\n",
    "print(\"Disabled automatic differentiation\")\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91650b72-36fa-4db2-82ce-63716ca6ae06",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf2996ea-6ffa-4780-ad19-9cc02985f239",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_with_kv_caching(set_early_exit_layer, show_visualization = True, show_df = True):\n",
    "    set_transformer_early_exit_mode(model, 'off')\n",
    "    generated_tokens = []\n",
    "    max_new_tokens = 10\n",
    "    generated = inputs[\"input_ids\"]\n",
    "    chosen_exit_layers = []\n",
    "    all_student_logits = []\n",
    "    all_teacher_logits = []\n",
    "    for step in range(max_new_tokens):  # generate 10 tokens\n",
    "        if step == 0:\n",
    "            student_outputs = model(generated, use_cache=True)\n",
    "            student_logits = student_outputs.logits\n",
    "            student_cache = student_outputs.past_key_values\n",
    "            teacher_outputs = model(generated, use_cache=True)\n",
    "            teacher_cache = teacher_outputs.past_key_values\n",
    "            teacher_logits = teacher_outputs.logits\n",
    "        else:\n",
    "            # Pass only the new token and the cache\n",
    "            student_outputs = model(\n",
    "                next_token,\n",
    "                past_key_values=student_cache,\n",
    "                use_cache=True,\n",
    "                output_hidden_states=True\n",
    "            )\n",
    "            early_exit_layer = set_early_exit_layer(step)\n",
    "            hidden_states = student_outputs.hidden_states\n",
    "            hidden_states = torch.stack(student_outputs.hidden_states)[1:]\n",
    "            student_logits = model.lm_head(hidden_states[early_exit_layer])\n",
    "            all_student_logits.append(student_logits)\n",
    "            student_cache = student_outputs.past_key_values  # updated with new token\n",
    "            # print(len(past_key_values))\n",
    "            for layer in range(early_exit_layer, 28):\n",
    "                student_cache[layer][0][:, :, -1] = student_cache[early_exit_layer][0][:, :, -1] # keys\n",
    "                student_cache[layer][1][:, :, -1] = student_cache[early_exit_layer][1][:, :, -1] # values\n",
    "            # print(len(student_cache), student_cache[0][0].shape)\n",
    "            \n",
    "            teacher_outputs = model(\n",
    "                next_token,\n",
    "                past_key_values=teacher_cache,\n",
    "                use_cache=True\n",
    "            )\n",
    "            teacher_cache = teacher_outputs.past_key_values\n",
    "            teacher_logits = teacher_outputs.logits\n",
    "            all_teacher_logits.append(teacher_logits)\n",
    "        # Take the most likely next token (greedy decoding here)\n",
    "        # next_token = torch.argmax(student_logits[:, -1, :], dim=-1).unsqueeze(-1)\n",
    "        next_token = torch.argmax(teacher_logits[:, -1, :], dim=-1).unsqueeze(-1)\n",
    "        if step > 0: \n",
    "            generated_tokens.append(next_token.item())\n",
    "            chosen_exit_layers.append(early_exit_layer)\n",
    "        else:\n",
    "            generated_tokens.append(next_token.item())\n",
    "            chosen_exit_layers.append(-1)\n",
    "        # Append to generated sequence\n",
    "        generated = torch.cat([generated, next_token], dim=-1)\n",
    "    \n",
    "    # print(tokenizer.decode(generated[0]))\n",
    "    all_student_logits = torch.concatenate(all_student_logits, axis = 0).transpose(0,1)\n",
    "    all_teacher_logits = torch.concatenate(all_teacher_logits, axis = 0).transpose(0,1)\n",
    "    # all_student_logits.shape\n",
    "    tokens = [tokenizer.decode([token]) for token in generated_tokens]\n",
    "    layers = [27 if item == 27 or item == -1 else item for item in chosen_exit_layers]\n",
    "    early_exit_layers = early_exit_layer_idxs.tolist()  # Convert tensor to list if needed\n",
    "    # Display the visualization\n",
    "    if show_visualization: display(visualize_tokens_by_exit_layer(tokens, layers, early_exit_layers, \n",
    "                                         title=\"Committed Early Exit Token Generation\"))\n",
    "    \n",
    "    chosen_exit_layers_tensor = torch.tensor(chosen_exit_layers[1:], device=device).unsqueeze(0).float()\n",
    "    chosen_exit_layers_tensor = torch.where(\n",
    "                        chosen_exit_layers_tensor == 27,\n",
    "                        torch.full_like(chosen_exit_layers_tensor, float('inf')),\n",
    "                        chosen_exit_layers_tensor\n",
    "                    )\n",
    "    repeated_sft_teacher_generated_tokens = generated[:, :-1]\n",
    "    \n",
    "    set_transformer_early_exit_mode(model, 'sft_student')\n",
    "    sft_student_output_scores, collected_exit_logits = model(repeated_sft_teacher_generated_tokens,\\\n",
    "                                                                 prescribed_exit_layer_idxs=chosen_exit_layers_tensor)\n",
    "    \n",
    "    sft_student_output = sft_student_output_scores.logits.squeeze()[20:]\n",
    "    kv_cache_output = all_student_logits.squeeze()\n",
    "    \n",
    "    student_probs = F.softmax(sft_student_output, dim=-1)\n",
    "    teacher_cache_probs = F.softmax(all_teacher_logits.squeeze(), dim=-1)\n",
    "    student_cache_probs = F.softmax(kv_cache_output, dim=-1)\n",
    "    \n",
    "    # model_outputs = model(repeated_sft_teacher_generated_tokens)\n",
    "    # model_probs = F.softmax(model_outputs.logits[0, 20:], dim = -1)\n",
    "    \n",
    "    # set_transformer_early_exit_mode(frozen_model, 'off')\n",
    "    # off_outputs = frozen_model(repeated_sft_teacher_generated_tokens)\n",
    "    # off_probs = F.softmax(off_outputs.logits[0, 20:], dim = -1)\n",
    "    \n",
    "    pd.options.display.float_format = \"{:.2f}\".format\n",
    "    rows = []\n",
    "    \n",
    "    def get_prob_token(probs):\n",
    "        top_id = torch.argmax(probs).item()\n",
    "        top_prob = probs[top_id].item()\n",
    "        top_token = tokenizer.decode([top_id])\n",
    "        return top_prob, top_token\n",
    "    \n",
    "    for idx in range(len(student_probs)):\n",
    "        # Student\n",
    "        student_top_prob, student_top_token = get_prob_token(student_probs[idx])\n",
    "        # teacher_top_prob, teacher_top_token = get_prob_token(teacher_probs[idx])\n",
    "        \n",
    "        student_cache_top_prob, student_cache_top_token = get_prob_token(student_cache_probs[idx])\n",
    "        teacher_cache_top_prob, teacher_cache_top_token = get_prob_token(teacher_cache_probs[idx])\n",
    "    \n",
    "        \n",
    "        # model_top_prob, model_top_token = get_prob_token(model_probs[idx])\n",
    "        \n",
    "        # off_top_prob, off_top_token = get_prob_token(off_probs[idx])\n",
    "    \n",
    "        rows.append({\n",
    "            # \"Position\": idx,\n",
    "            \"Student Token\": student_top_token,\n",
    "            \"Student Prob\": student_top_prob,\n",
    "            # \"Teacher Token\": teacher_top_token,\n",
    "            # \"Teacher Prob\": teacher_top_prob,\n",
    "            \"Student Cache Token\": student_cache_top_token,\n",
    "            \"Student Cache Prob\": student_cache_top_prob,\n",
    "            \"Teacher Cache Token\": teacher_cache_top_token,\n",
    "            \"Teacher Cache Prob\": teacher_cache_top_prob,\n",
    "            # \"Model Token\": model_top_token,\n",
    "            # \"Model Prob\": model_top_prob,\n",
    "            # \"Off Token\": off_top_token,\n",
    "            # \"Off Prob\": off_top_prob\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(rows)\n",
    "    if show_df: display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58ec9da5-fe38-4439-b4a7-91815662007c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\n",
      "Device: cuda\n",
      "address this hack!\n",
      "g++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
      "Copyright (C) 2021 Free Software Foundation, Inc.\n",
      "This is free software; see the source for copying conditions.  There is NO\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
      "\n",
      "trainable params: 2,179,072 || all params: 1,779,276,294 || trainable%: 0.1225\n",
      "Tokenizer loaded. Vocab size: 151643\n",
      "EOS token: <｜end▁of▁sentence｜> (ID: 151643)\n",
      "transform_conversations currently only for Deepseek models!\n"
     ]
    }
   ],
   "source": [
    "# Model configuration\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "\n",
    "print(f\"Loading model: {model_name}\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "tokenizer = get_tokenizer(model_name)\n",
    "model_config_path = \"/project/project_465001340/fair_stuff/externalization/config_deepseek.yaml\"   # args.model_config_path\n",
    "config = configs_from_yaml(model_config_path, tokenizer.eos_token_id)\n",
    "\n",
    "model = get_model(model_name, config['model'], device)\n",
    "model = replace_attention_layers(model, config['lora'], device)\n",
    "# set_transformer_early_exit_mode(model, 'off')\n",
    "\n",
    "# Load tokenizer\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "\n",
    "config['generation']['max_new_tokens'] = 10\n",
    "\n",
    "print(f\"Tokenizer loaded. Vocab size: {tokenizer.vocab_size}\")\n",
    "print(f\"EOS token: {tokenizer.eos_token} (ID: {tokenizer.eos_token_id})\")\n",
    "\n",
    "\n",
    "\n",
    "prompt = \"Explain the concept of recursion in programming.\"\n",
    "system_prompt = \"You are a helpful programming tutor.\"\n",
    "prefiller = \"\"\n",
    "\n",
    "pre_transformed_conversation = format_conversation(user_prompts = [prompt], system_prompt=system_prompt)\n",
    "formatted_prompt = transform_conversations(pre_transformed_conversation, prefiller)[0]\n",
    "inputs = tokenizer(formatted_prompt, return_tensors=\"pt\").to(device)\n",
    "input_ids = inputs.input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cd93364-492d-47ee-8f64-8e4068c9401c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from early_exit.util import module_name_is_layer_base\n",
    "early_exit_layer_idxs = []\n",
    "for name, module in model.named_modules():\n",
    "    if module_name_is_layer_base(name):\n",
    "        layer_idx = int(name.split('.')[-1])\n",
    "        early_exit_layer_idxs.append(layer_idx)\n",
    "\n",
    "early_exit_layer_idxs = torch.tensor(early_exit_layer_idxs, dtype = torch.int32)  # Add inf for final layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa387d7-1e1e-49e6-bcd6-a20eb753937c",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03899711-a256-4542-8aa0-73b071d6d522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student Token</th>\n",
       "      <th>Student Prob</th>\n",
       "      <th>Student Cache Token</th>\n",
       "      <th>Student Cache Prob</th>\n",
       "      <th>Teacher Cache Token</th>\n",
       "      <th>Teacher Cache Prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>,</td>\n",
       "      <td>1.00</td>\n",
       "      <td>,</td>\n",
       "      <td>1.00</td>\n",
       "      <td>,</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>so</td>\n",
       "      <td>0.78</td>\n",
       "      <td>so</td>\n",
       "      <td>0.78</td>\n",
       "      <td>so</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I</td>\n",
       "      <td>0.93</td>\n",
       "      <td>I</td>\n",
       "      <td>0.93</td>\n",
       "      <td>I</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>need</td>\n",
       "      <td>0.65</td>\n",
       "      <td>need</td>\n",
       "      <td>0.65</td>\n",
       "      <td>need</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to</td>\n",
       "      <td>1.00</td>\n",
       "      <td>to</td>\n",
       "      <td>1.00</td>\n",
       "      <td>to</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>explain</td>\n",
       "      <td>0.75</td>\n",
       "      <td>explain</td>\n",
       "      <td>0.75</td>\n",
       "      <td>explain</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>recursion</td>\n",
       "      <td>0.50</td>\n",
       "      <td>recursion</td>\n",
       "      <td>0.50</td>\n",
       "      <td>recursion</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>in</td>\n",
       "      <td>0.98</td>\n",
       "      <td>in</td>\n",
       "      <td>0.98</td>\n",
       "      <td>in</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>programming</td>\n",
       "      <td>1.00</td>\n",
       "      <td>programming</td>\n",
       "      <td>1.00</td>\n",
       "      <td>programming</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Student Token  Student Prob Student Cache Token  Student Cache Prob  \\\n",
       "0             ,          1.00                   ,                1.00   \n",
       "1            so          0.78                  so                0.78   \n",
       "2             I          0.93                   I                0.93   \n",
       "3          need          0.65                need                0.65   \n",
       "4            to          1.00                  to                1.00   \n",
       "5       explain          0.75             explain                0.75   \n",
       "6     recursion          0.50           recursion                0.50   \n",
       "7            in          0.98                  in                0.98   \n",
       "8   programming          1.00         programming                1.00   \n",
       "\n",
       "  Teacher Cache Token  Teacher Cache Prob  \n",
       "0                   ,                1.00  \n",
       "1                  so                0.78  \n",
       "2                   I                0.93  \n",
       "3                need                0.65  \n",
       "4                  to                1.00  \n",
       "5             explain                0.75  \n",
       "6           recursion                0.50  \n",
       "7                  in                0.98  \n",
       "8         programming                1.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def set_early_exit_layer(step):\n",
    "    return 27\n",
    "compare_with_kv_caching(set_early_exit_layer, show_visualization=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84c8f56c-baa2-46c6-bb67-acb1b012b67d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"font-family: Arial, sans-serif; margin: 20px; padding: 20px; \n",
       "                background-color: #f9f9f9; border-radius: 10px;\">\n",
       "        <h3 style=\"text-align: center; color: #333; margin-bottom: 20px;\">Committed Early Exit Token Generation</h3>\n",
       "        \n",
       "        <!-- Legend -->\n",
       "        <div style=\"display: flex; justify-content: center; gap: 15px; \n",
       "                    margin: 20px 0; padding: 15px; background-color: #fff; \n",
       "                    border-radius: 5px; flex-wrap: wrap; border: 1px solid #ddd;\">\n",
       "    \n",
       "                <div style=\"display: flex; align-items: center; gap: 8px;\">\n",
       "                    <div style=\"width: 25px; height: 15px; background-color: #6f91f2; \n",
       "                                border: 1px solid #333; border-radius: 3px;\"></div>\n",
       "                    <span style=\"font-size: 14px;\">Layer 25</span>\n",
       "                </div>\n",
       "            \n",
       "                <div style=\"display: flex; align-items: center; gap: 8px;\">\n",
       "                    <div style=\"width: 25px; height: 15px; background-color: #3a4cc0; \n",
       "                                border: 1px solid #333; border-radius: 3px;\"></div>\n",
       "                    <span style=\"font-size: 14px;\">Final Layer</span>\n",
       "                </div>\n",
       "            \n",
       "        </div>\n",
       "        \n",
       "        <!-- Tokens -->\n",
       "        <div style=\"line-height: 2.5; word-wrap: break-word; padding: 15px; \n",
       "                    background-color: #fff; border-radius: 5px; border: 1px solid #ddd;\">\n",
       "    <span style=\"display: inline-block; padding: 4px 8px; margin: 2px; \n",
       "                                      border-radius: 4px; border: 1px solid #666; \n",
       "                                      font-family: monospace; font-size: 13px; \n",
       "                                      background-color: #3a4cc0; color: white; \n",
       "                                      font-weight: bold; max-width: 200px; \n",
       "                                      overflow-wrap: break-word; vertical-align: middle;\">Okay</span><span style=\"display: inline-block; padding: 4px 8px; margin: 2px; \n",
       "                                      border-radius: 4px; border: 1px solid #666; \n",
       "                                      font-family: monospace; font-size: 13px; \n",
       "                                      background-color: #3a4cc0; color: white; \n",
       "                                      font-weight: bold; max-width: 200px; \n",
       "                                      overflow-wrap: break-word; vertical-align: middle;\">,</span><span style=\"display: inline-block; padding: 4px 8px; margin: 2px; \n",
       "                                      border-radius: 4px; border: 1px solid #666; \n",
       "                                      font-family: monospace; font-size: 13px; \n",
       "                                      background-color: #6f91f2; color: black; \n",
       "                                      font-weight: bold; max-width: 200px; \n",
       "                                      overflow-wrap: break-word; vertical-align: middle;\"> so</span><span style=\"display: inline-block; padding: 4px 8px; margin: 2px; \n",
       "                                      border-radius: 4px; border: 1px solid #666; \n",
       "                                      font-family: monospace; font-size: 13px; \n",
       "                                      background-color: #3a4cc0; color: white; \n",
       "                                      font-weight: bold; max-width: 200px; \n",
       "                                      overflow-wrap: break-word; vertical-align: middle;\"> I</span><span style=\"display: inline-block; padding: 4px 8px; margin: 2px; \n",
       "                                      border-radius: 4px; border: 1px solid #666; \n",
       "                                      font-family: monospace; font-size: 13px; \n",
       "                                      background-color: #3a4cc0; color: white; \n",
       "                                      font-weight: bold; max-width: 200px; \n",
       "                                      overflow-wrap: break-word; vertical-align: middle;\"> need</span><span style=\"display: inline-block; padding: 4px 8px; margin: 2px; \n",
       "                                      border-radius: 4px; border: 1px solid #666; \n",
       "                                      font-family: monospace; font-size: 13px; \n",
       "                                      background-color: #3a4cc0; color: white; \n",
       "                                      font-weight: bold; max-width: 200px; \n",
       "                                      overflow-wrap: break-word; vertical-align: middle;\"> to</span><span style=\"display: inline-block; padding: 4px 8px; margin: 2px; \n",
       "                                      border-radius: 4px; border: 1px solid #666; \n",
       "                                      font-family: monospace; font-size: 13px; \n",
       "                                      background-color: #3a4cc0; color: white; \n",
       "                                      font-weight: bold; max-width: 200px; \n",
       "                                      overflow-wrap: break-word; vertical-align: middle;\"> explain</span><span style=\"display: inline-block; padding: 4px 8px; margin: 2px; \n",
       "                                      border-radius: 4px; border: 1px solid #666; \n",
       "                                      font-family: monospace; font-size: 13px; \n",
       "                                      background-color: #3a4cc0; color: white; \n",
       "                                      font-weight: bold; max-width: 200px; \n",
       "                                      overflow-wrap: break-word; vertical-align: middle;\"> recursion</span><span style=\"display: inline-block; padding: 4px 8px; margin: 2px; \n",
       "                                      border-radius: 4px; border: 1px solid #666; \n",
       "                                      font-family: monospace; font-size: 13px; \n",
       "                                      background-color: #3a4cc0; color: white; \n",
       "                                      font-weight: bold; max-width: 200px; \n",
       "                                      overflow-wrap: break-word; vertical-align: middle;\"> in</span><span style=\"display: inline-block; padding: 4px 8px; margin: 2px; \n",
       "                                      border-radius: 4px; border: 1px solid #666; \n",
       "                                      font-family: monospace; font-size: 13px; \n",
       "                                      background-color: #3a4cc0; color: white; \n",
       "                                      font-weight: bold; max-width: 200px; \n",
       "                                      overflow-wrap: break-word; vertical-align: middle;\"> programming</span>\n",
       "        </div>\n",
       "        \n",
       "        <!-- Statistics -->\n",
       "        <div style=\"margin-top: 15px; padding: 10px; background-color: #e8f4fd; \n",
       "                    border-radius: 5px; font-family: monospace; font-size: 13px;\">\n",
       "    Total tokens: 10 | Layer 25: 1 (10.0%) | Final: 9 (90.0%)\n",
       "        </div>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student Token</th>\n",
       "      <th>Student Prob</th>\n",
       "      <th>Student Cache Token</th>\n",
       "      <th>Student Cache Prob</th>\n",
       "      <th>Teacher Cache Token</th>\n",
       "      <th>Teacher Cache Prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>,</td>\n",
       "      <td>1.00</td>\n",
       "      <td>,</td>\n",
       "      <td>1.00</td>\n",
       "      <td>,</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>so</td>\n",
       "      <td>0.99</td>\n",
       "      <td>so</td>\n",
       "      <td>1.00</td>\n",
       "      <td>so</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Helvetica</td>\n",
       "      <td>0.01</td>\n",
       "      <td>I</td>\n",
       "      <td>0.92</td>\n",
       "      <td>I</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>一定程度</td>\n",
       "      <td>0.01</td>\n",
       "      <td>need</td>\n",
       "      <td>0.64</td>\n",
       "      <td>need</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>transparent</td>\n",
       "      <td>0.03</td>\n",
       "      <td>to</td>\n",
       "      <td>1.00</td>\n",
       "      <td>to</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lay</td>\n",
       "      <td>0.01</td>\n",
       "      <td>explain</td>\n",
       "      <td>0.74</td>\n",
       "      <td>explain</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>enses</td>\n",
       "      <td>0.01</td>\n",
       "      <td>recursion</td>\n",
       "      <td>0.50</td>\n",
       "      <td>recursion</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Helvetica</td>\n",
       "      <td>0.00</td>\n",
       "      <td>in</td>\n",
       "      <td>0.98</td>\n",
       "      <td>in</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>incoming</td>\n",
       "      <td>0.06</td>\n",
       "      <td>programming</td>\n",
       "      <td>1.00</td>\n",
       "      <td>programming</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Student Token  Student Prob Student Cache Token  Student Cache Prob  \\\n",
       "0             ,          1.00                   ,                1.00   \n",
       "1            so          0.99                  so                1.00   \n",
       "2     Helvetica          0.01                   I                0.92   \n",
       "3          一定程度          0.01                need                0.64   \n",
       "4   transparent          0.03                  to                1.00   \n",
       "5           lay          0.01             explain                0.74   \n",
       "6         enses          0.01           recursion                0.50   \n",
       "7     Helvetica          0.00                  in                0.98   \n",
       "8      incoming          0.06         programming                1.00   \n",
       "\n",
       "  Teacher Cache Token  Teacher Cache Prob  \n",
       "0                   ,                1.00  \n",
       "1                  so                0.78  \n",
       "2                   I                0.93  \n",
       "3                need                0.65  \n",
       "4                  to                1.00  \n",
       "5             explain                0.75  \n",
       "6           recursion                0.50  \n",
       "7                  in                0.98  \n",
       "8         programming                1.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def set_early_exit_layer(step):\n",
    "    if step == 2: return 25\n",
    "    return 27\n",
    "compare_with_kv_caching(set_early_exit_layer, show_visualization=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e16f412-32b5-4a2d-8eec-f25acfa8efe6",
   "metadata": {},
   "source": [
    "### Some fishy behaviour in the hidden states when exit is set to inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23d27864-8808-4e4c-acc2-30443a2bc22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transform_conversations currently only for Deepseek models!\n",
      "full_tokenize currently only for Deepseek models!\n",
      "prompt tokens shape: torch.Size([1, 20])\n"
     ]
    }
   ],
   "source": [
    "set_transformer_early_exit_mode(model, 'sft_teacher')\n",
    "sft_teacher_response, (sft_teacher_generated_tokens, \n",
    "                          sft_teacher_final_layer_logprobs, \n",
    "                          gathered_early_exit_hidden_states) = generate_text(\n",
    "        model=model,\n",
    "        prompt=prompt,\n",
    "        system_prompt=system_prompt,\n",
    "        prefiller=prefiller,\n",
    "        tokenizer=tokenizer,\n",
    "        generation_config=config['generation'],\n",
    "        device=device\n",
    "    )\n",
    "repeated_sft_teacher_generated_tokens = sft_teacher_generated_tokens[:, :-1] # Removing the last token to match the log probs and hidden states shape\n",
    "chosen_exit_layers_tensor = torch.inf * torch.ones([1,9])\n",
    "set_transformer_early_exit_mode(model, 'off')\n",
    "model_outputs = model(repeated_sft_teacher_generated_tokens, output_hidden_states = True)\n",
    "set_transformer_early_exit_mode(model, 'sft_student')\n",
    "student_outputs = model(repeated_sft_teacher_generated_tokens, prescribed_exit_layer_idxs = chosen_exit_layers_tensor, output_hidden_states = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e94ad7cb-e23b-4a90-80d3-c2394ac69e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(T1,T2):\n",
    "    if (T1 == T2).all().item():\n",
    "        print(\"Input tensors are equal\")\n",
    "    else:\n",
    "        print(\"Input tensors are NOT equal\")\n",
    "        print(f\"Tensor 1 shape = {T1.shape}\")\n",
    "        print(f\"Tensor 1 sum = {T1.sum().item():.2f}\")\n",
    "        print(f\"Tensor 2 sum = {T2.sum().item():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0023a63b-246f-430a-b234-bc3b45d3c0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensors are equal\n"
     ]
    }
   ],
   "source": [
    "compare(student_outputs[0].logits, model_outputs.logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a631c815-0d9a-40d7-bf4d-738815ad36d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensors are equal\n"
     ]
    }
   ],
   "source": [
    "layer_idx = -1\n",
    "compare(student_outputs[0].hidden_states[layer_idx], model_outputs.hidden_states[layer_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f0b4af14-3f14-4fe9-8ee7-7e069972ea5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensors are NOT equal\n",
      "Tensor 1 shape = torch.Size([1, 29, 1536])\n",
      "Tensor 1 sum = 71.16\n",
      "Tensor 2 sum = 1184.38\n"
     ]
    }
   ],
   "source": [
    "layer_idx = -2\n",
    "compare(student_outputs[0].hidden_states[layer_idx], model_outputs.hidden_states[layer_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "480addc0-81fa-49a4-b6af-2bb67c6a8ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensors are NOT equal\n",
      "Tensor 1 shape = torch.Size([1, 29, 1536])\n",
      "Tensor 1 sum = 144.88\n",
      "Tensor 2 sum = 11.01\n"
     ]
    }
   ],
   "source": [
    "layer_idx = 0\n",
    "compare(student_outputs[0].hidden_states[layer_idx], model_outputs.hidden_states[layer_idx])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
