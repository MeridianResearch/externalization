{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aad93460-32b2-4881-a92a-4ab1a11cefb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replacing layer model.layers.0\n",
      "replacing layer model.layers.1\n",
      "replacing layer model.layers.2\n",
      "replacing layer model.layers.3\n",
      "replacing layer model.layers.4\n",
      "replacing layer model.layers.5\n",
      "replacing layer model.layers.6\n",
      "replacing layer model.layers.7\n",
      "replacing layer model.layers.8\n",
      "replacing layer model.layers.9\n",
      "replacing layer model.layers.10\n",
      "replacing layer model.layers.11\n",
      "replacing layer model.layers.12\n",
      "replacing layer model.layers.13\n",
      "replacing layer model.layers.14\n",
      "replacing layer model.layers.15\n",
      "replacing layer model.layers.16\n",
      "replacing layer model.layers.17\n",
      "replacing layer model.layers.18\n",
      "replacing layer model.layers.19\n",
      "replacing layer model.layers.20\n",
      "replacing layer model.layers.21\n",
      "replacing layer model.layers.22\n",
      "replacing layer model.layers.23\n",
      "replacing layer model.layers.24\n",
      "replacing layer model.layers.25\n",
      "replacing layer model.layers.26\n",
      "replacing layer model.layers.27\n",
      "address this hack!\n",
      "g++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
      "Copyright (C) 2021 Free Software Foundation, Inc.\n",
      "This is free software; see the source for copying conditions.  There is NO\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
      "\n",
      "trainable params: 2,179,072 || all params: 1,779,310,108 || trainable%: 0.1225\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from shared_utils.data import CSVPromptDataset\n",
    "from shared_utils.load import get_model, get_tokenizer, configs_from_yaml\n",
    "from shared_utils.generate import generate_text\n",
    "\n",
    "from early_exit.patching import replace_attention_layers, set_transformer_early_exit_mode\n",
    "\n",
    "import wandb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# LOAD IN EXPERIMENT ARGS\n",
    "# num_epoch = 1                     # args.num_epoch\n",
    "num_exit_samples = 1                  # args.num_exit_samples\n",
    "device = \"cuda\"                    # args.device\n",
    "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"                    # args.model_name\n",
    "model_config_path = \"../config_deepseek.yaml\"                     # args.model_config_path\n",
    "dataset_path = \"../results_and_data/early_exit_sft_dataset/test/data.csv\"                  # args.dataset_path\n",
    "prompt_config_path = \"../results_and_data/early_exit_sft_dataset/test/prompt_config.json\"                    # args.prompt_config_path\n",
    "batch_size = 1                    # args.batch_size -- might want to sort out batching, but increasing num_exit_samples might be better + less effort\n",
    "\n",
    "# LOAD IN THE MODEL AND TOKENIZER\n",
    "tokenizer = get_tokenizer(model_name)\n",
    "config = configs_from_yaml(model_config_path, tokenizer.eos_token_id)\n",
    "config['generation']['use_cache'] = False\n",
    "model = get_model(model_name, config['model'], device)\n",
    "base_model = get_model(model_name, config['model'], device)\n",
    "\n",
    "# ENABLE EARLY EXITING\n",
    "model = replace_attention_layers(model, config['lora'], device)\n",
    "\n",
    "set_transformer_early_exit_mode(model, 'free_generate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1db34b0-a866-43bf-bde2-fc0946ad8c9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transform_conversations currently only for Deepseek models!\n",
      "full_tokenize currently only for Deepseek models!\n",
      "prompt tokens shape: torch.Size([1, 20])\n",
      "Layer 0 called in free_generate mode with L = 20\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(13.8386, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(13.8386, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(142.1584, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 20, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(339.7139, device='cuda:0')\n",
      "Residual states sum =  tensor(142.1584, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(13.8386, device='cuda:0')\n",
      "Hidden states sum =  tensor(517.9693, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 1 called in free_generate mode with L = 20\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(517.9693, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(517.9693, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(115.2190, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 20, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(351.3582, device='cuda:0')\n",
      "Residual states sum =  tensor(115.2190, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(517.9693, device='cuda:0')\n",
      "Hidden states sum =  tensor(1632.5952, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 2 called in free_generate mode with L = 20\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(1632.5952, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(1632.5952, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(191.0783, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 20, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-54.5179, device='cuda:0')\n",
      "Residual states sum =  tensor(191.0783, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(1632.5952, device='cuda:0')\n",
      "Hidden states sum =  tensor(5988.6357, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 3 called in free_generate mode with L = 20\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(5988.6357, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(5988.6357, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(171.1255, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 20, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-423.5580, device='cuda:0')\n",
      "Residual states sum =  tensor(171.1255, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(5988.6357, device='cuda:0')\n",
      "Hidden states sum =  tensor(-3716.4697, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 4 called in free_generate mode with L = 20\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-3716.4697, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-3716.4697, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-235.8696, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 20, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1182.0616, device='cuda:0')\n",
      "Residual states sum =  tensor(-235.8696, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-3716.4697, device='cuda:0')\n",
      "Hidden states sum =  tensor(-8703.4385, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 5 called in free_generate mode with L = 20\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-8703.4385, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-8703.4385, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-815.7844, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 20, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-731.9587, device='cuda:0')\n",
      "Residual states sum =  tensor(-815.7844, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-8703.4385, device='cuda:0')\n",
      "Hidden states sum =  tensor(-28089.2539, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 6 called in free_generate mode with L = 20\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-28089.2539, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-28089.2539, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-457.2437, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 20, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1828.6060, device='cuda:0')\n",
      "Residual states sum =  tensor(-457.2437, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-28089.2539, device='cuda:0')\n",
      "Hidden states sum =  tensor(2281.8179, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 7 called in free_generate mode with L = 20\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(2281.8179, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(2281.8179, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-61.9338, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 20, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(325.3164, device='cuda:0')\n",
      "Residual states sum =  tensor(-61.9338, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(2281.8179, device='cuda:0')\n",
      "Hidden states sum =  tensor(3092.1675, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 8 called in free_generate mode with L = 20\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(3092.1675, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(3092.1675, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(203.7206, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 20, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(726.8759, device='cuda:0')\n",
      "Residual states sum =  tensor(203.7206, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(3092.1675, device='cuda:0')\n",
      "Hidden states sum =  tensor(2378.1580, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 9 called in free_generate mode with L = 20\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(2378.1580, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(2378.1580, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(211.6278, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 20, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(265.7718, device='cuda:0')\n",
      "Residual states sum =  tensor(211.6278, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(2378.1580, device='cuda:0')\n",
      "Hidden states sum =  tensor(-483.3735, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 10 called in free_generate mode with L = 20\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-483.3735, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-483.3735, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-121.3577, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 20, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(839.2294, device='cuda:0')\n",
      "Residual states sum =  tensor(-121.3577, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-483.3735, device='cuda:0')\n",
      "Hidden states sum =  tensor(9202.7520, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 11 called in free_generate mode with L = 20\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(9202.7520, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(9202.7520, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1486.2660, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 20, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1569.0905, device='cuda:0')\n",
      "Residual states sum =  tensor(1486.2660, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(9202.7520, device='cuda:0')\n",
      "Hidden states sum =  tensor(-4232.6992, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 12 called in free_generate mode with L = 20\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-4232.6992, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-4232.6992, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-457.6927, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 20, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-170.8519, device='cuda:0')\n",
      "Residual states sum =  tensor(-457.6927, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-4232.6992, device='cuda:0')\n",
      "Hidden states sum =  tensor(-1894.5652, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 13 called in free_generate mode with L = 20\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-1894.5652, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-1894.5652, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-172.4378, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 20, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1286.5638, device='cuda:0')\n",
      "Residual states sum =  tensor(-172.4378, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-1894.5652, device='cuda:0')\n",
      "Hidden states sum =  tensor(4003.6235, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 14 called in free_generate mode with L = 20\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(4003.6235, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(4003.6235, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(738.6761, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 20, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(3358.1960, device='cuda:0')\n",
      "Residual states sum =  tensor(738.6761, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(4003.6235, device='cuda:0')\n",
      "Hidden states sum =  tensor(2370.6143, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 15 called in free_generate mode with L = 20\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(2370.6143, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(2370.6143, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(589.5104, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 20, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-3106.2598, device='cuda:0')\n",
      "Residual states sum =  tensor(589.5104, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(2370.6143, device='cuda:0')\n",
      "Hidden states sum =  tensor(4557.0869, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 16 called in free_generate mode with L = 20\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(4557.0869, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(4557.0869, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(596.3895, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 20, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-5185.7622, device='cuda:0')\n",
      "Residual states sum =  tensor(596.3895, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(4557.0869, device='cuda:0')\n",
      "Hidden states sum =  tensor(-11861.1748, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 17 called in free_generate mode with L = 20\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-11861.1748, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-11861.1748, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-581.3384, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 20, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(3444.5864, device='cuda:0')\n",
      "Residual states sum =  tensor(-581.3384, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-11861.1748, device='cuda:0')\n",
      "Hidden states sum =  tensor(38579.1094, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 18 called in free_generate mode with L = 20\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(38579.1094, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(38579.1094, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1199.7628, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 20, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(33.3241, device='cuda:0')\n",
      "Residual states sum =  tensor(1199.7628, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(38579.1094, device='cuda:0')\n",
      "Hidden states sum =  tensor(-7905.0337, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 19 called in free_generate mode with L = 20\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-7905.0337, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-7905.0337, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-389.4237, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 20, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1055.6450, device='cuda:0')\n",
      "Residual states sum =  tensor(-389.4237, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-7905.0337, device='cuda:0')\n",
      "Hidden states sum =  tensor(-7693.4912, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 20 called in free_generate mode with L = 20\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-7693.4912, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-7693.4912, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-118.8980, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 20, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(215.3046, device='cuda:0')\n",
      "Residual states sum =  tensor(-118.8980, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-7693.4912, device='cuda:0')\n",
      "Hidden states sum =  tensor(3312.3184, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 21 called in free_generate mode with L = 20\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(3312.3184, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(3312.3184, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-70.0303, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 20, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(3154.0801, device='cuda:0')\n",
      "Residual states sum =  tensor(-70.0303, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(3312.3184, device='cuda:0')\n",
      "Hidden states sum =  tensor(-3141.7495, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 22 called in free_generate mode with L = 20\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-3141.7495, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-3141.7495, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-20.1407, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 20, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1590.3306, device='cuda:0')\n",
      "Residual states sum =  tensor(-20.1407, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-3141.7495, device='cuda:0')\n",
      "Hidden states sum =  tensor(1278.5542, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 23 called in free_generate mode with L = 20\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(1278.5542, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(1278.5542, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(171.5604, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 20, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1793.7059, device='cuda:0')\n",
      "Residual states sum =  tensor(171.5604, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(1278.5542, device='cuda:0')\n",
      "Hidden states sum =  tensor(14175.4756, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 24 called in free_generate mode with L = 20\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(14175.4756, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(14175.4756, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(481.2532, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 20, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1126.8768, device='cuda:0')\n",
      "Residual states sum =  tensor(481.2532, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(14175.4756, device='cuda:0')\n",
      "Hidden states sum =  tensor(-7597.9053, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 25 called in free_generate mode with L = 20\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-7597.9053, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-7597.9053, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-452.7793, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 20, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2104.9543, device='cuda:0')\n",
      "Residual states sum =  tensor(-452.7793, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-7597.9053, device='cuda:0')\n",
      "Hidden states sum =  tensor(-3264.4773, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 26 called in free_generate mode with L = 20\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-3264.4773, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-3264.4773, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-24.2660, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 20, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(5190.7734, device='cuda:0')\n",
      "Residual states sum =  tensor(-24.2660, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-3264.4773, device='cuda:0')\n",
      "Hidden states sum =  tensor(6564.7256, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 27 called in free_generate mode with L = 20\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(6564.7256, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(6564.7256, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-75.0443, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 20, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(8761.9912, device='cuda:0')\n",
      "Residual states sum =  tensor(-75.0443, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(6564.7256, device='cuda:0')\n",
      "Hidden states sum =  tensor(-5809.2490, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 0 called in free_generate mode with L = 21\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(13.6524, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(13.6524, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(132.0171, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 21, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(337.4263, device='cuda:0')\n",
      "Residual states sum =  tensor(132.0171, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(13.6524, device='cuda:0')\n",
      "Hidden states sum =  tensor(495.2191, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 1 called in free_generate mode with L = 21\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(495.2191, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(495.2191, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(115.2499, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 21, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(358.6299, device='cuda:0')\n",
      "Residual states sum =  tensor(115.2499, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(495.2191, device='cuda:0')\n",
      "Hidden states sum =  tensor(1604.3008, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 2 called in free_generate mode with L = 21\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(1604.3008, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(1604.3008, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(174.7612, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 21, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-91.8816, device='cuda:0')\n",
      "Residual states sum =  tensor(174.7612, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(1604.3008, device='cuda:0')\n",
      "Hidden states sum =  tensor(5868.4224, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 3 called in free_generate mode with L = 21\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(5868.4224, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(5868.4224, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(164.2148, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 21, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-444.5739, device='cuda:0')\n",
      "Residual states sum =  tensor(164.2148, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(5868.4224, device='cuda:0')\n",
      "Hidden states sum =  tensor(-3927.1465, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 4 called in free_generate mode with L = 21\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-3927.1465, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-3927.1465, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-248.4793, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 21, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1232.1577, device='cuda:0')\n",
      "Residual states sum =  tensor(-248.4793, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-3927.1465, device='cuda:0')\n",
      "Hidden states sum =  tensor(-9030.7832, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 5 called in free_generate mode with L = 21\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-9030.7832, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-9030.7832, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-847.7651, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 21, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-755.9034, device='cuda:0')\n",
      "Residual states sum =  tensor(-847.7651, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-9030.7832, device='cuda:0')\n",
      "Hidden states sum =  tensor(-29219.9082, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 6 called in free_generate mode with L = 21\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-29219.9082, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-29219.9082, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-476.5251, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 21, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1912.9391, device='cuda:0')\n",
      "Residual states sum =  tensor(-476.5251, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-29219.9082, device='cuda:0')\n",
      "Hidden states sum =  tensor(2381.1501, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 7 called in free_generate mode with L = 21\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(2381.1501, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(2381.1501, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-64.2585, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 21, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(342.1657, device='cuda:0')\n",
      "Residual states sum =  tensor(-64.2585, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(2381.1501, device='cuda:0')\n",
      "Hidden states sum =  tensor(3237.9653, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 8 called in free_generate mode with L = 21\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(3237.9653, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(3237.9653, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(212.8393, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 21, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(762.8668, device='cuda:0')\n",
      "Residual states sum =  tensor(212.8393, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(3237.9653, device='cuda:0')\n",
      "Hidden states sum =  tensor(2493.3018, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 9 called in free_generate mode with L = 21\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(2493.3018, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(2493.3018, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(222.1174, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 21, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(271.6426, device='cuda:0')\n",
      "Residual states sum =  tensor(222.1174, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(2493.3018, device='cuda:0')\n",
      "Hidden states sum =  tensor(-516.2512, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 10 called in free_generate mode with L = 21\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-516.2512, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-516.2512, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-131.4320, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 21, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(886.5980, device='cuda:0')\n",
      "Residual states sum =  tensor(-131.4320, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-516.2512, device='cuda:0')\n",
      "Hidden states sum =  tensor(9661.7188, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 11 called in free_generate mode with L = 21\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(9661.7188, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(9661.7188, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1559.7708, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 21, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1649.7112, device='cuda:0')\n",
      "Residual states sum =  tensor(1559.7708, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(9661.7188, device='cuda:0')\n",
      "Hidden states sum =  tensor(-4436.4780, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 12 called in free_generate mode with L = 21\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-4436.4780, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-4436.4780, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-479.3760, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 21, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-179.5327, device='cuda:0')\n",
      "Residual states sum =  tensor(-479.3760, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-4436.4780, device='cuda:0')\n",
      "Hidden states sum =  tensor(-1983.3236, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 13 called in free_generate mode with L = 21\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-1983.3236, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-1983.3236, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-180.5257, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 21, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1351.2454, device='cuda:0')\n",
      "Residual states sum =  tensor(-180.5257, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-1983.3236, device='cuda:0')\n",
      "Hidden states sum =  tensor(4202.3516, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 14 called in free_generate mode with L = 21\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(4202.3516, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(4202.3516, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(775.5141, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 21, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(3525.9937, device='cuda:0')\n",
      "Residual states sum =  tensor(775.5141, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(4202.3516, device='cuda:0')\n",
      "Hidden states sum =  tensor(2489.9121, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 15 called in free_generate mode with L = 21\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(2489.9121, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(2489.9121, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(618.9979, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 21, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-3262.0022, device='cuda:0')\n",
      "Residual states sum =  tensor(618.9979, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(2489.9121, device='cuda:0')\n",
      "Hidden states sum =  tensor(4783.5361, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 16 called in free_generate mode with L = 21\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(4783.5361, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(4783.5361, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(626.0343, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 21, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-5444.8896, device='cuda:0')\n",
      "Residual states sum =  tensor(626.0343, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(4783.5361, device='cuda:0')\n",
      "Hidden states sum =  tensor(-12455.7637, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 17 called in free_generate mode with L = 21\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-12455.7637, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-12455.7637, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-610.4722, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 21, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(3616.8269, device='cuda:0')\n",
      "Residual states sum =  tensor(-610.4722, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-12455.7637, device='cuda:0')\n",
      "Hidden states sum =  tensor(40508.3125, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 18 called in free_generate mode with L = 21\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(40508.3125, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(40508.3125, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1259.7578, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 21, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(34.9995, device='cuda:0')\n",
      "Residual states sum =  tensor(1259.7578, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(40508.3125, device='cuda:0')\n",
      "Hidden states sum =  tensor(-8300.3760, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 19 called in free_generate mode with L = 21\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-8300.3760, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-8300.3760, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-408.9009, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 21, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1108.4307, device='cuda:0')\n",
      "Residual states sum =  tensor(-408.9009, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-8300.3760, device='cuda:0')\n",
      "Hidden states sum =  tensor(-8078.1567, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 20 called in free_generate mode with L = 21\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-8078.1567, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-8078.1567, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-124.8452, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 21, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(226.0731, device='cuda:0')\n",
      "Residual states sum =  tensor(-124.8452, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-8078.1567, device='cuda:0')\n",
      "Hidden states sum =  tensor(3477.9485, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 21 called in free_generate mode with L = 21\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(3477.9485, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(3477.9485, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-73.5311, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 21, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(3311.7849, device='cuda:0')\n",
      "Residual states sum =  tensor(-73.5311, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(3477.9485, device='cuda:0')\n",
      "Hidden states sum =  tensor(-3298.8374, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 22 called in free_generate mode with L = 21\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-3298.8374, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-3298.8374, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-21.1478, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 21, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1669.8474, device='cuda:0')\n",
      "Residual states sum =  tensor(-21.1478, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-3298.8374, device='cuda:0')\n",
      "Hidden states sum =  tensor(1342.4805, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 23 called in free_generate mode with L = 21\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(1342.4805, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(1342.4805, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(180.1384, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 21, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1883.3918, device='cuda:0')\n",
      "Residual states sum =  tensor(180.1384, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(1342.4805, device='cuda:0')\n",
      "Hidden states sum =  tensor(14884.2480, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 24 called in free_generate mode with L = 21\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(14884.2480, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(14884.2480, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(505.3157, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 21, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1183.2208, device='cuda:0')\n",
      "Residual states sum =  tensor(505.3157, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(14884.2480, device='cuda:0')\n",
      "Hidden states sum =  tensor(-7977.8008, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 25 called in free_generate mode with L = 21\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-7977.8008, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-7977.8008, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-475.4183, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 21, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2210.2021, device='cuda:0')\n",
      "Residual states sum =  tensor(-475.4183, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-7977.8008, device='cuda:0')\n",
      "Hidden states sum =  tensor(-3427.6990, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 26 called in free_generate mode with L = 21\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-3427.6990, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-3427.6990, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-25.4792, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 21, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(5450.3125, device='cuda:0')\n",
      "Residual states sum =  tensor(-25.4792, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-3427.6990, device='cuda:0')\n",
      "Hidden states sum =  tensor(6892.9619, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 27 called in free_generate mode with L = 21\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(6892.9619, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(6892.9619, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-78.7966, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 21, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(9200.0918, device='cuda:0')\n",
      "Residual states sum =  tensor(-78.7966, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(6892.9619, device='cuda:0')\n",
      "Hidden states sum =  tensor(-6099.7109, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 0 called in free_generate mode with L = 22\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(12.7199, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(12.7199, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(127.0387, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 22, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(326.3284, device='cuda:0')\n",
      "Residual states sum =  tensor(127.0387, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(12.7199, device='cuda:0')\n",
      "Hidden states sum =  tensor(450.6089, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 1 called in free_generate mode with L = 22\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(450.6089, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(450.6089, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(106.7297, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 22, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(365.7418, device='cuda:0')\n",
      "Residual states sum =  tensor(106.7297, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(450.6089, device='cuda:0')\n",
      "Hidden states sum =  tensor(1594.7881, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 2 called in free_generate mode with L = 22\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(1594.7881, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(1594.7881, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(173.3477, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 22, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-22.6454, device='cuda:0')\n",
      "Residual states sum =  tensor(173.3477, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(1594.7881, device='cuda:0')\n",
      "Hidden states sum =  tensor(6581.3564, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 3 called in free_generate mode with L = 22\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(6581.3564, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(6581.3564, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(190.0313, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 22, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-464.5509, device='cuda:0')\n",
      "Residual states sum =  tensor(190.0313, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(6581.3564, device='cuda:0')\n",
      "Hidden states sum =  tensor(-4252.9692, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 4 called in free_generate mode with L = 22\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-4252.9692, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-4252.9692, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-264.6678, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 22, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1286.6177, device='cuda:0')\n",
      "Residual states sum =  tensor(-264.6678, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-4252.9692, device='cuda:0')\n",
      "Hidden states sum =  tensor(-9404.0215, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 5 called in free_generate mode with L = 22\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-9404.0215, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-9404.0215, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-882.2579, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 22, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-781.9697, device='cuda:0')\n",
      "Residual states sum =  tensor(-882.2579, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-9404.0215, device='cuda:0')\n",
      "Hidden states sum =  tensor(-30348.0059, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 6 called in free_generate mode with L = 22\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-30348.0059, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-30348.0059, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-495.6613, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 22, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1996.5472, device='cuda:0')\n",
      "Residual states sum =  tensor(-495.6613, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-30348.0059, device='cuda:0')\n",
      "Hidden states sum =  tensor(2471.6802, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 7 called in free_generate mode with L = 22\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(2471.6802, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(2471.6802, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-67.0251, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 22, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(358.6203, device='cuda:0')\n",
      "Residual states sum =  tensor(-67.0251, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(2471.6802, device='cuda:0')\n",
      "Hidden states sum =  tensor(3385.3193, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 8 called in free_generate mode with L = 22\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(3385.3193, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(3385.3193, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(222.3487, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 22, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(798.7061, device='cuda:0')\n",
      "Residual states sum =  tensor(222.3487, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(3385.3193, device='cuda:0')\n",
      "Hidden states sum =  tensor(2611.4043, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 9 called in free_generate mode with L = 22\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(2611.4043, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(2611.4043, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(232.9559, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 22, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(276.6627, device='cuda:0')\n",
      "Residual states sum =  tensor(232.9559, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(2611.4043, device='cuda:0')\n",
      "Hidden states sum =  tensor(-551.3906, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 10 called in free_generate mode with L = 22\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-551.3906, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-551.3906, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-141.8325, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 22, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(934.5659, device='cuda:0')\n",
      "Residual states sum =  tensor(-141.8325, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-551.3906, device='cuda:0')\n",
      "Hidden states sum =  tensor(10120.0107, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 11 called in free_generate mode with L = 22\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(10120.0107, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(10120.0107, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1633.1664, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 22, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1730.6191, device='cuda:0')\n",
      "Residual states sum =  tensor(1633.1664, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(10120.0107, device='cuda:0')\n",
      "Hidden states sum =  tensor(-4639.0195, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 12 called in free_generate mode with L = 22\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-4639.0195, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-4639.0195, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-500.9006, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 22, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-188.1802, device='cuda:0')\n",
      "Residual states sum =  tensor(-500.9006, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-4639.0195, device='cuda:0')\n",
      "Hidden states sum =  tensor(-2071.5872, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 13 called in free_generate mode with L = 22\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-2071.5872, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-2071.5872, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-188.5986, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 22, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1416.0134, device='cuda:0')\n",
      "Residual states sum =  tensor(-188.5986, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-2071.5872, device='cuda:0')\n",
      "Hidden states sum =  tensor(4400.8560, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 14 called in free_generate mode with L = 22\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(4400.8560, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(4400.8560, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(812.3503, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 22, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(3693.8533, device='cuda:0')\n",
      "Residual states sum =  tensor(812.3503, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(4400.8560, device='cuda:0')\n",
      "Hidden states sum =  tensor(2609.4451, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 15 called in free_generate mode with L = 22\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(2609.4451, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(2609.4451, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(648.4883, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 22, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-3417.8176, device='cuda:0')\n",
      "Residual states sum =  tensor(648.4883, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(2609.4451, device='cuda:0')\n",
      "Hidden states sum =  tensor(5009.4551, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 16 called in free_generate mode with L = 22\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(5009.4551, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(5009.4551, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(655.6357, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 22, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-5703.9951, device='cuda:0')\n",
      "Residual states sum =  tensor(655.6357, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(5009.4551, device='cuda:0')\n",
      "Hidden states sum =  tensor(-13050.4395, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 17 called in free_generate mode with L = 22\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-13050.4395, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-13050.4395, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-639.6091, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 22, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(3789.0698, device='cuda:0')\n",
      "Residual states sum =  tensor(-639.6091, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-13050.4395, device='cuda:0')\n",
      "Hidden states sum =  tensor(42437.5234, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 18 called in free_generate mode with L = 22\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(42437.5234, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(42437.5234, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1319.7517, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 22, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(36.6751, device='cuda:0')\n",
      "Residual states sum =  tensor(1319.7517, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(42437.5234, device='cuda:0')\n",
      "Hidden states sum =  tensor(-8695.7305, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 19 called in free_generate mode with L = 22\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-8695.7305, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-8695.7305, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-428.3783, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 22, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1161.2175, device='cuda:0')\n",
      "Residual states sum =  tensor(-428.3783, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-8695.7305, device='cuda:0')\n",
      "Hidden states sum =  tensor(-8462.8252, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 20 called in free_generate mode with L = 22\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-8462.8252, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-8462.8252, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-130.7924, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 22, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(236.8425, device='cuda:0')\n",
      "Residual states sum =  tensor(-130.7924, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-8462.8252, device='cuda:0')\n",
      "Hidden states sum =  tensor(3643.5881, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 21 called in free_generate mode with L = 22\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(3643.5881, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(3643.5881, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-77.0319, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 22, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(3469.4885, device='cuda:0')\n",
      "Residual states sum =  tensor(-77.0319, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(3643.5881, device='cuda:0')\n",
      "Hidden states sum =  tensor(-3455.9248, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 22 called in free_generate mode with L = 22\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-3455.9248, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-3455.9248, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-22.1548, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 22, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1749.3643, device='cuda:0')\n",
      "Residual states sum =  tensor(-22.1548, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-3455.9248, device='cuda:0')\n",
      "Hidden states sum =  tensor(1406.4053, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 23 called in free_generate mode with L = 22\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(1406.4053, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(1406.4053, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(188.7163, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 22, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1973.0774, device='cuda:0')\n",
      "Residual states sum =  tensor(188.7163, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(1406.4053, device='cuda:0')\n",
      "Hidden states sum =  tensor(15593.0195, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 24 called in free_generate mode with L = 22\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(15593.0195, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(15593.0195, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(529.3784, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 22, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1239.5649, device='cuda:0')\n",
      "Residual states sum =  tensor(529.3784, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(15593.0195, device='cuda:0')\n",
      "Hidden states sum =  tensor(-8357.6943, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 25 called in free_generate mode with L = 22\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-8357.6943, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-8357.6943, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-498.0573, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 22, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2315.4502, device='cuda:0')\n",
      "Residual states sum =  tensor(-498.0573, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-8357.6943, device='cuda:0')\n",
      "Hidden states sum =  tensor(-3590.9233, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 26 called in free_generate mode with L = 22\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-3590.9233, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-3590.9233, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-26.6925, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 22, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(5709.8511, device='cuda:0')\n",
      "Residual states sum =  tensor(-26.6925, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-3590.9233, device='cuda:0')\n",
      "Hidden states sum =  tensor(7221.1992, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 27 called in free_generate mode with L = 22\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(7221.1992, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(7221.1992, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-82.5488, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 22, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(9638.1895, device='cuda:0')\n",
      "Residual states sum =  tensor(-82.5488, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(7221.1992, device='cuda:0')\n",
      "Hidden states sum =  tensor(-6390.1748, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 0 called in free_generate mode with L = 23\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(13.2936, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(13.2936, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(123.9361, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 23, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(339.5831, device='cuda:0')\n",
      "Residual states sum =  tensor(123.9361, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(13.2936, device='cuda:0')\n",
      "Hidden states sum =  tensor(479.8104, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 1 called in free_generate mode with L = 23\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(479.8104, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(479.8104, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(117.0967, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 23, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(371.2179, device='cuda:0')\n",
      "Residual states sum =  tensor(117.0967, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(479.8104, device='cuda:0')\n",
      "Hidden states sum =  tensor(1543.8750, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 2 called in free_generate mode with L = 23\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(1543.8750, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(1543.8750, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(157.1604, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 23, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(5.8222, device='cuda:0')\n",
      "Residual states sum =  tensor(157.1604, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(1543.8750, device='cuda:0')\n",
      "Hidden states sum =  tensor(6919.5254, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 3 called in free_generate mode with L = 23\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(6919.5254, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(6919.5254, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(201.4079, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 23, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-474.7020, device='cuda:0')\n",
      "Residual states sum =  tensor(201.4079, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(6919.5254, device='cuda:0')\n",
      "Hidden states sum =  tensor(-4756.2627, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 4 called in free_generate mode with L = 23\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-4756.2627, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-4756.2627, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-295.6068, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 23, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1338.2325, device='cuda:0')\n",
      "Residual states sum =  tensor(-295.6068, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-4756.2627, device='cuda:0')\n",
      "Hidden states sum =  tensor(-9738.8857, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 5 called in free_generate mode with L = 23\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-9738.8857, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-9738.8857, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-913.1074, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 23, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-806.6184, device='cuda:0')\n",
      "Residual states sum =  tensor(-913.1074, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-9738.8857, device='cuda:0')\n",
      "Hidden states sum =  tensor(-31448.2188, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 6 called in free_generate mode with L = 23\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-31448.2188, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-31448.2188, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-514.5979, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 23, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2079.6318, device='cuda:0')\n",
      "Residual states sum =  tensor(-514.5979, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-31448.2188, device='cuda:0')\n",
      "Hidden states sum =  tensor(2558.0518, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 7 called in free_generate mode with L = 23\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(2558.0518, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(2558.0518, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-69.9838, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 23, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(375.2732, device='cuda:0')\n",
      "Residual states sum =  tensor(-69.9838, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(2558.0518, device='cuda:0')\n",
      "Hidden states sum =  tensor(3535.7925, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 8 called in free_generate mode with L = 23\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(3535.7925, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(3535.7925, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(232.4172, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 23, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(834.3573, device='cuda:0')\n",
      "Residual states sum =  tensor(232.4172, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(3535.7925, device='cuda:0')\n",
      "Hidden states sum =  tensor(2733.6497, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 9 called in free_generate mode with L = 23\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(2733.6497, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(2733.6497, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(244.1954, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 23, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(280.9185, device='cuda:0')\n",
      "Residual states sum =  tensor(244.1954, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(2733.6497, device='cuda:0')\n",
      "Hidden states sum =  tensor(-588.4622, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 10 called in free_generate mode with L = 23\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-588.4622, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-588.4622, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-152.5661, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 23, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(983.2102, device='cuda:0')\n",
      "Residual states sum =  tensor(-152.5661, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-588.4622, device='cuda:0')\n",
      "Hidden states sum =  tensor(10576.9785, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 11 called in free_generate mode with L = 23\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(10576.9785, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(10576.9785, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1706.4136, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 23, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1811.8560, device='cuda:0')\n",
      "Residual states sum =  tensor(1706.4136, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(10576.9785, device='cuda:0')\n",
      "Hidden states sum =  tensor(-4840.3672, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 12 called in free_generate mode with L = 23\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-4840.3672, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-4840.3672, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-522.2832, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 23, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-196.7761, device='cuda:0')\n",
      "Residual states sum =  tensor(-522.2832, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-4840.3672, device='cuda:0')\n",
      "Hidden states sum =  tensor(-2159.3149, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 13 called in free_generate mode with L = 23\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-2159.3149, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-2159.3149, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-196.6504, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 23, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1480.8887, device='cuda:0')\n",
      "Residual states sum =  tensor(-196.6504, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-2159.3149, device='cuda:0')\n",
      "Hidden states sum =  tensor(4599.3081, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 14 called in free_generate mode with L = 23\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(4599.3081, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(4599.3081, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(849.2153, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 23, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(3861.8127, device='cuda:0')\n",
      "Residual states sum =  tensor(849.2153, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(4599.3081, device='cuda:0')\n",
      "Hidden states sum =  tensor(2729.1648, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 15 called in free_generate mode with L = 23\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(2729.1648, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(2729.1648, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(677.9738, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 23, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-3573.7056, device='cuda:0')\n",
      "Residual states sum =  tensor(677.9738, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(2729.1648, device='cuda:0')\n",
      "Hidden states sum =  tensor(5234.6709, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 16 called in free_generate mode with L = 23\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(5234.6709, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(5234.6709, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(685.1851, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 23, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-5963.0791, device='cuda:0')\n",
      "Residual states sum =  tensor(685.1851, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(5234.6709, device='cuda:0')\n",
      "Hidden states sum =  tensor(-13645.1719, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 17 called in free_generate mode with L = 23\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-13645.1719, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-13645.1719, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-668.7487, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 23, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(3961.3140, device='cuda:0')\n",
      "Residual states sum =  tensor(-668.7487, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-13645.1719, device='cuda:0')\n",
      "Hidden states sum =  tensor(44366.7461, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 18 called in free_generate mode with L = 23\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(44366.7461, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(44366.7461, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1379.7449, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 23, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(38.3506, device='cuda:0')\n",
      "Residual states sum =  tensor(1379.7449, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(44366.7461, device='cuda:0')\n",
      "Hidden states sum =  tensor(-9091.0967, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 19 called in free_generate mode with L = 23\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-9091.0967, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-9091.0967, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-447.8563, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 23, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1214.0067, device='cuda:0')\n",
      "Residual states sum =  tensor(-447.8563, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-9091.0967, device='cuda:0')\n",
      "Hidden states sum =  tensor(-8847.4971, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 20 called in free_generate mode with L = 23\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-8847.4971, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-8847.4971, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-136.7396, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 23, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(247.6122, device='cuda:0')\n",
      "Residual states sum =  tensor(-136.7396, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-8847.4971, device='cuda:0')\n",
      "Hidden states sum =  tensor(3809.2217, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 21 called in free_generate mode with L = 23\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(3809.2217, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(3809.2217, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-80.5326, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 23, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(3627.1934, device='cuda:0')\n",
      "Residual states sum =  tensor(-80.5326, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(3809.2217, device='cuda:0')\n",
      "Hidden states sum =  tensor(-3613.0129, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 22 called in free_generate mode with L = 23\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-3613.0129, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-3613.0129, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-23.1619, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 23, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1828.8812, device='cuda:0')\n",
      "Residual states sum =  tensor(-23.1619, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-3613.0129, device='cuda:0')\n",
      "Hidden states sum =  tensor(1470.3311, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 23 called in free_generate mode with L = 23\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(1470.3311, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(1470.3311, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(197.2942, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 23, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2062.7629, device='cuda:0')\n",
      "Residual states sum =  tensor(197.2942, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(1470.3311, device='cuda:0')\n",
      "Hidden states sum =  tensor(16301.7910, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 24 called in free_generate mode with L = 23\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(16301.7910, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(16301.7910, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(553.4410, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 23, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1295.9089, device='cuda:0')\n",
      "Residual states sum =  tensor(553.4410, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(16301.7910, device='cuda:0')\n",
      "Hidden states sum =  tensor(-8737.5898, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 25 called in free_generate mode with L = 23\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-8737.5898, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-8737.5898, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-520.6962, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 23, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2420.6980, device='cuda:0')\n",
      "Residual states sum =  tensor(-520.6962, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-8737.5898, device='cuda:0')\n",
      "Hidden states sum =  tensor(-3754.1460, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 26 called in free_generate mode with L = 23\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-3754.1460, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-3754.1460, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-27.9058, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 23, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(5969.3896, device='cuda:0')\n",
      "Residual states sum =  tensor(-27.9058, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-3754.1460, device='cuda:0')\n",
      "Hidden states sum =  tensor(7549.4351, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 27 called in free_generate mode with L = 23\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(7549.4351, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(7549.4351, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-86.3009, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 23, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(10076.2852, device='cuda:0')\n",
      "Residual states sum =  tensor(-86.3009, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(7549.4351, device='cuda:0')\n",
      "Hidden states sum =  tensor(-6680.6382, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 0 called in free_generate mode with L = 24\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(13.1075, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(13.1075, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(113.7948, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 24, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(330.4979, device='cuda:0')\n",
      "Residual states sum =  tensor(113.7948, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(13.1075, device='cuda:0')\n",
      "Hidden states sum =  tensor(439.9502, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 1 called in free_generate mode with L = 24\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(439.9502, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(439.9502, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(114.0837, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 24, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(368.0204, device='cuda:0')\n",
      "Residual states sum =  tensor(114.0837, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(439.9502, device='cuda:0')\n",
      "Hidden states sum =  tensor(1495.5378, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 2 called in free_generate mode with L = 24\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(1495.5378, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(1495.5378, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(137.3578, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 24, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-17.2069, device='cuda:0')\n",
      "Residual states sum =  tensor(137.3578, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(1495.5378, device='cuda:0')\n",
      "Hidden states sum =  tensor(7244.5830, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 3 called in free_generate mode with L = 24\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(7244.5830, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(7244.5830, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(210.2431, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 24, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-477.4667, device='cuda:0')\n",
      "Residual states sum =  tensor(210.2431, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(7244.5830, device='cuda:0')\n",
      "Hidden states sum =  tensor(-5066.9062, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 4 called in free_generate mode with L = 24\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-5066.9062, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-5066.9062, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-319.3672, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 24, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1386.9703, device='cuda:0')\n",
      "Residual states sum =  tensor(-319.3672, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-5066.9062, device='cuda:0')\n",
      "Hidden states sum =  tensor(-10052.0254, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 5 called in free_generate mode with L = 24\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-10052.0254, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-10052.0254, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-941.9261, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 24, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-829.2003, device='cuda:0')\n",
      "Residual states sum =  tensor(-941.9261, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-10052.0254, device='cuda:0')\n",
      "Hidden states sum =  tensor(-32516.4102, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 6 called in free_generate mode with L = 24\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-32516.4102, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-32516.4102, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-533.6663, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 24, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2162.3364, device='cuda:0')\n",
      "Residual states sum =  tensor(-533.6663, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-32516.4102, device='cuda:0')\n",
      "Hidden states sum =  tensor(2642.7971, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 7 called in free_generate mode with L = 24\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(2642.7971, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(2642.7971, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-73.0467, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 24, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(392.3500, device='cuda:0')\n",
      "Residual states sum =  tensor(-73.0467, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(2642.7971, device='cuda:0')\n",
      "Hidden states sum =  tensor(3690.3037, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 8 called in free_generate mode with L = 24\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(3690.3037, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(3690.3037, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(243.0854, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 24, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(869.7964, device='cuda:0')\n",
      "Residual states sum =  tensor(243.0854, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(3690.3037, device='cuda:0')\n",
      "Hidden states sum =  tensor(2858.2407, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 9 called in free_generate mode with L = 24\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(2858.2407, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(2858.2407, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(255.5994, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 24, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(284.4766, device='cuda:0')\n",
      "Residual states sum =  tensor(255.5994, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(2858.2407, device='cuda:0')\n",
      "Hidden states sum =  tensor(-625.8459, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 10 called in free_generate mode with L = 24\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-625.8459, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-625.8459, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-163.5004, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 24, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1032.4390, device='cuda:0')\n",
      "Residual states sum =  tensor(-163.5004, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-625.8459, device='cuda:0')\n",
      "Hidden states sum =  tensor(11032.1680, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 11 called in free_generate mode with L = 24\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(11032.1680, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(11032.1680, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1779.5128, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 24, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1893.4421, device='cuda:0')\n",
      "Residual states sum =  tensor(1779.5128, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(11032.1680, device='cuda:0')\n",
      "Hidden states sum =  tensor(-5040.5796, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 12 called in free_generate mode with L = 24\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-5040.5796, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-5040.5796, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-543.5237, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 24, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-205.3116, device='cuda:0')\n",
      "Residual states sum =  tensor(-543.5237, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-5040.5796, device='cuda:0')\n",
      "Hidden states sum =  tensor(-2246.3835, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 13 called in free_generate mode with L = 24\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-2246.3835, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-2246.3835, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-204.6620, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 24, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1545.9125, device='cuda:0')\n",
      "Residual states sum =  tensor(-204.6620, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-2246.3835, device='cuda:0')\n",
      "Hidden states sum =  tensor(4798.0488, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 14 called in free_generate mode with L = 24\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(4798.0488, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(4798.0488, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(886.1570, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 24, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(4029.9133, device='cuda:0')\n",
      "Residual states sum =  tensor(886.1570, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(4798.0488, device='cuda:0')\n",
      "Hidden states sum =  tensor(2848.9849, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 15 called in free_generate mode with L = 24\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(2848.9849, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(2848.9849, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(707.4474, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 24, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-3729.6709, device='cuda:0')\n",
      "Residual states sum =  tensor(707.4474, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(2848.9849, device='cuda:0')\n",
      "Hidden states sum =  tensor(5459.0527, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 16 called in free_generate mode with L = 24\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(5459.0527, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(5459.0527, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(714.6771, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 24, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-6222.1396, device='cuda:0')\n",
      "Residual states sum =  tensor(714.6771, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(5459.0527, device='cuda:0')\n",
      "Hidden states sum =  tensor(-14239.9619, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 17 called in free_generate mode with L = 24\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-14239.9619, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-14239.9619, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-697.8911, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 24, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(4133.5610, device='cuda:0')\n",
      "Residual states sum =  tensor(-697.8911, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-14239.9619, device='cuda:0')\n",
      "Hidden states sum =  tensor(46295.9844, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 18 called in free_generate mode with L = 24\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(46295.9844, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(46295.9844, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1439.7368, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 24, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(40.0272, device='cuda:0')\n",
      "Residual states sum =  tensor(1439.7368, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(46295.9844, device='cuda:0')\n",
      "Hidden states sum =  tensor(-9486.4746, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 19 called in free_generate mode with L = 24\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-9486.4746, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-9486.4746, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-467.3344, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 24, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1266.7981, device='cuda:0')\n",
      "Residual states sum =  tensor(-467.3344, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-9486.4746, device='cuda:0')\n",
      "Hidden states sum =  tensor(-9232.1699, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 20 called in free_generate mode with L = 24\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-9232.1699, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-9232.1699, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-142.6865, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 24, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(258.3823, device='cuda:0')\n",
      "Residual states sum =  tensor(-142.6865, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-9232.1699, device='cuda:0')\n",
      "Hidden states sum =  tensor(3974.8604, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 21 called in free_generate mode with L = 24\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(3974.8604, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(3974.8604, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-84.0332, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 24, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(3784.8977, device='cuda:0')\n",
      "Residual states sum =  tensor(-84.0332, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(3974.8604, device='cuda:0')\n",
      "Hidden states sum =  tensor(-3770.1001, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 22 called in free_generate mode with L = 24\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-3770.1001, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-3770.1001, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-24.1689, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 24, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1908.3983, device='cuda:0')\n",
      "Residual states sum =  tensor(-24.1689, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-3770.1001, device='cuda:0')\n",
      "Hidden states sum =  tensor(1534.2559, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 23 called in free_generate mode with L = 24\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(1534.2559, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(1534.2559, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(205.8721, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 24, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2152.4490, device='cuda:0')\n",
      "Residual states sum =  tensor(205.8721, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(1534.2559, device='cuda:0')\n",
      "Hidden states sum =  tensor(17010.5645, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 24 called in free_generate mode with L = 24\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(17010.5645, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(17010.5645, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(577.5037, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 24, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1352.2531, device='cuda:0')\n",
      "Residual states sum =  tensor(577.5037, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(17010.5645, device='cuda:0')\n",
      "Hidden states sum =  tensor(-9117.4844, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 25 called in free_generate mode with L = 24\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-9117.4844, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-9117.4844, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-543.3351, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 24, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2525.9453, device='cuda:0')\n",
      "Residual states sum =  tensor(-543.3351, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-9117.4844, device='cuda:0')\n",
      "Hidden states sum =  tensor(-3917.3711, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 26 called in free_generate mode with L = 24\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-3917.3711, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-3917.3711, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-29.1192, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 24, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(6228.9282, device='cuda:0')\n",
      "Residual states sum =  tensor(-29.1192, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-3917.3711, device='cuda:0')\n",
      "Hidden states sum =  tensor(7877.6729, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 27 called in free_generate mode with L = 24\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(7877.6729, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(7877.6729, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-90.0531, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 24, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(10514.3867, device='cuda:0')\n",
      "Residual states sum =  tensor(-90.0531, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(7877.6729, device='cuda:0')\n",
      "Hidden states sum =  tensor(-6971.1016, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 0 called in free_generate mode with L = 25\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(13.6812, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(13.6812, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(110.6922, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 25, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(346.2578, device='cuda:0')\n",
      "Residual states sum =  tensor(110.6922, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(13.6812, device='cuda:0')\n",
      "Hidden states sum =  tensor(464.7670, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 1 called in free_generate mode with L = 25\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(464.7670, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(464.7670, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(121.8266, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 25, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(350.6037, device='cuda:0')\n",
      "Residual states sum =  tensor(121.8266, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(464.7670, device='cuda:0')\n",
      "Hidden states sum =  tensor(1469.5454, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 2 called in free_generate mode with L = 25\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(1469.5454, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(1469.5454, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(120.8589, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 25, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(28.6697, device='cuda:0')\n",
      "Residual states sum =  tensor(120.8589, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(1469.5454, device='cuda:0')\n",
      "Hidden states sum =  tensor(7805.8652, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 3 called in free_generate mode with L = 25\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(7805.8652, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(7805.8652, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(221.8288, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 25, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-480.3643, device='cuda:0')\n",
      "Residual states sum =  tensor(221.8288, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(7805.8652, device='cuda:0')\n",
      "Hidden states sum =  tensor(-5321.5957, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 4 called in free_generate mode with L = 25\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-5321.5957, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-5321.5957, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-334.5070, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 25, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1438.7861, device='cuda:0')\n",
      "Residual states sum =  tensor(-334.5070, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-5321.5957, device='cuda:0')\n",
      "Hidden states sum =  tensor(-10461.9219, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 5 called in free_generate mode with L = 25\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-10461.9219, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-10461.9219, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-980.0959, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 25, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-849.6872, device='cuda:0')\n",
      "Residual states sum =  tensor(-980.0959, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-10461.9219, device='cuda:0')\n",
      "Hidden states sum =  tensor(-33681.7812, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 6 called in free_generate mode with L = 25\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-33681.7812, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-33681.7812, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-554.1196, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 25, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2244.0825, device='cuda:0')\n",
      "Residual states sum =  tensor(-554.1196, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-33681.7812, device='cuda:0')\n",
      "Hidden states sum =  tensor(2727.3647, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 7 called in free_generate mode with L = 25\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(2727.3647, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(2727.3647, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-75.9401, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 25, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(409.9372, device='cuda:0')\n",
      "Residual states sum =  tensor(-75.9401, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(2727.3647, device='cuda:0')\n",
      "Hidden states sum =  tensor(3848.5928, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 8 called in free_generate mode with L = 25\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(3848.5928, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(3848.5928, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(254.3236, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 25, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(904.8344, device='cuda:0')\n",
      "Residual states sum =  tensor(254.3236, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(3848.5928, device='cuda:0')\n",
      "Hidden states sum =  tensor(2984.1064, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 9 called in free_generate mode with L = 25\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(2984.1064, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(2984.1064, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(267.0840, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 25, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(287.3539, device='cuda:0')\n",
      "Residual states sum =  tensor(267.0840, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(2984.1064, device='cuda:0')\n",
      "Hidden states sum =  tensor(-662.3904, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 10 called in free_generate mode with L = 25\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-662.3904, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-662.3904, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-174.5385, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 25, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1082.2407, device='cuda:0')\n",
      "Residual states sum =  tensor(-174.5385, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-662.3904, device='cuda:0')\n",
      "Hidden states sum =  tensor(11485.4922, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 11 called in free_generate mode with L = 25\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(11485.4922, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(11485.4922, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1852.4614, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 25, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1975.3290, device='cuda:0')\n",
      "Residual states sum =  tensor(1852.4614, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(11485.4922, device='cuda:0')\n",
      "Hidden states sum =  tensor(-5239.4575, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 12 called in free_generate mode with L = 25\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-5239.4575, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-5239.4575, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-564.5948, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 25, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-213.7845, device='cuda:0')\n",
      "Residual states sum =  tensor(-564.5948, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-5239.4575, device='cuda:0')\n",
      "Hidden states sum =  tensor(-2332.8052, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 13 called in free_generate mode with L = 25\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-2332.8052, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-2332.8052, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-212.6294, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 25, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1611.1309, device='cuda:0')\n",
      "Residual states sum =  tensor(-212.6294, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-2332.8052, device='cuda:0')\n",
      "Hidden states sum =  tensor(4997.4233, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 14 called in free_generate mode with L = 25\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(4997.4233, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(4997.4233, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(923.2170, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 25, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(4198.1865, device='cuda:0')\n",
      "Residual states sum =  tensor(923.2170, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(4997.4233, device='cuda:0')\n",
      "Hidden states sum =  tensor(2968.8279, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 15 called in free_generate mode with L = 25\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(2968.8279, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(2968.8279, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(736.9087, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 25, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-3885.7354, device='cuda:0')\n",
      "Residual states sum =  tensor(736.9087, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(2968.8279, device='cuda:0')\n",
      "Hidden states sum =  tensor(5682.5410, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 16 called in free_generate mode with L = 25\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(5682.5410, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(5682.5410, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(744.1115, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 25, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-6481.1724, device='cuda:0')\n",
      "Residual states sum =  tensor(744.1115, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(5682.5410, device='cuda:0')\n",
      "Hidden states sum =  tensor(-14834.8281, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 17 called in free_generate mode with L = 25\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-14834.8281, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-14834.8281, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-727.0356, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 25, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(4305.8130, device='cuda:0')\n",
      "Residual states sum =  tensor(-727.0356, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-14834.8281, device='cuda:0')\n",
      "Hidden states sum =  tensor(48225.2344, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 18 called in free_generate mode with L = 25\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(48225.2344, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(48225.2344, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1499.7273, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 25, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(41.7037, device='cuda:0')\n",
      "Residual states sum =  tensor(1499.7273, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(48225.2344, device='cuda:0')\n",
      "Hidden states sum =  tensor(-9881.8672, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 19 called in free_generate mode with L = 25\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-9881.8672, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-9881.8672, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-486.8129, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 25, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1319.5918, device='cuda:0')\n",
      "Residual states sum =  tensor(-486.8129, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-9881.8672, device='cuda:0')\n",
      "Hidden states sum =  tensor(-9616.8506, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 20 called in free_generate mode with L = 25\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-9616.8506, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-9616.8506, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-148.6337, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 25, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(269.1509, device='cuda:0')\n",
      "Residual states sum =  tensor(-148.6337, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-9616.8506, device='cuda:0')\n",
      "Hidden states sum =  tensor(4140.5000, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 21 called in free_generate mode with L = 25\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(4140.5000, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(4140.5000, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-87.5337, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 25, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(3942.6025, device='cuda:0')\n",
      "Residual states sum =  tensor(-87.5337, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(4140.5000, device='cuda:0')\n",
      "Hidden states sum =  tensor(-3927.1895, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 22 called in free_generate mode with L = 25\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-3927.1895, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-3927.1895, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-25.1759, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 25, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1987.9153, device='cuda:0')\n",
      "Residual states sum =  tensor(-25.1759, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-3927.1895, device='cuda:0')\n",
      "Hidden states sum =  tensor(1598.1816, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 23 called in free_generate mode with L = 25\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(1598.1816, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(1598.1816, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(214.4501, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 25, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2242.1340, device='cuda:0')\n",
      "Residual states sum =  tensor(214.4501, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(1598.1816, device='cuda:0')\n",
      "Hidden states sum =  tensor(17719.3359, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 24 called in free_generate mode with L = 25\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(17719.3359, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(17719.3359, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(601.5662, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 25, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1408.5974, device='cuda:0')\n",
      "Residual states sum =  tensor(601.5662, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(17719.3359, device='cuda:0')\n",
      "Hidden states sum =  tensor(-9497.3789, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 25 called in free_generate mode with L = 25\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-9497.3789, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-9497.3789, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-565.9741, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 25, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2631.1934, device='cuda:0')\n",
      "Residual states sum =  tensor(-565.9741, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-9497.3789, device='cuda:0')\n",
      "Hidden states sum =  tensor(-4080.5955, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 26 called in free_generate mode with L = 25\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-4080.5955, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-4080.5955, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-30.3325, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 25, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(6488.4658, device='cuda:0')\n",
      "Residual states sum =  tensor(-30.3325, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-4080.5955, device='cuda:0')\n",
      "Hidden states sum =  tensor(8205.9092, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 27 called in free_generate mode with L = 25\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(8205.9092, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(8205.9092, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-93.8051, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 25, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(10952.4863, device='cuda:0')\n",
      "Residual states sum =  tensor(-93.8051, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(8205.9092, device='cuda:0')\n",
      "Hidden states sum =  tensor(-7261.5630, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 0 called in free_generate mode with L = 26\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(13.1206, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(13.1206, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(108.5690, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 26, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(363.6409, device='cuda:0')\n",
      "Residual states sum =  tensor(108.5690, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(13.1206, device='cuda:0')\n",
      "Hidden states sum =  tensor(504.1283, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 1 called in free_generate mode with L = 26\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(504.1283, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(504.1283, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(132.5946, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 26, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(369.3982, device='cuda:0')\n",
      "Residual states sum =  tensor(132.5946, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(504.1283, device='cuda:0')\n",
      "Hidden states sum =  tensor(1447.0430, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 2 called in free_generate mode with L = 26\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(1447.0430, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(1447.0430, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(106.6562, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 26, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-17.5679, device='cuda:0')\n",
      "Residual states sum =  tensor(106.6562, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(1447.0430, device='cuda:0')\n",
      "Hidden states sum =  tensor(8168.7598, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 3 called in free_generate mode with L = 26\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(8168.7598, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(8168.7598, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(226.9846, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 26, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-488.5952, device='cuda:0')\n",
      "Residual states sum =  tensor(226.9846, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(8168.7598, device='cuda:0')\n",
      "Hidden states sum =  tensor(-5553.1387, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 4 called in free_generate mode with L = 26\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-5553.1387, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-5553.1387, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-346.0400, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 26, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1489.6118, device='cuda:0')\n",
      "Residual states sum =  tensor(-346.0400, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-5553.1387, device='cuda:0')\n",
      "Hidden states sum =  tensor(-10841.1826, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 5 called in free_generate mode with L = 26\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-10841.1826, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-10841.1826, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1012.6011, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 26, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-872.6941, device='cuda:0')\n",
      "Residual states sum =  tensor(-1012.6011, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-10841.1826, device='cuda:0')\n",
      "Hidden states sum =  tensor(-34815.6992, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 6 called in free_generate mode with L = 26\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-34815.6992, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-34815.6992, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-573.7794, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 26, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2324.7349, device='cuda:0')\n",
      "Residual states sum =  tensor(-573.7794, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-34815.6992, device='cuda:0')\n",
      "Hidden states sum =  tensor(2814.5195, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 7 called in free_generate mode with L = 26\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(2814.5195, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(2814.5195, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-78.5159, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 26, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(427.7166, device='cuda:0')\n",
      "Residual states sum =  tensor(-78.5159, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(2814.5195, device='cuda:0')\n",
      "Hidden states sum =  tensor(4008.3171, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 8 called in free_generate mode with L = 26\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(4008.3171, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(4008.3171, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(265.8484, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 26, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(939.3014, device='cuda:0')\n",
      "Residual states sum =  tensor(265.8484, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(4008.3171, device='cuda:0')\n",
      "Hidden states sum =  tensor(3109.1152, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 9 called in free_generate mode with L = 26\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(3109.1152, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(3109.1152, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(278.3914, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 26, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(289.5382, device='cuda:0')\n",
      "Residual states sum =  tensor(278.3914, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(3109.1152, device='cuda:0')\n",
      "Hidden states sum =  tensor(-698.0015, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 10 called in free_generate mode with L = 26\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-698.0015, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-698.0015, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-185.6423, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 26, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1132.6466, device='cuda:0')\n",
      "Residual states sum =  tensor(-185.6423, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-698.0015, device='cuda:0')\n",
      "Hidden states sum =  tensor(11937.6943, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 11 called in free_generate mode with L = 26\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(11937.6943, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(11937.6943, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1925.3392, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 26, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2057.5120, device='cuda:0')\n",
      "Residual states sum =  tensor(1925.3392, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(11937.6943, device='cuda:0')\n",
      "Hidden states sum =  tensor(-5436.8145, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 12 called in free_generate mode with L = 26\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-5436.8145, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-5436.8145, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-585.4778, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 26, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-222.1964, device='cuda:0')\n",
      "Residual states sum =  tensor(-585.4778, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-5436.8145, device='cuda:0')\n",
      "Hidden states sum =  tensor(-2418.6619, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 13 called in free_generate mode with L = 26\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-2418.6619, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-2418.6619, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-220.5628, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 26, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1676.5970, device='cuda:0')\n",
      "Residual states sum =  tensor(-220.5628, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-2418.6619, device='cuda:0')\n",
      "Hidden states sum =  tensor(5197.6509, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 14 called in free_generate mode with L = 26\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(5197.6509, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(5197.6509, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(960.4144, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 26, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(4366.6445, device='cuda:0')\n",
      "Residual states sum =  tensor(960.4144, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(5197.6509, device='cuda:0')\n",
      "Hidden states sum =  tensor(3088.5784, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 15 called in free_generate mode with L = 26\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(3088.5784, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(3088.5784, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(766.3507, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 26, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-4041.9233, device='cuda:0')\n",
      "Residual states sum =  tensor(766.3507, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(3088.5784, device='cuda:0')\n",
      "Hidden states sum =  tensor(5905.1196, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 16 called in free_generate mode with L = 26\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(5905.1196, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(5905.1196, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(773.4905, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 26, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-6740.1748, device='cuda:0')\n",
      "Residual states sum =  tensor(773.4905, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(5905.1196, device='cuda:0')\n",
      "Hidden states sum =  tensor(-15429.7812, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 17 called in free_generate mode with L = 26\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-15429.7812, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-15429.7812, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-756.1827, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 26, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(4478.0718, device='cuda:0')\n",
      "Residual states sum =  tensor(-756.1827, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-15429.7812, device='cuda:0')\n",
      "Hidden states sum =  tensor(50154.5078, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 18 called in free_generate mode with L = 26\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(50154.5078, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(50154.5078, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1559.7161, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 26, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(43.3814, device='cuda:0')\n",
      "Residual states sum =  tensor(1559.7161, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(50154.5078, device='cuda:0')\n",
      "Hidden states sum =  tensor(-10277.2715, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 19 called in free_generate mode with L = 26\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-10277.2715, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-10277.2715, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-506.2918, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 26, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1372.3868, device='cuda:0')\n",
      "Residual states sum =  tensor(-506.2918, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-10277.2715, device='cuda:0')\n",
      "Hidden states sum =  tensor(-10001.5352, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 20 called in free_generate mode with L = 26\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-10001.5352, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-10001.5352, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-154.5809, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 26, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(279.9201, device='cuda:0')\n",
      "Residual states sum =  tensor(-154.5809, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-10001.5352, device='cuda:0')\n",
      "Hidden states sum =  tensor(4306.1475, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 21 called in free_generate mode with L = 26\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(4306.1475, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(4306.1475, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-91.0341, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 26, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(4100.3071, device='cuda:0')\n",
      "Residual states sum =  tensor(-91.0341, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(4306.1475, device='cuda:0')\n",
      "Hidden states sum =  tensor(-4084.2769, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 22 called in free_generate mode with L = 26\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-4084.2769, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-4084.2769, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-26.1829, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 26, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2067.4321, device='cuda:0')\n",
      "Residual states sum =  tensor(-26.1829, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-4084.2769, device='cuda:0')\n",
      "Hidden states sum =  tensor(1662.1074, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 23 called in free_generate mode with L = 26\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(1662.1074, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(1662.1074, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(223.0280, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 26, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2331.8203, device='cuda:0')\n",
      "Residual states sum =  tensor(223.0280, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(1662.1074, device='cuda:0')\n",
      "Hidden states sum =  tensor(18428.1094, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 24 called in free_generate mode with L = 26\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(18428.1094, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(18428.1094, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(625.6288, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 26, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1464.9421, device='cuda:0')\n",
      "Residual states sum =  tensor(625.6288, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(18428.1094, device='cuda:0')\n",
      "Hidden states sum =  tensor(-9877.2734, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 25 called in free_generate mode with L = 26\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-9877.2734, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-9877.2734, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-588.6129, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 26, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2736.4409, device='cuda:0')\n",
      "Residual states sum =  tensor(-588.6129, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-9877.2734, device='cuda:0')\n",
      "Hidden states sum =  tensor(-4243.8179, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 26 called in free_generate mode with L = 26\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-4243.8179, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-4243.8179, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-31.5459, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 26, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(6748.0054, device='cuda:0')\n",
      "Residual states sum =  tensor(-31.5459, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-4243.8179, device='cuda:0')\n",
      "Hidden states sum =  tensor(8534.1445, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 27 called in free_generate mode with L = 26\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(8534.1445, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(8534.1445, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-97.5572, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 26, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(11390.5850, device='cuda:0')\n",
      "Residual states sum =  tensor(-97.5572, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(8534.1445, device='cuda:0')\n",
      "Hidden states sum =  tensor(-7552.0254, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 0 called in free_generate mode with L = 27\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(13.7089, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(13.7089, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(108.6609, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 27, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(397.3965, device='cuda:0')\n",
      "Residual states sum =  tensor(108.6609, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(13.7089, device='cuda:0')\n",
      "Hidden states sum =  tensor(506.7096, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 1 called in free_generate mode with L = 27\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(506.7096, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(506.7096, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(134.5790, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 27, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(385.8296, device='cuda:0')\n",
      "Residual states sum =  tensor(134.5790, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(506.7096, device='cuda:0')\n",
      "Hidden states sum =  tensor(1479.4624, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 2 called in free_generate mode with L = 27\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(1479.4624, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(1479.4624, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(109.0231, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 27, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2.6045, device='cuda:0')\n",
      "Residual states sum =  tensor(109.0231, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(1479.4624, device='cuda:0')\n",
      "Hidden states sum =  tensor(8112.6411, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 3 called in free_generate mode with L = 27\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(8112.6411, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(8112.6411, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(221.8568, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 27, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-495.4720, device='cuda:0')\n",
      "Residual states sum =  tensor(221.8568, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(8112.6411, device='cuda:0')\n",
      "Hidden states sum =  tensor(-5884.1895, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 4 called in free_generate mode with L = 27\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-5884.1895, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-5884.1895, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-361.8094, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 27, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1537.5254, device='cuda:0')\n",
      "Residual states sum =  tensor(-361.8094, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-5884.1895, device='cuda:0')\n",
      "Hidden states sum =  tensor(-11170.3359, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 5 called in free_generate mode with L = 27\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-11170.3359, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-11170.3359, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1042.6520, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 27, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-896.0323, device='cuda:0')\n",
      "Residual states sum =  tensor(-1042.6520, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-11170.3359, device='cuda:0')\n",
      "Hidden states sum =  tensor(-36008.0391, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 6 called in free_generate mode with L = 27\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-36008.0391, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-36008.0391, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-594.1711, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 27, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2404.0742, device='cuda:0')\n",
      "Residual states sum =  tensor(-594.1711, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-36008.0391, device='cuda:0')\n",
      "Hidden states sum =  tensor(2899.6909, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 7 called in free_generate mode with L = 27\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(2899.6909, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(2899.6909, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-80.7501, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 27, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(445.2331, device='cuda:0')\n",
      "Residual states sum =  tensor(-80.7501, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(2899.6909, device='cuda:0')\n",
      "Hidden states sum =  tensor(4169.7979, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 8 called in free_generate mode with L = 27\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(4169.7979, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(4169.7979, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(277.8175, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 27, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(973.2653, device='cuda:0')\n",
      "Residual states sum =  tensor(277.8175, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(4169.7979, device='cuda:0')\n",
      "Hidden states sum =  tensor(3235.0806, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 9 called in free_generate mode with L = 27\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(3235.0806, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(3235.0806, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(289.8509, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 27, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(290.9814, device='cuda:0')\n",
      "Residual states sum =  tensor(289.8509, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(3235.0806, device='cuda:0')\n",
      "Hidden states sum =  tensor(-733.4893, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 10 called in free_generate mode with L = 27\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-733.4893, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-733.4893, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-196.7897, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 27, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1183.7173, device='cuda:0')\n",
      "Residual states sum =  tensor(-196.7897, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-733.4893, device='cuda:0')\n",
      "Hidden states sum =  tensor(12389.3838, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 11 called in free_generate mode with L = 27\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(12389.3838, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(12389.3838, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1998.1987, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 27, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2140.0410, device='cuda:0')\n",
      "Residual states sum =  tensor(1998.1987, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(12389.3838, device='cuda:0')\n",
      "Hidden states sum =  tensor(-5632.5317, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 12 called in free_generate mode with L = 27\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-5632.5317, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-5632.5317, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-606.1748, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 27, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-230.5505, device='cuda:0')\n",
      "Residual states sum =  tensor(-606.1748, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-5632.5317, device='cuda:0')\n",
      "Hidden states sum =  tensor(-2503.8955, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 13 called in free_generate mode with L = 27\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-2503.8955, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-2503.8955, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-228.4635, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 27, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1742.3701, device='cuda:0')\n",
      "Residual states sum =  tensor(-228.4635, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-2503.8955, device='cuda:0')\n",
      "Hidden states sum =  tensor(5398.9009, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 14 called in free_generate mode with L = 27\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(5398.9009, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(5398.9009, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(997.7594, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 27, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(4535.2930, device='cuda:0')\n",
      "Residual states sum =  tensor(997.7594, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(5398.9009, device='cuda:0')\n",
      "Hidden states sum =  tensor(3208.1228, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 15 called in free_generate mode with L = 27\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(3208.1228, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(3208.1228, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(795.7633, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 27, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-4198.2573, device='cuda:0')\n",
      "Residual states sum =  tensor(795.7633, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(3208.1228, device='cuda:0')\n",
      "Hidden states sum =  tensor(6126.7729, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 16 called in free_generate mode with L = 27\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(6126.7729, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(6126.7729, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(802.8135, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 27, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-6999.1465, device='cuda:0')\n",
      "Residual states sum =  tensor(802.8135, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(6126.7729, device='cuda:0')\n",
      "Hidden states sum =  tensor(-16024.8262, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 17 called in free_generate mode with L = 27\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-16024.8262, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-16024.8262, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-785.3324, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 27, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(4650.3413, device='cuda:0')\n",
      "Residual states sum =  tensor(-785.3324, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-16024.8262, device='cuda:0')\n",
      "Hidden states sum =  tensor(52083.7656, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 18 called in free_generate mode with L = 27\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(52083.7656, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(52083.7656, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1619.7030, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 27, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(45.0601, device='cuda:0')\n",
      "Residual states sum =  tensor(1619.7030, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(52083.7656, device='cuda:0')\n",
      "Hidden states sum =  tensor(-10672.6865, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 19 called in free_generate mode with L = 27\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-10672.6865, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-10672.6865, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-525.7712, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 27, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1425.1831, device='cuda:0')\n",
      "Residual states sum =  tensor(-525.7712, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-10672.6865, device='cuda:0')\n",
      "Hidden states sum =  tensor(-10386.2227, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 20 called in free_generate mode with L = 27\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-10386.2227, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-10386.2227, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-160.5285, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 27, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(290.6891, device='cuda:0')\n",
      "Residual states sum =  tensor(-160.5285, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-10386.2227, device='cuda:0')\n",
      "Hidden states sum =  tensor(4471.7910, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 21 called in free_generate mode with L = 27\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(4471.7910, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(4471.7910, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-94.5346, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 27, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(4258.0107, device='cuda:0')\n",
      "Residual states sum =  tensor(-94.5346, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(4471.7910, device='cuda:0')\n",
      "Hidden states sum =  tensor(-4241.3633, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 22 called in free_generate mode with L = 27\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-4241.3633, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-4241.3633, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-27.1900, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 27, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2146.9492, device='cuda:0')\n",
      "Residual states sum =  tensor(-27.1900, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-4241.3633, device='cuda:0')\n",
      "Hidden states sum =  tensor(1726.0332, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 23 called in free_generate mode with L = 27\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(1726.0332, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(1726.0332, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(231.6060, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 27, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2421.5066, device='cuda:0')\n",
      "Residual states sum =  tensor(231.6060, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(1726.0332, device='cuda:0')\n",
      "Hidden states sum =  tensor(19136.8828, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 24 called in free_generate mode with L = 27\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(19136.8828, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(19136.8828, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(649.6915, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 27, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1521.2860, device='cuda:0')\n",
      "Residual states sum =  tensor(649.6915, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(19136.8828, device='cuda:0')\n",
      "Hidden states sum =  tensor(-10257.1709, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 25 called in free_generate mode with L = 27\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-10257.1709, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-10257.1709, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-611.2520, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 27, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2841.6885, device='cuda:0')\n",
      "Residual states sum =  tensor(-611.2520, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-10257.1709, device='cuda:0')\n",
      "Hidden states sum =  tensor(-4407.0420, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 26 called in free_generate mode with L = 27\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-4407.0420, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-4407.0420, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-32.7591, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 27, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(7007.5439, device='cuda:0')\n",
      "Residual states sum =  tensor(-32.7591, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-4407.0420, device='cuda:0')\n",
      "Hidden states sum =  tensor(8862.3828, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 27 called in free_generate mode with L = 27\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(8862.3828, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(8862.3828, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-101.3094, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 27, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(11828.6836, device='cuda:0')\n",
      "Residual states sum =  tensor(-101.3094, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(8862.3828, device='cuda:0')\n",
      "Hidden states sum =  tensor(-7842.4858, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 0 called in free_generate mode with L = 28\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(14.3036, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(14.3036, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(113.8309, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 28, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(436.1375, device='cuda:0')\n",
      "Residual states sum =  tensor(113.8309, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(14.3036, device='cuda:0')\n",
      "Hidden states sum =  tensor(562.9250, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 1 called in free_generate mode with L = 28\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(562.9250, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(562.9250, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(144.7048, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 28, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(405.6843, device='cuda:0')\n",
      "Residual states sum =  tensor(144.7048, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(562.9250, device='cuda:0')\n",
      "Hidden states sum =  tensor(1489.9985, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 2 called in free_generate mode with L = 28\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(1489.9985, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(1489.9985, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(97.9368, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 28, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-45.1113, device='cuda:0')\n",
      "Residual states sum =  tensor(97.9368, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(1489.9985, device='cuda:0')\n",
      "Hidden states sum =  tensor(8272.9385, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 3 called in free_generate mode with L = 28\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(8272.9385, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(8272.9385, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(224.8623, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 28, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-524.2992, device='cuda:0')\n",
      "Residual states sum =  tensor(224.8623, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(8272.9385, device='cuda:0')\n",
      "Hidden states sum =  tensor(-6149.0557, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 4 called in free_generate mode with L = 28\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-6149.0557, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-6149.0557, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-380.4170, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 28, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1580.8606, device='cuda:0')\n",
      "Residual states sum =  tensor(-380.4170, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-6149.0557, device='cuda:0')\n",
      "Hidden states sum =  tensor(-11408.1680, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 5 called in free_generate mode with L = 28\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-11408.1680, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-11408.1680, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1066.9122, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 28, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-916.9457, device='cuda:0')\n",
      "Residual states sum =  tensor(-1066.9122, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-11408.1680, device='cuda:0')\n",
      "Hidden states sum =  tensor(-37144.1250, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 6 called in free_generate mode with L = 28\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-37144.1250, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-37144.1250, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-614.1913, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 28, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2482.6416, device='cuda:0')\n",
      "Residual states sum =  tensor(-614.1913, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-37144.1250, device='cuda:0')\n",
      "Hidden states sum =  tensor(2981.7412, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 7 called in free_generate mode with L = 28\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(2981.7412, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(2981.7412, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-82.8805, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 28, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(462.7216, device='cuda:0')\n",
      "Residual states sum =  tensor(-82.8805, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(2981.7412, device='cuda:0')\n",
      "Hidden states sum =  tensor(4332.7646, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 8 called in free_generate mode with L = 28\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(4332.7646, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(4332.7646, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(290.1862, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 28, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1006.8652, device='cuda:0')\n",
      "Residual states sum =  tensor(290.1862, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(4332.7646, device='cuda:0')\n",
      "Hidden states sum =  tensor(3363.2373, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 9 called in free_generate mode with L = 28\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(3363.2373, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(3363.2373, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(301.6167, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 28, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(291.6370, device='cuda:0')\n",
      "Residual states sum =  tensor(301.6167, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(3363.2373, device='cuda:0')\n",
      "Hidden states sum =  tensor(-769.4258, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 10 called in free_generate mode with L = 28\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-769.4258, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-769.4258, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-207.9960, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 28, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1235.5281, device='cuda:0')\n",
      "Residual states sum =  tensor(-207.9960, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-769.4258, device='cuda:0')\n",
      "Hidden states sum =  tensor(12840.7812, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 11 called in free_generate mode with L = 28\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(12840.7812, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(12840.7812, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(2071.0791, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 28, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2222.9521, device='cuda:0')\n",
      "Residual states sum =  tensor(2071.0791, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(12840.7812, device='cuda:0')\n",
      "Hidden states sum =  tensor(-5826.6069, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 12 called in free_generate mode with L = 28\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-5826.6069, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-5826.6069, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-626.6934, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 28, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-238.8484, device='cuda:0')\n",
      "Residual states sum =  tensor(-626.6934, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-5826.6069, device='cuda:0')\n",
      "Hidden states sum =  tensor(-2588.2056, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 13 called in free_generate mode with L = 28\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-2588.2056, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-2588.2056, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-236.3060, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 28, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1808.5157, device='cuda:0')\n",
      "Residual states sum =  tensor(-236.3060, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-2588.2056, device='cuda:0')\n",
      "Hidden states sum =  tensor(5601.3213, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 14 called in free_generate mode with L = 28\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(5601.3213, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(5601.3213, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1035.2649, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 28, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(4704.1328, device='cuda:0')\n",
      "Residual states sum =  tensor(1035.2649, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(5601.3213, device='cuda:0')\n",
      "Hidden states sum =  tensor(3327.3699, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 15 called in free_generate mode with L = 28\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(3327.3699, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(3327.3699, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(825.1274, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 28, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-4354.7549, device='cuda:0')\n",
      "Residual states sum =  tensor(825.1274, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(3327.3699, device='cuda:0')\n",
      "Hidden states sum =  tensor(6347.4556, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 16 called in free_generate mode with L = 28\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(6347.4556, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(6347.4556, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(832.0765, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 28, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-7258.0879, device='cuda:0')\n",
      "Residual states sum =  tensor(832.0765, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(6347.4556, device='cuda:0')\n",
      "Hidden states sum =  tensor(-16619.9785, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 17 called in free_generate mode with L = 28\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-16619.9785, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-16619.9785, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-814.4867, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 28, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(4822.6240, device='cuda:0')\n",
      "Residual states sum =  tensor(-814.4867, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-16619.9785, device='cuda:0')\n",
      "Hidden states sum =  tensor(54013.0156, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 18 called in free_generate mode with L = 28\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(54013.0156, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(54013.0156, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1679.6882, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 28, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(46.7405, device='cuda:0')\n",
      "Residual states sum =  tensor(1679.6882, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(54013.0156, device='cuda:0')\n",
      "Hidden states sum =  tensor(-11068.1143, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 19 called in free_generate mode with L = 28\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-11068.1143, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-11068.1143, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-545.2513, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 28, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1477.9800, device='cuda:0')\n",
      "Residual states sum =  tensor(-545.2513, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-11068.1143, device='cuda:0')\n",
      "Hidden states sum =  tensor(-10770.9189, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 20 called in free_generate mode with L = 28\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-10770.9189, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-10770.9189, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-166.4766, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 28, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(301.4574, device='cuda:0')\n",
      "Residual states sum =  tensor(-166.4766, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-10770.9189, device='cuda:0')\n",
      "Hidden states sum =  tensor(4637.4351, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 21 called in free_generate mode with L = 28\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(4637.4351, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(4637.4351, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-98.0349, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 28, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(4415.7158, device='cuda:0')\n",
      "Residual states sum =  tensor(-98.0349, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(4637.4351, device='cuda:0')\n",
      "Hidden states sum =  tensor(-4398.4531, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 22 called in free_generate mode with L = 28\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-4398.4531, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-4398.4531, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-28.1971, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 28, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2226.4663, device='cuda:0')\n",
      "Residual states sum =  tensor(-28.1971, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-4398.4531, device='cuda:0')\n",
      "Hidden states sum =  tensor(1789.9531, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 23 called in free_generate mode with L = 28\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(1789.9531, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(1789.9531, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(240.1840, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 28, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2511.1919, device='cuda:0')\n",
      "Residual states sum =  tensor(240.1840, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(1789.9531, device='cuda:0')\n",
      "Hidden states sum =  tensor(19845.6543, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 24 called in free_generate mode with L = 28\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(19845.6543, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(19845.6543, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(673.7540, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 28, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1577.6309, device='cuda:0')\n",
      "Residual states sum =  tensor(673.7540, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(19845.6543, device='cuda:0')\n",
      "Hidden states sum =  tensor(-10637.0674, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 25 called in free_generate mode with L = 28\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-10637.0674, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-10637.0674, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-633.8909, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 28, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2946.9365, device='cuda:0')\n",
      "Residual states sum =  tensor(-633.8909, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-10637.0674, device='cuda:0')\n",
      "Hidden states sum =  tensor(-4570.2646, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 26 called in free_generate mode with L = 28\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-4570.2646, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-4570.2646, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-33.9725, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 28, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(7267.0820, device='cuda:0')\n",
      "Residual states sum =  tensor(-33.9725, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-4570.2646, device='cuda:0')\n",
      "Hidden states sum =  tensor(9190.6201, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 27 called in free_generate mode with L = 28\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(9190.6201, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(9190.6201, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-105.0615, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 28, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(12266.7842, device='cuda:0')\n",
      "Residual states sum =  tensor(-105.0615, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(9190.6201, device='cuda:0')\n",
      "Hidden states sum =  tensor(-8132.9478, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 0 called in free_generate mode with L = 29\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(15.3604, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(15.3604, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(117.1555, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 29, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(418.2126, device='cuda:0')\n",
      "Residual states sum =  tensor(117.1555, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(15.3604, device='cuda:0')\n",
      "Hidden states sum =  tensor(518.4208, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 1 called in free_generate mode with L = 29\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(518.4208, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(518.4208, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(133.0498, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 29, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(407.2112, device='cuda:0')\n",
      "Residual states sum =  tensor(133.0498, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(518.4208, device='cuda:0')\n",
      "Hidden states sum =  tensor(1470.3699, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 2 called in free_generate mode with L = 29\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(1470.3699, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(1470.3699, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(85.4426, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 29, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-68.6261, device='cuda:0')\n",
      "Residual states sum =  tensor(85.4426, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(1470.3699, device='cuda:0')\n",
      "Hidden states sum =  tensor(8800.5742, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 3 called in free_generate mode with L = 29\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(8800.5742, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(8800.5742, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(239.0782, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 29, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-527.5520, device='cuda:0')\n",
      "Residual states sum =  tensor(239.0782, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(8800.5742, device='cuda:0')\n",
      "Hidden states sum =  tensor(-6401.4902, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 4 called in free_generate mode with L = 29\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-6401.4902, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-6401.4902, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-394.8162, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 29, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1626.9563, device='cuda:0')\n",
      "Residual states sum =  tensor(-394.8162, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-6401.4902, device='cuda:0')\n",
      "Hidden states sum =  tensor(-11716.7607, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 5 called in free_generate mode with L = 29\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-11716.7607, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-11716.7607, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1094.9646, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 29, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-939.3988, device='cuda:0')\n",
      "Residual states sum =  tensor(-1094.9646, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-11716.7607, device='cuda:0')\n",
      "Hidden states sum =  tensor(-38301.1797, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 6 called in free_generate mode with L = 29\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-38301.1797, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-38301.1797, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-634.5655, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 29, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2560.9026, device='cuda:0')\n",
      "Residual states sum =  tensor(-634.5655, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-38301.1797, device='cuda:0')\n",
      "Hidden states sum =  tensor(3059.8359, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 7 called in free_generate mode with L = 29\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(3059.8359, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(3059.8359, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-85.0840, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 29, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(480.5975, device='cuda:0')\n",
      "Residual states sum =  tensor(-85.0840, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(3059.8359, device='cuda:0')\n",
      "Hidden states sum =  tensor(4498.1646, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 8 called in free_generate mode with L = 29\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(4498.1646, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(4498.1646, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(303.1218, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 29, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1040.2913, device='cuda:0')\n",
      "Residual states sum =  tensor(303.1218, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(4498.1646, device='cuda:0')\n",
      "Hidden states sum =  tensor(3495.1709, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 9 called in free_generate mode with L = 29\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(3495.1709, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(3495.1709, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(313.8390, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 29, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(291.4146, device='cuda:0')\n",
      "Residual states sum =  tensor(313.8390, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(3495.1709, device='cuda:0')\n",
      "Hidden states sum =  tensor(-805.7646, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 10 called in free_generate mode with L = 29\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-805.7646, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-805.7646, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-219.3159, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 29, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1288.1804, device='cuda:0')\n",
      "Residual states sum =  tensor(-219.3159, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-805.7646, device='cuda:0')\n",
      "Hidden states sum =  tensor(13291.5752, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 11 called in free_generate mode with L = 29\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(13291.5752, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(13291.5752, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(2143.9807, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 29, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2306.2710, device='cuda:0')\n",
      "Residual states sum =  tensor(2143.9807, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(13291.5752, device='cuda:0')\n",
      "Hidden states sum =  tensor(-6018.8335, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 12 called in free_generate mode with L = 29\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-6018.8335, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-6018.8335, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-647.0085, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 29, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-247.0945, device='cuda:0')\n",
      "Residual states sum =  tensor(-647.0085, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-6018.8335, device='cuda:0')\n",
      "Hidden states sum =  tensor(-2671.3362, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 13 called in free_generate mode with L = 29\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-2671.3362, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-2671.3362, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-244.0714, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 29, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1875.0892, device='cuda:0')\n",
      "Residual states sum =  tensor(-244.0714, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-2671.3362, device='cuda:0')\n",
      "Hidden states sum =  tensor(5805., device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 14 called in free_generate mode with L = 29\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(5805., device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(5805., device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1072.9441, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 29, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(4873.1660, device='cuda:0')\n",
      "Residual states sum =  tensor(1072.9441, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(5805., device='cuda:0')\n",
      "Hidden states sum =  tensor(3446.3066, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 15 called in free_generate mode with L = 29\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(3446.3066, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(3446.3066, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(854.4320, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 29, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-4511.4424, device='cuda:0')\n",
      "Residual states sum =  tensor(854.4320, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(3446.3066, device='cuda:0')\n",
      "Hidden states sum =  tensor(6567.1353, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 16 called in free_generate mode with L = 29\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(6567.1353, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(6567.1353, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(861.2737, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 29, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-7517.0068, device='cuda:0')\n",
      "Residual states sum =  tensor(861.2737, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(6567.1353, device='cuda:0')\n",
      "Hidden states sum =  tensor(-17215.2891, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 17 called in free_generate mode with L = 29\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-17215.2891, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-17215.2891, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-843.6498, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 29, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(4994.9180, device='cuda:0')\n",
      "Residual states sum =  tensor(-843.6498, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-17215.2891, device='cuda:0')\n",
      "Hidden states sum =  tensor(55942.2461, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 18 called in free_generate mode with L = 29\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(55942.2461, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(55942.2461, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1739.6716, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 29, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(48.4218, device='cuda:0')\n",
      "Residual states sum =  tensor(1739.6716, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(55942.2461, device='cuda:0')\n",
      "Hidden states sum =  tensor(-11463.5586, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 19 called in free_generate mode with L = 29\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-11463.5586, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-11463.5586, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-564.7325, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 29, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1530.7773, device='cuda:0')\n",
      "Residual states sum =  tensor(-564.7325, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-11463.5586, device='cuda:0')\n",
      "Hidden states sum =  tensor(-11155.6211, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 20 called in free_generate mode with L = 29\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-11155.6211, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-11155.6211, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-172.4252, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 29, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(312.2263, device='cuda:0')\n",
      "Residual states sum =  tensor(-172.4252, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-11155.6211, device='cuda:0')\n",
      "Hidden states sum =  tensor(4803.0806, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 21 called in free_generate mode with L = 29\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(4803.0806, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(4803.0806, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-101.5352, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 29, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(4573.4199, device='cuda:0')\n",
      "Residual states sum =  tensor(-101.5352, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(4803.0806, device='cuda:0')\n",
      "Hidden states sum =  tensor(-4555.5391, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 22 called in free_generate mode with L = 29\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-4555.5391, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-4555.5391, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-29.2042, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 29, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2305.9832, device='cuda:0')\n",
      "Residual states sum =  tensor(-29.2042, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-4555.5391, device='cuda:0')\n",
      "Hidden states sum =  tensor(1853.8789, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 23 called in free_generate mode with L = 29\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(1853.8789, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(1853.8789, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(248.7617, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 29, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2600.8774, device='cuda:0')\n",
      "Residual states sum =  tensor(248.7617, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(1853.8789, device='cuda:0')\n",
      "Hidden states sum =  tensor(20554.4277, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 24 called in free_generate mode with L = 29\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(20554.4277, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(20554.4277, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(697.8168, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 29, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1633.9749, device='cuda:0')\n",
      "Residual states sum =  tensor(697.8168, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(20554.4277, device='cuda:0')\n",
      "Hidden states sum =  tensor(-11016.9600, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 25 called in free_generate mode with L = 29\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-11016.9600, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-11016.9600, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-656.5298, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 29, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(3052.1836, device='cuda:0')\n",
      "Residual states sum =  tensor(-656.5298, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-11016.9600, device='cuda:0')\n",
      "Hidden states sum =  tensor(-4733.4873, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 26 called in free_generate mode with L = 29\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-4733.4873, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-4733.4873, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-35.1857, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 29, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(7526.6201, device='cuda:0')\n",
      "Residual states sum =  tensor(-35.1857, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-4733.4873, device='cuda:0')\n",
      "Hidden states sum =  tensor(9518.8535, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 27 called in free_generate mode with L = 29\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(9518.8535, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(9518.8535, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-108.8137, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 29, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(12704.8828, device='cuda:0')\n",
      "Residual states sum =  tensor(-108.8137, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(9518.8535, device='cuda:0')\n",
      "Hidden states sum =  tensor(-8423.4121, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 0 called in free_generate mode with L = 30\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(14.0411, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(14.0411, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(105.2641, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 30, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(416.0212, device='cuda:0')\n",
      "Residual states sum =  tensor(105.2641, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(14.0411, device='cuda:0')\n",
      "Hidden states sum =  tensor(506.5851, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 1 called in free_generate mode with L = 30\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(506.5851, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(506.5851, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(133.2363, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 30, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(434.0270, device='cuda:0')\n",
      "Residual states sum =  tensor(133.2363, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(506.5851, device='cuda:0')\n",
      "Hidden states sum =  tensor(1489.3489, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 2 called in free_generate mode with L = 30\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(1489.3489, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(1489.3489, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(83.2695, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 30, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(3.7930, device='cuda:0')\n",
      "Residual states sum =  tensor(83.2695, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(1489.3489, device='cuda:0')\n",
      "Hidden states sum =  tensor(9205.0508, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 3 called in free_generate mode with L = 30\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(9205.0508, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(9205.0508, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(257.3786, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 30, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-532.7582, device='cuda:0')\n",
      "Residual states sum =  tensor(257.3786, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(9205.0508, device='cuda:0')\n",
      "Hidden states sum =  tensor(-6772.5996, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 4 called in free_generate mode with L = 30\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-6772.5996, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-6772.5996, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-414.1873, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 30, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1677.5020, device='cuda:0')\n",
      "Residual states sum =  tensor(-414.1873, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-6772.5996, device='cuda:0')\n",
      "Hidden states sum =  tensor(-12017.7764, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 5 called in free_generate mode with L = 30\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-12017.7764, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-12017.7764, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1124.4146, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 30, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-960.6380, device='cuda:0')\n",
      "Residual states sum =  tensor(-1124.4146, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-12017.7764, device='cuda:0')\n",
      "Hidden states sum =  tensor(-39469.2891, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 6 called in free_generate mode with L = 30\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-39469.2891, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-39469.2891, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-654.7495, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 30, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2639.2388, device='cuda:0')\n",
      "Residual states sum =  tensor(-654.7495, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-39469.2891, device='cuda:0')\n",
      "Hidden states sum =  tensor(3128.8667, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 7 called in free_generate mode with L = 30\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(3128.8667, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(3128.8667, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-87.8564, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 30, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(499.2355, device='cuda:0')\n",
      "Residual states sum =  tensor(-87.8564, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(3128.8667, device='cuda:0')\n",
      "Hidden states sum =  tensor(4664.8389, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 8 called in free_generate mode with L = 30\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(4664.8389, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(4664.8389, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(316.5648, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 30, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1073.5181, device='cuda:0')\n",
      "Residual states sum =  tensor(316.5648, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(4664.8389, device='cuda:0')\n",
      "Hidden states sum =  tensor(3631.9004, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 9 called in free_generate mode with L = 30\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(3631.9004, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(3631.9004, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(326.6258, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 30, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(290.4413, device='cuda:0')\n",
      "Residual states sum =  tensor(326.6258, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(3631.9004, device='cuda:0')\n",
      "Hidden states sum =  tensor(-841.4458, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 10 called in free_generate mode with L = 30\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-841.4458, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-841.4458, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-230.6987, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 30, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1341.6924, device='cuda:0')\n",
      "Residual states sum =  tensor(-230.6987, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-841.4458, device='cuda:0')\n",
      "Hidden states sum =  tensor(13741.7598, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 11 called in free_generate mode with L = 30\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(13741.7598, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(13741.7598, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(2216.9248, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 30, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2390.0854, device='cuda:0')\n",
      "Residual states sum =  tensor(2216.9248, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(13741.7598, device='cuda:0')\n",
      "Hidden states sum =  tensor(-6208.9189, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 12 called in free_generate mode with L = 30\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-6208.9189, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-6208.9189, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-667.0981, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 30, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-255.2831, device='cuda:0')\n",
      "Residual states sum =  tensor(-667.0981, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-6208.9189, device='cuda:0')\n",
      "Hidden states sum =  tensor(-2753.1128, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 13 called in free_generate mode with L = 30\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-2753.1128, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-2753.1128, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-251.7422, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 30, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1942.1416, device='cuda:0')\n",
      "Residual states sum =  tensor(-251.7422, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-2753.1128, device='cuda:0')\n",
      "Hidden states sum =  tensor(6009.9961, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 14 called in free_generate mode with L = 30\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(6009.9961, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(6009.9961, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1110.8080, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 30, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(5042.3911, device='cuda:0')\n",
      "Residual states sum =  tensor(1110.8080, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(6009.9961, device='cuda:0')\n",
      "Hidden states sum =  tensor(3565.0007, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 15 called in free_generate mode with L = 30\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(3565.0007, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(3565.0007, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(883.6790, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 30, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-4668.3560, device='cuda:0')\n",
      "Residual states sum =  tensor(883.6790, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(3565.0007, device='cuda:0')\n",
      "Hidden states sum =  tensor(6785.7939, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 16 called in free_generate mode with L = 30\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(6785.7939, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(6785.7939, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(890.4000, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 30, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-7775.9082, device='cuda:0')\n",
      "Residual states sum =  tensor(890.4000, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(6785.7939, device='cuda:0')\n",
      "Hidden states sum =  tensor(-17810.8477, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 17 called in free_generate mode with L = 30\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-17810.8477, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-17810.8477, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-872.8279, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 30, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(5167.2197, device='cuda:0')\n",
      "Residual states sum =  tensor(-872.8279, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-17810.8477, device='cuda:0')\n",
      "Hidden states sum =  tensor(57871.5039, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 18 called in free_generate mode with L = 30\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(57871.5039, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(57871.5039, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1799.6537, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 30, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(50.1046, device='cuda:0')\n",
      "Residual states sum =  tensor(1799.6537, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(57871.5039, device='cuda:0')\n",
      "Hidden states sum =  tensor(-11859.0186, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 19 called in free_generate mode with L = 30\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-11859.0186, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-11859.0186, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-584.2143, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 30, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1583.5765, device='cuda:0')\n",
      "Residual states sum =  tensor(-584.2143, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-11859.0186, device='cuda:0')\n",
      "Hidden states sum =  tensor(-11540.3389, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 20 called in free_generate mode with L = 30\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-11540.3389, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-11540.3389, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-178.3743, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 30, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(322.9949, device='cuda:0')\n",
      "Residual states sum =  tensor(-178.3743, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-11540.3389, device='cuda:0')\n",
      "Hidden states sum =  tensor(4968.7280, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 21 called in free_generate mode with L = 30\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(4968.7280, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(4968.7280, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-105.0354, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 30, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(4731.1255, device='cuda:0')\n",
      "Residual states sum =  tensor(-105.0354, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(4968.7280, device='cuda:0')\n",
      "Hidden states sum =  tensor(-4712.6270, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 22 called in free_generate mode with L = 30\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-4712.6270, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-4712.6270, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-30.2112, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 30, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2385.5005, device='cuda:0')\n",
      "Residual states sum =  tensor(-30.2112, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-4712.6270, device='cuda:0')\n",
      "Hidden states sum =  tensor(1917.8027, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 23 called in free_generate mode with L = 30\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(1917.8027, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(1917.8027, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(257.3396, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 30, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2690.5635, device='cuda:0')\n",
      "Residual states sum =  tensor(257.3396, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(1917.8027, device='cuda:0')\n",
      "Hidden states sum =  tensor(21263.1992, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 24 called in free_generate mode with L = 30\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(21263.1992, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(21263.1992, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(721.8793, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 30, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1690.3193, device='cuda:0')\n",
      "Residual states sum =  tensor(721.8793, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(21263.1992, device='cuda:0')\n",
      "Hidden states sum =  tensor(-11396.8584, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 25 called in free_generate mode with L = 30\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-11396.8584, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-11396.8584, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-679.1688, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 30, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(3157.4314, device='cuda:0')\n",
      "Residual states sum =  tensor(-679.1688, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-11396.8584, device='cuda:0')\n",
      "Hidden states sum =  tensor(-4896.7109, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 26 called in free_generate mode with L = 30\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-4896.7109, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-4896.7109, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-36.3990, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 30, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(7786.1592, device='cuda:0')\n",
      "Residual states sum =  tensor(-36.3990, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-4896.7109, device='cuda:0')\n",
      "Hidden states sum =  tensor(9847.0928, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 27 called in free_generate mode with L = 30\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(9847.0928, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(9847.0928, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-112.5657, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 30, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(13142.9824, device='cuda:0')\n",
      "Residual states sum =  tensor(-112.5657, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(9847.0928, device='cuda:0')\n",
      "Hidden states sum =  tensor(-8713.8770, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 0 called in free_generate mode with L = 31\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(14.6293, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(14.6293, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(105.3560, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 31, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(450.3802, device='cuda:0')\n",
      "Residual states sum =  tensor(105.3560, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(14.6293, device='cuda:0')\n",
      "Hidden states sum =  tensor(508.9067, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 1 called in free_generate mode with L = 31\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(508.9067, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(508.9067, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(136.0203, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 31, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(468.8276, device='cuda:0')\n",
      "Residual states sum =  tensor(136.0203, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(508.9067, device='cuda:0')\n",
      "Hidden states sum =  tensor(1468.6514, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 2 called in free_generate mode with L = 31\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(1468.6514, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(1468.6514, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(76.4990, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 31, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2.2749, device='cuda:0')\n",
      "Residual states sum =  tensor(76.4990, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(1468.6514, device='cuda:0')\n",
      "Hidden states sum =  tensor(9317.4531, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 3 called in free_generate mode with L = 31\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(9317.4531, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(9317.4531, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(258.5179, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 31, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-563.7104, device='cuda:0')\n",
      "Residual states sum =  tensor(258.5179, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(9317.4531, device='cuda:0')\n",
      "Hidden states sum =  tensor(-7087.6699, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 4 called in free_generate mode with L = 31\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-7087.6699, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-7087.6699, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-435.9621, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 31, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1722.5873, device='cuda:0')\n",
      "Residual states sum =  tensor(-435.9621, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-7087.6699, device='cuda:0')\n",
      "Hidden states sum =  tensor(-12244.8105, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 5 called in free_generate mode with L = 31\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-12244.8105, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-12244.8105, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1148.2512, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 31, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-984.8234, device='cuda:0')\n",
      "Residual states sum =  tensor(-1148.2512, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-12244.8105, device='cuda:0')\n",
      "Hidden states sum =  tensor(-40544.5195, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 6 called in free_generate mode with L = 31\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-40544.5195, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-40544.5195, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-674.1127, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 31, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2717.7749, device='cuda:0')\n",
      "Residual states sum =  tensor(-674.1127, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-40544.5195, device='cuda:0')\n",
      "Hidden states sum =  tensor(3195.6641, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 7 called in free_generate mode with L = 31\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(3195.6641, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(3195.6641, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-90.8611, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 31, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(518.5602, device='cuda:0')\n",
      "Residual states sum =  tensor(-90.8611, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(3195.6641, device='cuda:0')\n",
      "Hidden states sum =  tensor(4832.6060, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 8 called in free_generate mode with L = 31\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(4832.6060, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(4832.6060, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(330.4466, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 31, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1106.3462, device='cuda:0')\n",
      "Residual states sum =  tensor(330.4466, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(4832.6060, device='cuda:0')\n",
      "Hidden states sum =  tensor(3769.7910, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 9 called in free_generate mode with L = 31\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(3769.7910, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(3769.7910, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(339.4620, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 31, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(288.9705, device='cuda:0')\n",
      "Residual states sum =  tensor(339.4620, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(3769.7910, device='cuda:0')\n",
      "Hidden states sum =  tensor(-875.5552, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 10 called in free_generate mode with L = 31\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-875.5552, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-875.5552, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-242.0670, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 31, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1396.0266, device='cuda:0')\n",
      "Residual states sum =  tensor(-242.0670, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-875.5552, device='cuda:0')\n",
      "Hidden states sum =  tensor(14191.8164, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 11 called in free_generate mode with L = 31\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(14191.8164, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(14191.8164, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(2290.0210, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 31, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2474.4653, device='cuda:0')\n",
      "Residual states sum =  tensor(2290.0210, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(14191.8164, device='cuda:0')\n",
      "Hidden states sum =  tensor(-6396.9219, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 12 called in free_generate mode with L = 31\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-6396.9219, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-6396.9219, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-686.9561, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 31, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-263.4083, device='cuda:0')\n",
      "Residual states sum =  tensor(-686.9561, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-6396.9219, device='cuda:0')\n",
      "Hidden states sum =  tensor(-2833.3665, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 13 called in free_generate mode with L = 31\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-2833.3665, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-2833.3665, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-259.2945, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 31, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2009.7155, device='cuda:0')\n",
      "Residual states sum =  tensor(-259.2945, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-2833.3665, device='cuda:0')\n",
      "Hidden states sum =  tensor(6216.3940, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 14 called in free_generate mode with L = 31\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(6216.3940, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(6216.3940, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1148.8679, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 31, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(5211.8008, device='cuda:0')\n",
      "Residual states sum =  tensor(1148.8679, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(6216.3940, device='cuda:0')\n",
      "Hidden states sum =  tensor(3683.5498, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 15 called in free_generate mode with L = 31\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(3683.5498, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(3683.5498, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(912.8774, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 31, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-4825.5283, device='cuda:0')\n",
      "Residual states sum =  tensor(912.8774, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(3683.5498, device='cuda:0')\n",
      "Hidden states sum =  tensor(7003.4424, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 16 called in free_generate mode with L = 31\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(7003.4424, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(7003.4424, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(919.4523, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 31, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-8034.7998, device='cuda:0')\n",
      "Residual states sum =  tensor(919.4523, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(7003.4424, device='cuda:0')\n",
      "Hidden states sum =  tensor(-18406.7422, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 17 called in free_generate mode with L = 31\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-18406.7422, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-18406.7422, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-902.0274, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 31, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(5339.5264, device='cuda:0')\n",
      "Residual states sum =  tensor(-902.0274, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-18406.7422, device='cuda:0')\n",
      "Hidden states sum =  tensor(59800.7969, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 18 called in free_generate mode with L = 31\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(59800.7969, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(59800.7969, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1859.6350, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 31, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(51.7883, device='cuda:0')\n",
      "Residual states sum =  tensor(1859.6350, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(59800.7969, device='cuda:0')\n",
      "Hidden states sum =  tensor(-12254.5059, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 19 called in free_generate mode with L = 31\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-12254.5059, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-12254.5059, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-603.6966, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 31, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1636.3773, device='cuda:0')\n",
      "Residual states sum =  tensor(-603.6966, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-12254.5059, device='cuda:0')\n",
      "Hidden states sum =  tensor(-11925.0674, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 20 called in free_generate mode with L = 31\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-11925.0674, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-11925.0674, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-184.3238, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 31, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(333.7630, device='cuda:0')\n",
      "Residual states sum =  tensor(-184.3238, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-11925.0674, device='cuda:0')\n",
      "Hidden states sum =  tensor(5134.3770, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 21 called in free_generate mode with L = 31\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(5134.3770, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(5134.3770, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-108.5355, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 31, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(4888.8296, device='cuda:0')\n",
      "Residual states sum =  tensor(-108.5355, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(5134.3770, device='cuda:0')\n",
      "Hidden states sum =  tensor(-4869.7148, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 22 called in free_generate mode with L = 31\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-4869.7148, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-4869.7148, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-31.2183, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 31, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2465.0178, device='cuda:0')\n",
      "Residual states sum =  tensor(-31.2183, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-4869.7148, device='cuda:0')\n",
      "Hidden states sum =  tensor(1981.7266, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 23 called in free_generate mode with L = 31\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(1981.7266, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(1981.7266, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(265.9174, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 31, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2780.2495, device='cuda:0')\n",
      "Residual states sum =  tensor(265.9174, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(1981.7266, device='cuda:0')\n",
      "Hidden states sum =  tensor(21971.9707, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 24 called in free_generate mode with L = 31\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(21971.9707, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(21971.9707, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(745.9419, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 31, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1746.6636, device='cuda:0')\n",
      "Residual states sum =  tensor(745.9419, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(21971.9707, device='cuda:0')\n",
      "Hidden states sum =  tensor(-11776.7520, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 25 called in free_generate mode with L = 31\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-11776.7520, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-11776.7520, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-701.8077, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 31, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(3262.6794, device='cuda:0')\n",
      "Residual states sum =  tensor(-701.8077, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-11776.7520, device='cuda:0')\n",
      "Hidden states sum =  tensor(-5059.9351, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 26 called in free_generate mode with L = 31\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-5059.9351, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-5059.9351, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-37.6122, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 31, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(8045.6973, device='cuda:0')\n",
      "Residual states sum =  tensor(-37.6122, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-5059.9351, device='cuda:0')\n",
      "Hidden states sum =  tensor(10175.3311, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 27 called in free_generate mode with L = 31\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(10175.3311, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(10175.3311, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-116.3178, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 31, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(13581.0820, device='cuda:0')\n",
      "Residual states sum =  tensor(-116.3178, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(10175.3311, device='cuda:0')\n",
      "Hidden states sum =  tensor(-9004.3359, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 0 called in free_generate mode with L = 32\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(15.8809, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(15.8809, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(116.4700, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 32, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(460.6646, device='cuda:0')\n",
      "Residual states sum =  tensor(116.4700, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(15.8809, device='cuda:0')\n",
      "Hidden states sum =  tensor(487.4511, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 1 called in free_generate mode with L = 32\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(487.4511, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(487.4511, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(126.3034, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 32, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(474.1610, device='cuda:0')\n",
      "Residual states sum =  tensor(126.3034, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(487.4511, device='cuda:0')\n",
      "Hidden states sum =  tensor(1357.8218, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 2 called in free_generate mode with L = 32\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(1357.8218, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(1357.8218, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(44.8577, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 32, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(49.3065, device='cuda:0')\n",
      "Residual states sum =  tensor(44.8577, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(1357.8218, device='cuda:0')\n",
      "Hidden states sum =  tensor(9789.6289, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 3 called in free_generate mode with L = 32\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(9789.6289, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(9789.6289, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(260.6981, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 32, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-607.0415, device='cuda:0')\n",
      "Residual states sum =  tensor(260.6981, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(9789.6289, device='cuda:0')\n",
      "Hidden states sum =  tensor(-7244.3301, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 4 called in free_generate mode with L = 32\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-7244.3301, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-7244.3301, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-449.1600, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 32, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1774.6139, device='cuda:0')\n",
      "Residual states sum =  tensor(-449.1600, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-7244.3301, device='cuda:0')\n",
      "Hidden states sum =  tensor(-12531.6504, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 5 called in free_generate mode with L = 32\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-12531.6504, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-12531.6504, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1177.4348, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 32, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1018.1583, device='cuda:0')\n",
      "Residual states sum =  tensor(-1177.4348, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-12531.6504, device='cuda:0')\n",
      "Hidden states sum =  tensor(-41660.4531, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 6 called in free_generate mode with L = 32\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-41660.4531, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-41660.4531, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-694.2878, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 32, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2796.6597, device='cuda:0')\n",
      "Residual states sum =  tensor(-694.2878, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-41660.4531, device='cuda:0')\n",
      "Hidden states sum =  tensor(3260.3716, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 7 called in free_generate mode with L = 32\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(3260.3716, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(3260.3716, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-94.1178, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 32, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(538.1685, device='cuda:0')\n",
      "Residual states sum =  tensor(-94.1178, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(3260.3716, device='cuda:0')\n",
      "Hidden states sum =  tensor(5004.5229, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 8 called in free_generate mode with L = 32\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(5004.5229, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(5004.5229, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(344.9847, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 32, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1138.7314, device='cuda:0')\n",
      "Residual states sum =  tensor(344.9847, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(5004.5229, device='cuda:0')\n",
      "Hidden states sum =  tensor(3906.6899, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 9 called in free_generate mode with L = 32\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(3906.6899, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(3906.6899, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(352.1172, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 32, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(287.0887, device='cuda:0')\n",
      "Residual states sum =  tensor(352.1172, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(3906.6899, device='cuda:0')\n",
      "Hidden states sum =  tensor(-908.5317, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 10 called in free_generate mode with L = 32\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-908.5317, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-908.5317, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-253.4886, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 32, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1451.3281, device='cuda:0')\n",
      "Residual states sum =  tensor(-253.4886, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-908.5317, device='cuda:0')\n",
      "Hidden states sum =  tensor(14641.6240, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 11 called in free_generate mode with L = 32\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(14641.6240, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(14641.6240, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(2363.2939, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 32, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2559.4124, device='cuda:0')\n",
      "Residual states sum =  tensor(2363.2939, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(14641.6240, device='cuda:0')\n",
      "Hidden states sum =  tensor(-6582.9980, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 12 called in free_generate mode with L = 32\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-6582.9980, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-6582.9980, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-706.5898, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 32, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-271.4681, device='cuda:0')\n",
      "Residual states sum =  tensor(-706.5898, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-6582.9980, device='cuda:0')\n",
      "Hidden states sum =  tensor(-2912.0293, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 13 called in free_generate mode with L = 32\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-2912.0293, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-2912.0293, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-266.7211, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 32, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2077.8389, device='cuda:0')\n",
      "Residual states sum =  tensor(-266.7211, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-2912.0293, device='cuda:0')\n",
      "Hidden states sum =  tensor(6424.1592, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 14 called in free_generate mode with L = 32\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(6424.1592, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(6424.1592, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1187.1235, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 32, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(5381.3760, device='cuda:0')\n",
      "Residual states sum =  tensor(1187.1235, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(6424.1592, device='cuda:0')\n",
      "Hidden states sum =  tensor(3802.0332, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 15 called in free_generate mode with L = 32\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(3802.0332, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(3802.0332, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(942.0408, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 32, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-4982.9863, device='cuda:0')\n",
      "Residual states sum =  tensor(942.0408, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(3802.0332, device='cuda:0')\n",
      "Hidden states sum =  tensor(7220.1343, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 16 called in free_generate mode with L = 32\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(7220.1343, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(7220.1343, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(948.4307, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 32, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-8293.6826, device='cuda:0')\n",
      "Residual states sum =  tensor(948.4307, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(7220.1343, device='cuda:0')\n",
      "Hidden states sum =  tensor(-19003.0371, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 17 called in free_generate mode with L = 32\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-19003.0371, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-19003.0371, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-931.2526, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 32, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(5511.8369, device='cuda:0')\n",
      "Residual states sum =  tensor(-931.2526, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-19003.0371, device='cuda:0')\n",
      "Hidden states sum =  tensor(61730.1562, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 18 called in free_generate mode with L = 32\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(61730.1562, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(61730.1562, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1919.6160, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 32, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(53.4739, device='cuda:0')\n",
      "Residual states sum =  tensor(1919.6160, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(61730.1562, device='cuda:0')\n",
      "Hidden states sum =  tensor(-12650.0098, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 19 called in free_generate mode with L = 32\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-12650.0098, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-12650.0098, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-623.1796, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 32, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1689.1796, device='cuda:0')\n",
      "Residual states sum =  tensor(-623.1796, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-12650.0098, device='cuda:0')\n",
      "Hidden states sum =  tensor(-12309.8105, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 20 called in free_generate mode with L = 32\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-12309.8105, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-12309.8105, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-190.2736, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 32, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(344.5320, device='cuda:0')\n",
      "Residual states sum =  tensor(-190.2736, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-12309.8105, device='cuda:0')\n",
      "Hidden states sum =  tensor(5300.0259, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 21 called in free_generate mode with L = 32\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(5300.0259, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(5300.0259, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-112.0355, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 32, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(5046.5342, device='cuda:0')\n",
      "Residual states sum =  tensor(-112.0355, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(5300.0259, device='cuda:0')\n",
      "Hidden states sum =  tensor(-5026.8008, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 22 called in free_generate mode with L = 32\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-5026.8008, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-5026.8008, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-32.2253, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 32, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2544.5347, device='cuda:0')\n",
      "Residual states sum =  tensor(-32.2253, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-5026.8008, device='cuda:0')\n",
      "Hidden states sum =  tensor(2045.6484, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 23 called in free_generate mode with L = 32\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(2045.6484, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(2045.6484, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(274.4955, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 32, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2869.9358, device='cuda:0')\n",
      "Residual states sum =  tensor(274.4955, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(2045.6484, device='cuda:0')\n",
      "Hidden states sum =  tensor(22680.7422, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 24 called in free_generate mode with L = 32\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(22680.7422, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(22680.7422, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(770.0045, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 32, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1803.0083, device='cuda:0')\n",
      "Residual states sum =  tensor(770.0045, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(22680.7422, device='cuda:0')\n",
      "Hidden states sum =  tensor(-12156.6484, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 25 called in free_generate mode with L = 32\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-12156.6484, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-12156.6484, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-724.4467, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 32, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(3367.9270, device='cuda:0')\n",
      "Residual states sum =  tensor(-724.4467, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-12156.6484, device='cuda:0')\n",
      "Hidden states sum =  tensor(-5223.1577, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 26 called in free_generate mode with L = 32\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-5223.1577, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-5223.1577, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-38.8256, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 32, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(8305.2354, device='cuda:0')\n",
      "Residual states sum =  tensor(-38.8256, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-5223.1577, device='cuda:0')\n",
      "Hidden states sum =  tensor(10503.5664, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 27 called in free_generate mode with L = 32\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(10503.5664, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(10503.5664, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-120.0701, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 32, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(14019.1787, device='cuda:0')\n",
      "Residual states sum =  tensor(-120.0701, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(10503.5664, device='cuda:0')\n",
      "Hidden states sum =  tensor(-9294.7998, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 0 called in free_generate mode with L = 33\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(16.4125, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(16.4125, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(118.5452, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 33, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(459.8390, device='cuda:0')\n",
      "Residual states sum =  tensor(118.5452, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(16.4125, device='cuda:0')\n",
      "Hidden states sum =  tensor(505.2041, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 1 called in free_generate mode with L = 33\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(505.2041, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(505.2041, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(133.8412, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 33, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(485.5797, device='cuda:0')\n",
      "Residual states sum =  tensor(133.8412, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(505.2041, device='cuda:0')\n",
      "Hidden states sum =  tensor(1317.9658, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 2 called in free_generate mode with L = 33\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(1317.9658, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(1317.9658, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(32.6999, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 33, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(121.8495, device='cuda:0')\n",
      "Residual states sum =  tensor(32.6999, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(1317.9658, device='cuda:0')\n",
      "Hidden states sum =  tensor(10563.2031, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 3 called in free_generate mode with L = 33\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(10563.2031, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(10563.2031, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(286.6929, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 33, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-648.9932, device='cuda:0')\n",
      "Residual states sum =  tensor(286.6929, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(10563.2031, device='cuda:0')\n",
      "Hidden states sum =  tensor(-7444.4941, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 4 called in free_generate mode with L = 33\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-7444.4941, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-7444.4941, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-463.8432, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 33, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1828.0256, device='cuda:0')\n",
      "Residual states sum =  tensor(-463.8432, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-7444.4941, device='cuda:0')\n",
      "Hidden states sum =  tensor(-12825.4336, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 5 called in free_generate mode with L = 33\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-12825.4336, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-12825.4336, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1206.5525, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 33, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1053.9860, device='cuda:0')\n",
      "Residual states sum =  tensor(-1206.5525, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-12825.4336, device='cuda:0')\n",
      "Hidden states sum =  tensor(-42853.9883, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 6 called in free_generate mode with L = 33\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-42853.9883, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-42853.9883, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-714.9470, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 33, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2875.4561, device='cuda:0')\n",
      "Residual states sum =  tensor(-714.9470, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-42853.9883, device='cuda:0')\n",
      "Hidden states sum =  tensor(3328.7588, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 7 called in free_generate mode with L = 33\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(3328.7588, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(3328.7588, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-96.9576, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 33, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(558.3522, device='cuda:0')\n",
      "Residual states sum =  tensor(-96.9576, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(3328.7588, device='cuda:0')\n",
      "Hidden states sum =  tensor(5181.3281, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 8 called in free_generate mode with L = 33\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(5181.3281, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(5181.3281, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(360.3393, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 33, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1170.5212, device='cuda:0')\n",
      "Residual states sum =  tensor(360.3393, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(5181.3281, device='cuda:0')\n",
      "Hidden states sum =  tensor(4043.9385, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 9 called in free_generate mode with L = 33\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(4043.9385, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(4043.9385, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(364.7906, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 33, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(284.7883, device='cuda:0')\n",
      "Residual states sum =  tensor(364.7906, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(4043.9385, device='cuda:0')\n",
      "Hidden states sum =  tensor(-941.8267, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 10 called in free_generate mode with L = 33\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-941.8267, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-941.8267, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-265.0877, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 33, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1507.7778, device='cuda:0')\n",
      "Residual states sum =  tensor(-265.0877, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-941.8267, device='cuda:0')\n",
      "Hidden states sum =  tensor(15090.9639, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 11 called in free_generate mode with L = 33\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(15090.9639, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(15090.9639, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(2436.7007, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 33, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2644.8452, device='cuda:0')\n",
      "Residual states sum =  tensor(2436.7007, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(15090.9639, device='cuda:0')\n",
      "Hidden states sum =  tensor(-6767.2388, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 12 called in free_generate mode with L = 33\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-6767.2388, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-6767.2388, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-726.0387, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 33, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-279.5135, device='cuda:0')\n",
      "Residual states sum =  tensor(-726.0387, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-6767.2388, device='cuda:0')\n",
      "Hidden states sum =  tensor(-2989.3228, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 13 called in free_generate mode with L = 33\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-2989.3228, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-2989.3228, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-274.0607, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 33, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2146.5874, device='cuda:0')\n",
      "Residual states sum =  tensor(-274.0607, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-2989.3228, device='cuda:0')\n",
      "Hidden states sum =  tensor(6633.4473, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 14 called in free_generate mode with L = 33\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(6633.4473, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(6633.4473, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1225.5916, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 33, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(5551.0830, device='cuda:0')\n",
      "Residual states sum =  tensor(1225.5916, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(6633.4473, device='cuda:0')\n",
      "Hidden states sum =  tensor(3920.6133, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 15 called in free_generate mode with L = 33\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(3920.6133, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(3920.6133, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(971.1906, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 33, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-5140.8330, device='cuda:0')\n",
      "Residual states sum =  tensor(971.1906, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(3920.6133, device='cuda:0')\n",
      "Hidden states sum =  tensor(7435.8955, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 16 called in free_generate mode with L = 33\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(7435.8955, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(7435.8955, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(977.3463, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 33, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-8552.6016, device='cuda:0')\n",
      "Residual states sum =  tensor(977.3463, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(7435.8955, device='cuda:0')\n",
      "Hidden states sum =  tensor(-19599.3340, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 17 called in free_generate mode with L = 33\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-19599.3340, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-19599.3340, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-960.5184, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 33, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(5684.3184, device='cuda:0')\n",
      "Residual states sum =  tensor(-960.5184, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-19599.3340, device='cuda:0')\n",
      "Hidden states sum =  tensor(63658.6914, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 18 called in free_generate mode with L = 33\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(63658.6914, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(63658.6914, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1979.5948, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 33, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(55.0244, device='cuda:0')\n",
      "Residual states sum =  tensor(1979.5948, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(63658.6914, device='cuda:0')\n",
      "Hidden states sum =  tensor(-13045.2129, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 19 called in free_generate mode with L = 33\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-13045.2129, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-13045.2129, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-642.6354, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 33, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1741.9399, device='cuda:0')\n",
      "Residual states sum =  tensor(-642.6354, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-13045.2129, device='cuda:0')\n",
      "Hidden states sum =  tensor(-12694.9834, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 20 called in free_generate mode with L = 33\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-12694.9834, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-12694.9834, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-196.2108, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 33, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(355.2893, device='cuda:0')\n",
      "Residual states sum =  tensor(-196.2108, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-12694.9834, device='cuda:0')\n",
      "Hidden states sum =  tensor(5465.5635, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 21 called in free_generate mode with L = 33\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(5465.5635, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(5465.5635, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-115.5410, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 33, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(5204.2246, device='cuda:0')\n",
      "Residual states sum =  tensor(-115.5410, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(5465.5635, device='cuda:0')\n",
      "Hidden states sum =  tensor(-5183.8877, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 22 called in free_generate mode with L = 33\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-5183.8877, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-5183.8877, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-33.2323, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 33, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2624.0522, device='cuda:0')\n",
      "Residual states sum =  tensor(-33.2323, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-5183.8877, device='cuda:0')\n",
      "Hidden states sum =  tensor(2109.6230, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 23 called in free_generate mode with L = 33\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(2109.6230, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(2109.6230, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(283.0748, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 33, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2959.5918, device='cuda:0')\n",
      "Residual states sum =  tensor(283.0748, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(2109.6230, device='cuda:0')\n",
      "Hidden states sum =  tensor(23389.5391, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 24 called in free_generate mode with L = 33\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(23389.5391, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(23389.5391, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(794.0673, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 33, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1859.3329, device='cuda:0')\n",
      "Residual states sum =  tensor(794.0673, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(23389.5391, device='cuda:0')\n",
      "Hidden states sum =  tensor(-12536.5859, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 25 called in free_generate mode with L = 33\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-12536.5859, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-12536.5859, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-747.0875, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 33, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(3473.1716, device='cuda:0')\n",
      "Residual states sum =  tensor(-747.0875, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-12536.5859, device='cuda:0')\n",
      "Hidden states sum =  tensor(-5386.3755, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 26 called in free_generate mode with L = 33\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-5386.3755, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-5386.3755, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-40.0381, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 33, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(8564.7754, device='cuda:0')\n",
      "Residual states sum =  tensor(-40.0381, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-5386.3755, device='cuda:0')\n",
      "Hidden states sum =  tensor(10831.7021, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 27 called in free_generate mode with L = 33\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(10831.7021, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(10831.7021, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-123.8254, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 33, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(14457.2744, device='cuda:0')\n",
      "Residual states sum =  tensor(-123.8254, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(10831.7021, device='cuda:0')\n",
      "Hidden states sum =  tensor(-9585.2324, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 0 called in free_generate mode with L = 34\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(17.0072, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(17.0072, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(123.7152, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 34, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(509.2081, device='cuda:0')\n",
      "Residual states sum =  tensor(123.7152, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(17.0072, device='cuda:0')\n",
      "Hidden states sum =  tensor(552.4261, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 1 called in free_generate mode with L = 34\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(552.4261, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(552.4261, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(139.0938, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 34, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(499.8825, device='cuda:0')\n",
      "Residual states sum =  tensor(139.0938, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(552.4261, device='cuda:0')\n",
      "Hidden states sum =  tensor(1378.2378, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 2 called in free_generate mode with L = 34\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(1378.2378, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(1378.2378, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(44.4446, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 34, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(144.8192, device='cuda:0')\n",
      "Residual states sum =  tensor(44.4446, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(1378.2378, device='cuda:0')\n",
      "Hidden states sum =  tensor(10826.1982, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 3 called in free_generate mode with L = 34\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(10826.1982, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(10826.1982, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(295.3941, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 34, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-703.9113, device='cuda:0')\n",
      "Residual states sum =  tensor(295.3941, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(10826.1982, device='cuda:0')\n",
      "Hidden states sum =  tensor(-7689.1426, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 4 called in free_generate mode with L = 34\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-7689.1426, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-7689.1426, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-485.4973, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 34, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1872.8000, device='cuda:0')\n",
      "Residual states sum =  tensor(-485.4973, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-7689.1426, device='cuda:0')\n",
      "Hidden states sum =  tensor(-13001.4072, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 5 called in free_generate mode with L = 34\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-13001.4072, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-13001.4072, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1226.8406, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 34, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1085.7200, device='cuda:0')\n",
      "Residual states sum =  tensor(-1226.8406, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-13001.4072, device='cuda:0')\n",
      "Hidden states sum =  tensor(-43941.7500, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 6 called in free_generate mode with L = 34\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-43941.7500, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-43941.7500, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-734.7430, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 34, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2954.0142, device='cuda:0')\n",
      "Residual states sum =  tensor(-734.7430, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-43941.7500, device='cuda:0')\n",
      "Hidden states sum =  tensor(3403.2043, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 7 called in free_generate mode with L = 34\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(3403.2043, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(3403.2043, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-98.9723, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 34, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(578.8688, device='cuda:0')\n",
      "Residual states sum =  tensor(-98.9723, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(3403.2043, device='cuda:0')\n",
      "Hidden states sum =  tensor(5361.4595, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 8 called in free_generate mode with L = 34\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(5361.4595, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(5361.4595, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(376.2419, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 34, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1201.5966, device='cuda:0')\n",
      "Residual states sum =  tensor(376.2419, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(5361.4595, device='cuda:0')\n",
      "Hidden states sum =  tensor(4179.6553, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 9 called in free_generate mode with L = 34\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(4179.6553, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(4179.6553, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(377.2596, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 34, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(282.1027, device='cuda:0')\n",
      "Residual states sum =  tensor(377.2596, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(4179.6553, device='cuda:0')\n",
      "Hidden states sum =  tensor(-975.2754, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 10 called in free_generate mode with L = 34\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-975.2754, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-975.2754, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-276.8421, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 34, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1565.3792, device='cuda:0')\n",
      "Residual states sum =  tensor(-276.8421, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-975.2754, device='cuda:0')\n",
      "Hidden states sum =  tensor(15539.7119, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 11 called in free_generate mode with L = 34\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(15539.7119, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(15539.7119, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(2510.2341, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 34, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2730.6316, device='cuda:0')\n",
      "Residual states sum =  tensor(2510.2341, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(15539.7119, device='cuda:0')\n",
      "Hidden states sum =  tensor(-6950.2144, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 12 called in free_generate mode with L = 34\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-6950.2144, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-6950.2144, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-745.3749, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 34, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-287.5017, device='cuda:0')\n",
      "Residual states sum =  tensor(-745.3749, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-6950.2144, device='cuda:0')\n",
      "Hidden states sum =  tensor(-3065.0339, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 13 called in free_generate mode with L = 34\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-3065.0339, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-3065.0339, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-281.2708, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 34, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2215.9045, device='cuda:0')\n",
      "Residual states sum =  tensor(-281.2708, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-3065.0339, device='cuda:0')\n",
      "Hidden states sum =  tensor(6844.1445, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 14 called in free_generate mode with L = 34\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(6844.1445, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(6844.1445, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1264.2581, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 34, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(5720.9346, device='cuda:0')\n",
      "Residual states sum =  tensor(1264.2581, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(6844.1445, device='cuda:0')\n",
      "Hidden states sum =  tensor(4039.1729, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 15 called in free_generate mode with L = 34\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(4039.1729, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(4039.1729, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1000.3210, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 34, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-5298.9297, device='cuda:0')\n",
      "Residual states sum =  tensor(1000.3210, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(4039.1729, device='cuda:0')\n",
      "Hidden states sum =  tensor(7650.8447, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 16 called in free_generate mode with L = 34\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(7650.8447, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(7650.8447, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1006.1811, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 34, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-8811.4707, device='cuda:0')\n",
      "Residual states sum =  tensor(1006.1811, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(7650.8447, device='cuda:0')\n",
      "Hidden states sum =  tensor(-20196.6191, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 17 called in free_generate mode with L = 34\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-20196.6191, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-20196.6191, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-989.8044, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 34, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(5856.6323, device='cuda:0')\n",
      "Residual states sum =  tensor(-989.8044, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-20196.6191, device='cuda:0')\n",
      "Hidden states sum =  tensor(65588.1719, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 18 called in free_generate mode with L = 34\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(65588.1719, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(65588.1719, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(2039.5746, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 34, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(56.7092, device='cuda:0')\n",
      "Residual states sum =  tensor(2039.5746, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(65588.1719, device='cuda:0')\n",
      "Hidden states sum =  tensor(-13440.7402, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 19 called in free_generate mode with L = 34\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-13440.7402, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-13440.7402, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-662.1173, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 34, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1794.7424, device='cuda:0')\n",
      "Residual states sum =  tensor(-662.1173, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-13440.7402, device='cuda:0')\n",
      "Hidden states sum =  tensor(-13079.7656, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 20 called in free_generate mode with L = 34\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-13079.7656, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-13079.7656, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-202.1614, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 34, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(366.0582, device='cuda:0')\n",
      "Residual states sum =  tensor(-202.1614, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-13079.7656, device='cuda:0')\n",
      "Hidden states sum =  tensor(5631.2153, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 21 called in free_generate mode with L = 34\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(5631.2153, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(5631.2153, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-119.0411, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 34, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(5361.9282, device='cuda:0')\n",
      "Residual states sum =  tensor(-119.0411, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(5631.2153, device='cuda:0')\n",
      "Hidden states sum =  tensor(-5340.9746, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 22 called in free_generate mode with L = 34\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-5340.9746, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-5340.9746, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-34.2394, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 34, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2703.5693, device='cuda:0')\n",
      "Residual states sum =  tensor(-34.2394, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-5340.9746, device='cuda:0')\n",
      "Hidden states sum =  tensor(2173.5459, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 23 called in free_generate mode with L = 34\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(2173.5459, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(2173.5459, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(291.6529, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 34, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(3049.2769, device='cuda:0')\n",
      "Residual states sum =  tensor(291.6529, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(2173.5459, device='cuda:0')\n",
      "Hidden states sum =  tensor(24098.3125, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 24 called in free_generate mode with L = 34\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(24098.3125, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(24098.3125, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(818.1298, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 34, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1915.6772, device='cuda:0')\n",
      "Residual states sum =  tensor(818.1298, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(24098.3125, device='cuda:0')\n",
      "Hidden states sum =  tensor(-12916.4824, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 25 called in free_generate mode with L = 34\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-12916.4824, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-12916.4824, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-769.7267, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 34, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(3578.4185, device='cuda:0')\n",
      "Residual states sum =  tensor(-769.7267, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-12916.4824, device='cuda:0')\n",
      "Hidden states sum =  tensor(-5549.6006, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 26 called in free_generate mode with L = 34\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-5549.6006, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-5549.6006, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-41.2513, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 34, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(8824.3145, device='cuda:0')\n",
      "Residual states sum =  tensor(-41.2513, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-5549.6006, device='cuda:0')\n",
      "Hidden states sum =  tensor(11159.9336, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 27 called in free_generate mode with L = 34\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(11159.9336, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(11159.9336, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-127.5778, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 34, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(14895.3740, device='cuda:0')\n",
      "Residual states sum =  tensor(-127.5778, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(11159.9336, device='cuda:0')\n",
      "Hidden states sum =  tensor(-9875.6914, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 0 called in free_generate mode with L = 35\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(17.3115, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(17.3115, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(123.2822, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 35, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(492.6697, device='cuda:0')\n",
      "Residual states sum =  tensor(123.2822, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(17.3115, device='cuda:0')\n",
      "Hidden states sum =  tensor(529.9186, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 1 called in free_generate mode with L = 35\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(529.9186, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(529.9186, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(127.6077, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 35, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(487.4626, device='cuda:0')\n",
      "Residual states sum =  tensor(127.6077, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(529.9186, device='cuda:0')\n",
      "Hidden states sum =  tensor(1371.4993, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 2 called in free_generate mode with L = 35\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(1371.4993, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(1371.4993, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(30.7637, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 35, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(186.8060, device='cuda:0')\n",
      "Residual states sum =  tensor(30.7637, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(1371.4993, device='cuda:0')\n",
      "Hidden states sum =  tensor(11372.8340, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 3 called in free_generate mode with L = 35\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(11372.8340, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(11372.8340, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(298.5841, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 35, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-745.1357, device='cuda:0')\n",
      "Residual states sum =  tensor(298.5841, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(11372.8340, device='cuda:0')\n",
      "Hidden states sum =  tensor(-7766.1318, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 4 called in free_generate mode with L = 35\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-7766.1318, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-7766.1318, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-496.0306, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 35, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1909.1643, device='cuda:0')\n",
      "Residual states sum =  tensor(-496.0306, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-7766.1318, device='cuda:0')\n",
      "Hidden states sum =  tensor(-13191.7686, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 5 called in free_generate mode with L = 35\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-13191.7686, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-13191.7686, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1248.1504, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 35, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1123.0348, device='cuda:0')\n",
      "Residual states sum =  tensor(-1248.1504, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-13191.7686, device='cuda:0')\n",
      "Hidden states sum =  tensor(-45127.0352, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 6 called in free_generate mode with L = 35\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-45127.0352, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-45127.0352, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-755.7966, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 35, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-3031.6514, device='cuda:0')\n",
      "Residual states sum =  tensor(-755.7966, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-45127.0352, device='cuda:0')\n",
      "Hidden states sum =  tensor(3478.7256, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 7 called in free_generate mode with L = 35\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(3478.7256, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(3478.7256, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-100.5829, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 35, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(599.8785, device='cuda:0')\n",
      "Residual states sum =  tensor(-100.5829, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(3478.7256, device='cuda:0')\n",
      "Hidden states sum =  tensor(5545.1914, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 8 called in free_generate mode with L = 35\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(5545.1914, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(5545.1914, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(392.6648, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 35, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1232.1062, device='cuda:0')\n",
      "Residual states sum =  tensor(392.6648, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(5545.1914, device='cuda:0')\n",
      "Hidden states sum =  tensor(4315.4595, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 9 called in free_generate mode with L = 35\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(4315.4595, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(4315.4595, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(389.8150, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 35, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(278.9999, device='cuda:0')\n",
      "Residual states sum =  tensor(389.8150, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(4315.4595, device='cuda:0')\n",
      "Hidden states sum =  tensor(-1008.5430, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 10 called in free_generate mode with L = 35\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-1008.5430, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-1008.5430, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-288.7126, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 35, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1623.9990, device='cuda:0')\n",
      "Residual states sum =  tensor(-288.7126, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-1008.5430, device='cuda:0')\n",
      "Hidden states sum =  tensor(15987.3701, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 11 called in free_generate mode with L = 35\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(15987.3701, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(15987.3701, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(2583.8574, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 35, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2816.5679, device='cuda:0')\n",
      "Residual states sum =  tensor(2583.8574, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(15987.3701, device='cuda:0')\n",
      "Hidden states sum =  tensor(-7131.8193, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 12 called in free_generate mode with L = 35\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-7131.8193, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-7131.8193, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-764.5778, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 35, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-295.4670, device='cuda:0')\n",
      "Residual states sum =  tensor(-764.5778, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-7131.8193, device='cuda:0')\n",
      "Hidden states sum =  tensor(-3139.3894, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 13 called in free_generate mode with L = 35\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-3139.3894, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-3139.3894, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-288.3859, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 35, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2285.8994, device='cuda:0')\n",
      "Residual states sum =  tensor(-288.3859, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-3139.3894, device='cuda:0')\n",
      "Hidden states sum =  tensor(7056.6538, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 14 called in free_generate mode with L = 35\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(7056.6538, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(7056.6538, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1303.1646, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 35, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(5890.9189, device='cuda:0')\n",
      "Residual states sum =  tensor(1303.1646, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(7056.6538, device='cuda:0')\n",
      "Hidden states sum =  tensor(4157.8359, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 15 called in free_generate mode with L = 35\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(4157.8359, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(4157.8359, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1029.4418, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 35, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-5457.3730, device='cuda:0')\n",
      "Residual states sum =  tensor(1029.4418, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(4157.8359, device='cuda:0')\n",
      "Hidden states sum =  tensor(7865.0239, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 16 called in free_generate mode with L = 35\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(7865.0239, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(7865.0239, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1034.9498, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 35, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-9070.3389, device='cuda:0')\n",
      "Residual states sum =  tensor(1034.9498, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(7865.0239, device='cuda:0')\n",
      "Hidden states sum =  tensor(-20794.5273, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 17 called in free_generate mode with L = 35\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-20794.5273, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-20794.5273, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1019.1245, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 35, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(6028.9443, device='cuda:0')\n",
      "Residual states sum =  tensor(-1019.1245, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-20794.5273, device='cuda:0')\n",
      "Hidden states sum =  tensor(67517.7188, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 18 called in free_generate mode with L = 35\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(67517.7188, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(67517.7188, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(2099.5542, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 35, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(58.3961, device='cuda:0')\n",
      "Residual states sum =  tensor(2099.5542, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(67517.7188, device='cuda:0')\n",
      "Hidden states sum =  tensor(-13836.2812, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 19 called in free_generate mode with L = 35\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-13836.2812, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-13836.2812, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-681.5996, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 35, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1847.5459, device='cuda:0')\n",
      "Residual states sum =  tensor(-681.5996, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-13836.2812, device='cuda:0')\n",
      "Hidden states sum =  tensor(-13464.5635, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 20 called in free_generate mode with L = 35\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-13464.5635, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-13464.5635, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-208.1128, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 35, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(376.8254, device='cuda:0')\n",
      "Residual states sum =  tensor(-208.1128, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-13464.5635, device='cuda:0')\n",
      "Hidden states sum =  tensor(5796.8682, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 21 called in free_generate mode with L = 35\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(5796.8682, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(5796.8682, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-122.5410, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 35, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(5519.6318, device='cuda:0')\n",
      "Residual states sum =  tensor(-122.5410, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(5796.8682, device='cuda:0')\n",
      "Hidden states sum =  tensor(-5498.0610, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 22 called in free_generate mode with L = 35\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-5498.0610, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-5498.0610, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-35.2463, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 35, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2783.0867, device='cuda:0')\n",
      "Residual states sum =  tensor(-35.2463, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-5498.0610, device='cuda:0')\n",
      "Hidden states sum =  tensor(2237.4727, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 23 called in free_generate mode with L = 35\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(2237.4727, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(2237.4727, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(300.2307, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 35, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(3138.9624, device='cuda:0')\n",
      "Residual states sum =  tensor(300.2307, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(2237.4727, device='cuda:0')\n",
      "Hidden states sum =  tensor(24807.0859, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 24 called in free_generate mode with L = 35\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(24807.0859, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(24807.0859, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(842.1925, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 35, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1972.0210, device='cuda:0')\n",
      "Residual states sum =  tensor(842.1925, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(24807.0859, device='cuda:0')\n",
      "Hidden states sum =  tensor(-13296.3789, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 25 called in free_generate mode with L = 35\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-13296.3789, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-13296.3789, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-792.3657, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 35, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(3683.6667, device='cuda:0')\n",
      "Residual states sum =  tensor(-792.3657, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-13296.3789, device='cuda:0')\n",
      "Hidden states sum =  tensor(-5712.8247, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 26 called in free_generate mode with L = 35\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-5712.8247, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-5712.8247, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-42.4647, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 35, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(9083.8535, device='cuda:0')\n",
      "Residual states sum =  tensor(-42.4647, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-5712.8247, device='cuda:0')\n",
      "Hidden states sum =  tensor(11488.1660, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 27 called in free_generate mode with L = 35\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(11488.1660, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(11488.1660, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-131.3305, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 35, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(15333.4707, device='cuda:0')\n",
      "Residual states sum =  tensor(-131.3305, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(11488.1660, device='cuda:0')\n",
      "Hidden states sum =  tensor(-10166.1572, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 0 called in free_generate mode with L = 36\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(18.3259, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(18.3259, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(126.9546, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 36, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(499.3284, device='cuda:0')\n",
      "Residual states sum =  tensor(126.9546, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(18.3259, device='cuda:0')\n",
      "Hidden states sum =  tensor(543.0610, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 1 called in free_generate mode with L = 36\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(543.0610, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(543.0610, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(134.7638, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 36, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(505.0490, device='cuda:0')\n",
      "Residual states sum =  tensor(134.7638, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(543.0610, device='cuda:0')\n",
      "Hidden states sum =  tensor(1388.2402, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 2 called in free_generate mode with L = 36\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(1388.2402, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(1388.2402, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(22.8688, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 36, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(263.2997, device='cuda:0')\n",
      "Residual states sum =  tensor(22.8688, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(1388.2402, device='cuda:0')\n",
      "Hidden states sum =  tensor(12148.7539, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 3 called in free_generate mode with L = 36\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(12148.7539, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(12148.7539, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(322.5565, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 36, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-773.0165, device='cuda:0')\n",
      "Residual states sum =  tensor(322.5565, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(12148.7539, device='cuda:0')\n",
      "Hidden states sum =  tensor(-7976.5156, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 4 called in free_generate mode with L = 36\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-7976.5156, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-7976.5156, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-510.9667, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 36, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1955.4514, device='cuda:0')\n",
      "Residual states sum =  tensor(-510.9667, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-7976.5156, device='cuda:0')\n",
      "Hidden states sum =  tensor(-13409.8965, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 5 called in free_generate mode with L = 36\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-13409.8965, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-13409.8965, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1270.9011, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 36, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1161.1848, device='cuda:0')\n",
      "Residual states sum =  tensor(-1270.9011, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-13409.8965, device='cuda:0')\n",
      "Hidden states sum =  tensor(-46276.7695, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 6 called in free_generate mode with L = 36\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-46276.7695, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-46276.7695, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-775.4760, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 36, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-3108.0808, device='cuda:0')\n",
      "Residual states sum =  tensor(-775.4760, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-46276.7695, device='cuda:0')\n",
      "Hidden states sum =  tensor(3545.9863, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 7 called in free_generate mode with L = 36\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(3545.9863, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(3545.9863, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-102.7768, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 36, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(621.7201, device='cuda:0')\n",
      "Residual states sum =  tensor(-102.7768, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(3545.9863, device='cuda:0')\n",
      "Hidden states sum =  tensor(5728.1494, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 8 called in free_generate mode with L = 36\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(5728.1494, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(5728.1494, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(409.2360, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 36, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1262.2023, device='cuda:0')\n",
      "Residual states sum =  tensor(409.2360, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(5728.1494, device='cuda:0')\n",
      "Hidden states sum =  tensor(4453.5825, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 9 called in free_generate mode with L = 36\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(4453.5825, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(4453.5825, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(402.7304, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 36, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(275.5636, device='cuda:0')\n",
      "Residual states sum =  tensor(402.7304, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(4453.5825, device='cuda:0')\n",
      "Hidden states sum =  tensor(-1041.5190, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 10 called in free_generate mode with L = 36\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-1041.5190, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-1041.5190, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-300.7532, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 36, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1683.5024, device='cuda:0')\n",
      "Residual states sum =  tensor(-300.7532, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-1041.5190, device='cuda:0')\n",
      "Hidden states sum =  tensor(16433.8633, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 11 called in free_generate mode with L = 36\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(16433.8633, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(16433.8633, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(2657.5298, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 36, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2902.5403, device='cuda:0')\n",
      "Residual states sum =  tensor(2657.5298, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(16433.8633, device='cuda:0')\n",
      "Hidden states sum =  tensor(-7311.7749, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 12 called in free_generate mode with L = 36\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-7311.7749, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-7311.7749, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-783.6224, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 36, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-303.3977, device='cuda:0')\n",
      "Residual states sum =  tensor(-783.6224, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-7311.7749, device='cuda:0')\n",
      "Hidden states sum =  tensor(-3212.5259, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 13 called in free_generate mode with L = 36\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-3212.5259, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-3212.5259, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-295.4169, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 36, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2356.6143, device='cuda:0')\n",
      "Residual states sum =  tensor(-295.4169, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-3212.5259, device='cuda:0')\n",
      "Hidden states sum =  tensor(7271.0308, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 14 called in free_generate mode with L = 36\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(7271.0308, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(7271.0308, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1342.3160, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 36, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(6061.0415, device='cuda:0')\n",
      "Residual states sum =  tensor(1342.3160, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(7271.0308, device='cuda:0')\n",
      "Hidden states sum =  tensor(4276.6748, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 15 called in free_generate mode with L = 36\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(4276.6748, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(4276.6748, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1058.5608, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 36, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-5616.1807, device='cuda:0')\n",
      "Residual states sum =  tensor(1058.5608, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(4276.6748, device='cuda:0')\n",
      "Hidden states sum =  tensor(8078.5005, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 16 called in free_generate mode with L = 36\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(8078.5005, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(8078.5005, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1063.6575, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 36, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-9329.2100, device='cuda:0')\n",
      "Residual states sum =  tensor(1063.6575, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(8078.5005, device='cuda:0')\n",
      "Hidden states sum =  tensor(-21393.1094, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 17 called in free_generate mode with L = 36\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-21393.1094, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-21393.1094, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1048.4791, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 36, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(6201.2524, device='cuda:0')\n",
      "Residual states sum =  tensor(-1048.4791, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-21393.1094, device='cuda:0')\n",
      "Hidden states sum =  tensor(69447.3906, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 18 called in free_generate mode with L = 36\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(69447.3906, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(69447.3906, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(2159.5337, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 36, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(60.0855, device='cuda:0')\n",
      "Residual states sum =  tensor(2159.5337, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(69447.3906, device='cuda:0')\n",
      "Hidden states sum =  tensor(-14231.8311, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 19 called in free_generate mode with L = 36\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-14231.8311, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-14231.8311, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-701.0816, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 36, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1900.3486, device='cuda:0')\n",
      "Residual states sum =  tensor(-701.0816, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-14231.8311, device='cuda:0')\n",
      "Hidden states sum =  tensor(-13849.3701, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 20 called in free_generate mode with L = 36\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-13849.3701, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-13849.3701, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-214.0649, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 36, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(387.5928, device='cuda:0')\n",
      "Residual states sum =  tensor(-214.0649, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-13849.3701, device='cuda:0')\n",
      "Hidden states sum =  tensor(5962.5259, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 21 called in free_generate mode with L = 36\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(5962.5259, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(5962.5259, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-126.0410, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 36, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(5677.3369, device='cuda:0')\n",
      "Residual states sum =  tensor(-126.0410, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(5962.5259, device='cuda:0')\n",
      "Hidden states sum =  tensor(-5655.1494, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 22 called in free_generate mode with L = 36\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-5655.1494, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-5655.1494, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-36.2535, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 36, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2862.6035, device='cuda:0')\n",
      "Residual states sum =  tensor(-36.2535, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-5655.1494, device='cuda:0')\n",
      "Hidden states sum =  tensor(2301.3926, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 23 called in free_generate mode with L = 36\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(2301.3926, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(2301.3926, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(308.8084, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 36, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(3228.6482, device='cuda:0')\n",
      "Residual states sum =  tensor(308.8084, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(2301.3926, device='cuda:0')\n",
      "Hidden states sum =  tensor(25515.8594, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 24 called in free_generate mode with L = 36\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(25515.8594, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(25515.8594, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(866.2550, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 36, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2028.3652, device='cuda:0')\n",
      "Residual states sum =  tensor(866.2550, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(25515.8594, device='cuda:0')\n",
      "Hidden states sum =  tensor(-13676.2773, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 25 called in free_generate mode with L = 36\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-13676.2773, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-13676.2773, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-815.0046, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 36, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(3788.9143, device='cuda:0')\n",
      "Residual states sum =  tensor(-815.0046, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-13676.2773, device='cuda:0')\n",
      "Hidden states sum =  tensor(-5876.0474, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 26 called in free_generate mode with L = 36\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-5876.0474, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-5876.0474, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-43.6780, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 36, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(9343.3906, device='cuda:0')\n",
      "Residual states sum =  tensor(-43.6780, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-5876.0474, device='cuda:0')\n",
      "Hidden states sum =  tensor(11816.3965, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 27 called in free_generate mode with L = 36\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(11816.3965, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(11816.3965, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-135.0828, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 36, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(15771.5703, device='cuda:0')\n",
      "Residual states sum =  tensor(-135.0828, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(11816.3965, device='cuda:0')\n",
      "Hidden states sum =  tensor(-10456.6162, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 0 called in free_generate mode with L = 37\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(18.0411, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(18.0411, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(126.5884, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 37, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(538.8246, device='cuda:0')\n",
      "Residual states sum =  tensor(126.5884, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(18.0411, device='cuda:0')\n",
      "Hidden states sum =  tensor(608.7234, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 1 called in free_generate mode with L = 37\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(608.7234, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(608.7234, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(145.5997, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 37, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(521.0867, device='cuda:0')\n",
      "Residual states sum =  tensor(145.5997, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(608.7234, device='cuda:0')\n",
      "Hidden states sum =  tensor(1351.8813, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 2 called in free_generate mode with L = 37\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(1351.8813, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(1351.8813, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(13.5851, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 37, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(284.4842, device='cuda:0')\n",
      "Residual states sum =  tensor(13.5851, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(1351.8813, device='cuda:0')\n",
      "Hidden states sum =  tensor(12516.6943, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 3 called in free_generate mode with L = 37\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(12516.6943, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(12516.6943, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(330.6628, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 37, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-821.2806, device='cuda:0')\n",
      "Residual states sum =  tensor(330.6628, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(12516.6943, device='cuda:0')\n",
      "Hidden states sum =  tensor(-8288.5801, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 4 called in free_generate mode with L = 37\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-8288.5801, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-8288.5801, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-537.6121, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 37, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2007.1663, device='cuda:0')\n",
      "Residual states sum =  tensor(-537.6121, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-8288.5801, device='cuda:0')\n",
      "Hidden states sum =  tensor(-13580.3359, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 5 called in free_generate mode with L = 37\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-13580.3359, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-13580.3359, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1289.9395, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 37, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1196.2075, device='cuda:0')\n",
      "Residual states sum =  tensor(-1289.9395, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-13580.3359, device='cuda:0')\n",
      "Hidden states sum =  tensor(-47365.9570, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 6 called in free_generate mode with L = 37\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-47365.9570, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-47365.9570, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-794.7834, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 37, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-3184.0403, device='cuda:0')\n",
      "Residual states sum =  tensor(-794.7834, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-47365.9570, device='cuda:0')\n",
      "Hidden states sum =  tensor(3609.3857, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 7 called in free_generate mode with L = 37\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(3609.3857, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(3609.3857, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-105.1517, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 37, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(644.1088, device='cuda:0')\n",
      "Residual states sum =  tensor(-105.1517, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(3609.3857, device='cuda:0')\n",
      "Hidden states sum =  tensor(5911.6904, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 8 called in free_generate mode with L = 37\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(5911.6904, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(5911.6904, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(426.2481, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 37, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1291.8574, device='cuda:0')\n",
      "Residual states sum =  tensor(426.2481, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(5911.6904, device='cuda:0')\n",
      "Hidden states sum =  tensor(4593.7012, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 9 called in free_generate mode with L = 37\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(4593.7012, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(4593.7012, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(415.9406, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 37, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(272.0405, device='cuda:0')\n",
      "Residual states sum =  tensor(415.9406, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(4593.7012, device='cuda:0')\n",
      "Hidden states sum =  tensor(-1072.7036, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 10 called in free_generate mode with L = 37\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-1072.7036, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-1072.7036, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-312.8213, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 37, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1743.6968, device='cuda:0')\n",
      "Residual states sum =  tensor(-312.8213, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-1072.7036, device='cuda:0')\n",
      "Hidden states sum =  tensor(16879.4590, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 11 called in free_generate mode with L = 37\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(16879.4590, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(16879.4590, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(2731.2866, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 37, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2988.4719, device='cuda:0')\n",
      "Residual states sum =  tensor(2731.2866, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(16879.4590, device='cuda:0')\n",
      "Hidden states sum =  tensor(-7489.9780, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 12 called in free_generate mode with L = 37\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-7489.9780, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-7489.9780, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-802.4990, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 37, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-311.2959, device='cuda:0')\n",
      "Residual states sum =  tensor(-802.4990, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-7489.9780, device='cuda:0')\n",
      "Hidden states sum =  tensor(-3284.4761, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 13 called in free_generate mode with L = 37\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-3284.4761, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-3284.4761, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-302.3632, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 37, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2428.0667, device='cuda:0')\n",
      "Residual states sum =  tensor(-302.3632, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-3284.4761, device='cuda:0')\n",
      "Hidden states sum =  tensor(7487.2588, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 14 called in free_generate mode with L = 37\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(7487.2588, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(7487.2588, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1381.7107, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 37, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(6231.3223, device='cuda:0')\n",
      "Residual states sum =  tensor(1381.7107, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(7487.2588, device='cuda:0')\n",
      "Hidden states sum =  tensor(4395.7402, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 15 called in free_generate mode with L = 37\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(4395.7402, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(4395.7402, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1087.6860, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 37, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-5775.3682, device='cuda:0')\n",
      "Residual states sum =  tensor(1087.6860, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(4395.7402, device='cuda:0')\n",
      "Hidden states sum =  tensor(8291.3447, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 16 called in free_generate mode with L = 37\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(8291.3447, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(8291.3447, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1092.3098, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 37, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-9588.0820, device='cuda:0')\n",
      "Residual states sum =  tensor(1092.3098, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(8291.3447, device='cuda:0')\n",
      "Hidden states sum =  tensor(-21992.3867, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 17 called in free_generate mode with L = 37\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-21992.3867, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-21992.3867, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1077.8679, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 37, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(6373.5586, device='cuda:0')\n",
      "Residual states sum =  tensor(-1077.8679, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-21992.3867, device='cuda:0')\n",
      "Hidden states sum =  tensor(71377.1406, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 18 called in free_generate mode with L = 37\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(71377.1406, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(71377.1406, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(2219.5129, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 37, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(61.7769, device='cuda:0')\n",
      "Residual states sum =  tensor(2219.5129, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(71377.1406, device='cuda:0')\n",
      "Hidden states sum =  tensor(-14627.3906, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 19 called in free_generate mode with L = 37\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-14627.3906, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-14627.3906, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-720.5635, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 37, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1953.1511, device='cuda:0')\n",
      "Residual states sum =  tensor(-720.5635, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-14627.3906, device='cuda:0')\n",
      "Hidden states sum =  tensor(-14234.1943, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 20 called in free_generate mode with L = 37\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-14234.1943, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-14234.1943, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-220.0182, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 37, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(398.3608, device='cuda:0')\n",
      "Residual states sum =  tensor(-220.0182, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-14234.1943, device='cuda:0')\n",
      "Hidden states sum =  tensor(6128.1802, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 21 called in free_generate mode with L = 37\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(6128.1802, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(6128.1802, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-129.5410, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 37, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(5835.0405, device='cuda:0')\n",
      "Residual states sum =  tensor(-129.5410, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(6128.1802, device='cuda:0')\n",
      "Hidden states sum =  tensor(-5812.2349, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 22 called in free_generate mode with L = 37\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-5812.2349, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-5812.2349, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-37.2606, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 37, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2942.1211, device='cuda:0')\n",
      "Residual states sum =  tensor(-37.2606, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-5812.2349, device='cuda:0')\n",
      "Hidden states sum =  tensor(2365.3115, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 23 called in free_generate mode with L = 37\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(2365.3115, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(2365.3115, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(317.3862, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 37, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(3318.3330, device='cuda:0')\n",
      "Residual states sum =  tensor(317.3862, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(2365.3115, device='cuda:0')\n",
      "Hidden states sum =  tensor(26224.6328, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 24 called in free_generate mode with L = 37\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(26224.6328, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(26224.6328, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(890.3176, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 37, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2084.7090, device='cuda:0')\n",
      "Residual states sum =  tensor(890.3176, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(26224.6328, device='cuda:0')\n",
      "Hidden states sum =  tensor(-14056.1738, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 25 called in free_generate mode with L = 37\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-14056.1738, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-14056.1738, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-837.6437, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 37, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(3894.1616, device='cuda:0')\n",
      "Residual states sum =  tensor(-837.6437, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-14056.1738, device='cuda:0')\n",
      "Hidden states sum =  tensor(-6039.2725, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 26 called in free_generate mode with L = 37\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-6039.2725, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-6039.2725, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-44.8914, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 37, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(9602.9297, device='cuda:0')\n",
      "Residual states sum =  tensor(-44.8914, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-6039.2725, device='cuda:0')\n",
      "Hidden states sum =  tensor(12144.6279, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 27 called in free_generate mode with L = 37\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(12144.6279, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(12144.6279, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-138.8355, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 37, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(16209.6699, device='cuda:0')\n",
      "Residual states sum =  tensor(-138.8355, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(12144.6279, device='cuda:0')\n",
      "Hidden states sum =  tensor(-10747.0771, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 0 called in free_generate mode with L = 38\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(17.4806, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(17.4806, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(124.4652, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 38, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(561.1844, device='cuda:0')\n",
      "Residual states sum =  tensor(124.4652, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(17.4806, device='cuda:0')\n",
      "Hidden states sum =  tensor(612.9448, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 1 called in free_generate mode with L = 38\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(612.9448, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(612.9448, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(151.5071, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 38, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(536.2493, device='cuda:0')\n",
      "Residual states sum =  tensor(151.5071, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(612.9448, device='cuda:0')\n",
      "Hidden states sum =  tensor(1331.5457, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 2 called in free_generate mode with L = 38\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(1331.5457, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(1331.5457, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(10.0679, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 38, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(301.9992, device='cuda:0')\n",
      "Residual states sum =  tensor(10.0679, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(1331.5457, device='cuda:0')\n",
      "Hidden states sum =  tensor(12542.4072, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 3 called in free_generate mode with L = 38\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(12542.4072, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(12542.4072, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(331.0630, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 38, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-854.0095, device='cuda:0')\n",
      "Residual states sum =  tensor(331.0630, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(12542.4072, device='cuda:0')\n",
      "Hidden states sum =  tensor(-8741.4805, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 4 called in free_generate mode with L = 38\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-8741.4805, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-8741.4805, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-567.4645, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 38, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2054.1187, device='cuda:0')\n",
      "Residual states sum =  tensor(-567.4645, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-8741.4805, device='cuda:0')\n",
      "Hidden states sum =  tensor(-13760.4102, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 5 called in free_generate mode with L = 38\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-13760.4102, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-13760.4102, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1309.4807, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 38, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1231.8470, device='cuda:0')\n",
      "Residual states sum =  tensor(-1309.4807, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-13760.4102, device='cuda:0')\n",
      "Hidden states sum =  tensor(-48509.1055, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 6 called in free_generate mode with L = 38\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-48509.1055, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-48509.1055, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-814.7744, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 38, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-3259.4700, device='cuda:0')\n",
      "Residual states sum =  tensor(-814.7744, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-48509.1055, device='cuda:0')\n",
      "Hidden states sum =  tensor(3668.8684, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 7 called in free_generate mode with L = 38\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(3668.8684, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(3668.8684, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-107.6777, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 38, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(666.7758, device='cuda:0')\n",
      "Residual states sum =  tensor(-107.6777, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(3668.8684, device='cuda:0')\n",
      "Hidden states sum =  tensor(6097.3101, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 8 called in free_generate mode with L = 38\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(6097.3101, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(6097.3101, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(444.0633, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 38, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1321.0398, device='cuda:0')\n",
      "Residual states sum =  tensor(444.0633, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(6097.3101, device='cuda:0')\n",
      "Hidden states sum =  tensor(4735.8086, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 9 called in free_generate mode with L = 38\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(4735.8086, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(4735.8086, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(429.4591, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 38, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(268.5705, device='cuda:0')\n",
      "Residual states sum =  tensor(429.4591, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(4735.8086, device='cuda:0')\n",
      "Hidden states sum =  tensor(-1101.5454, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 10 called in free_generate mode with L = 38\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-1101.5454, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-1101.5454, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-324.7945, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 38, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1804.4375, device='cuda:0')\n",
      "Residual states sum =  tensor(-324.7945, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-1101.5454, device='cuda:0')\n",
      "Hidden states sum =  tensor(17324.5723, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 11 called in free_generate mode with L = 38\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(17324.5723, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(17324.5723, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(2805.1702, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 38, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-3074.3459, device='cuda:0')\n",
      "Residual states sum =  tensor(2805.1702, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(17324.5723, device='cuda:0')\n",
      "Hidden states sum =  tensor(-7666.2383, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 12 called in free_generate mode with L = 38\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-7666.2383, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-7666.2383, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-821.1757, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 38, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-319.1814, device='cuda:0')\n",
      "Residual states sum =  tensor(-821.1757, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-7666.2383, device='cuda:0')\n",
      "Hidden states sum =  tensor(-3355.2102, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 13 called in free_generate mode with L = 38\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-3355.2102, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-3355.2102, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-309.2186, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 38, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2500.2544, device='cuda:0')\n",
      "Residual states sum =  tensor(-309.2186, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-3355.2102, device='cuda:0')\n",
      "Hidden states sum =  tensor(7705.1572, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 14 called in free_generate mode with L = 38\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(7705.1572, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(7705.1572, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1421.3295, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 38, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(6401.7871, device='cuda:0')\n",
      "Residual states sum =  tensor(1421.3295, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(7705.1572, device='cuda:0')\n",
      "Hidden states sum =  tensor(4515.0381, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 15 called in free_generate mode with L = 38\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(4515.0381, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(4515.0381, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1116.8226, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 38, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-5934.9512, device='cuda:0')\n",
      "Residual states sum =  tensor(1116.8226, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(4515.0381, device='cuda:0')\n",
      "Hidden states sum =  tensor(8503.6982, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 16 called in free_generate mode with L = 38\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(8503.6982, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(8503.6982, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1120.9205, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 38, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-9846.9561, device='cuda:0')\n",
      "Residual states sum =  tensor(1120.9205, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(8503.6982, device='cuda:0')\n",
      "Hidden states sum =  tensor(-22592.3652, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 17 called in free_generate mode with L = 38\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-22592.3652, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-22592.3652, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1107.2900, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 38, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(6545.8574, device='cuda:0')\n",
      "Residual states sum =  tensor(-1107.2900, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-22592.3652, device='cuda:0')\n",
      "Hidden states sum =  tensor(73306.9766, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 18 called in free_generate mode with L = 38\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(73306.9766, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(73306.9766, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(2279.4932, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 38, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(63.4706, device='cuda:0')\n",
      "Residual states sum =  tensor(2279.4932, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(73306.9766, device='cuda:0')\n",
      "Hidden states sum =  tensor(-15022.9678, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 19 called in free_generate mode with L = 38\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-15022.9678, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-15022.9678, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-740.0452, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 38, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2005.9536, device='cuda:0')\n",
      "Residual states sum =  tensor(-740.0452, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-15022.9678, device='cuda:0')\n",
      "Hidden states sum =  tensor(-14619.0322, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 20 called in free_generate mode with L = 38\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-14619.0322, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-14619.0322, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-225.9723, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 38, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(409.1279, device='cuda:0')\n",
      "Residual states sum =  tensor(-225.9723, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-14619.0322, device='cuda:0')\n",
      "Hidden states sum =  tensor(6293.8379, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 21 called in free_generate mode with L = 38\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(6293.8379, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(6293.8379, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-133.0408, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 38, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(5992.7451, device='cuda:0')\n",
      "Residual states sum =  tensor(-133.0408, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(6293.8379, device='cuda:0')\n",
      "Hidden states sum =  tensor(-5969.3223, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 22 called in free_generate mode with L = 38\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-5969.3223, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-5969.3223, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-38.2675, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 38, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-3021.6382, device='cuda:0')\n",
      "Residual states sum =  tensor(-38.2675, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-5969.3223, device='cuda:0')\n",
      "Hidden states sum =  tensor(2429.2383, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 23 called in free_generate mode with L = 38\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(2429.2383, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(2429.2383, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(325.9641, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 38, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(3408.0193, device='cuda:0')\n",
      "Residual states sum =  tensor(325.9641, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(2429.2383, device='cuda:0')\n",
      "Hidden states sum =  tensor(26933.4062, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 24 called in free_generate mode with L = 38\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(26933.4062, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(26933.4062, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(914.3801, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 38, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2141.0537, device='cuda:0')\n",
      "Residual states sum =  tensor(914.3801, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(26933.4062, device='cuda:0')\n",
      "Hidden states sum =  tensor(-14436.0684, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 25 called in free_generate mode with L = 38\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-14436.0684, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-14436.0684, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-860.2827, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 38, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(3999.4099, device='cuda:0')\n",
      "Residual states sum =  tensor(-860.2827, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-14436.0684, device='cuda:0')\n",
      "Hidden states sum =  tensor(-6202.4961, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 26 called in free_generate mode with L = 38\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-6202.4961, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-6202.4961, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-46.1045, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 38, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(9862.4688, device='cuda:0')\n",
      "Residual states sum =  tensor(-46.1045, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-6202.4961, device='cuda:0')\n",
      "Hidden states sum =  tensor(12472.8594, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 27 called in free_generate mode with L = 38\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(12472.8594, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(12472.8594, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-142.5882, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 38, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(16647.7676, device='cuda:0')\n",
      "Residual states sum =  tensor(-142.5882, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(12472.8594, device='cuda:0')\n",
      "Hidden states sum =  tensor(-11037.5410, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 0 called in free_generate mode with L = 39\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(19.6507, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(19.6507, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(137.1523, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 39, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(557.2910, device='cuda:0')\n",
      "Residual states sum =  tensor(137.1523, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(19.6507, device='cuda:0')\n",
      "Hidden states sum =  tensor(626.5961, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 1 called in free_generate mode with L = 39\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(626.5961, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(626.5961, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(161.9798, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 39, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(552.9080, device='cuda:0')\n",
      "Residual states sum =  tensor(161.9798, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(626.5961, device='cuda:0')\n",
      "Hidden states sum =  tensor(1336.0669, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 2 called in free_generate mode with L = 39\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(1336.0669, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(1336.0669, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(6.0039, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 39, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(274.8933, device='cuda:0')\n",
      "Residual states sum =  tensor(6.0039, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(1336.0669, device='cuda:0')\n",
      "Hidden states sum =  tensor(13475.6289, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 3 called in free_generate mode with L = 39\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(13475.6289, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(13475.6289, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(346.6693, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 39, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-926.3986, device='cuda:0')\n",
      "Residual states sum =  tensor(346.6693, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(13475.6289, device='cuda:0')\n",
      "Hidden states sum =  tensor(-9106.8916, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 4 called in free_generate mode with L = 39\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-9106.8916, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-9106.8916, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-590.4250, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 39, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2095.5366, device='cuda:0')\n",
      "Residual states sum =  tensor(-590.4250, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-9106.8916, device='cuda:0')\n",
      "Hidden states sum =  tensor(-13987.0684, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 5 called in free_generate mode with L = 39\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-13987.0684, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-13987.0684, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1331.0978, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 39, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1267.9255, device='cuda:0')\n",
      "Residual states sum =  tensor(-1331.0978, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-13987.0684, device='cuda:0')\n",
      "Hidden states sum =  tensor(-49645.6172, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 6 called in free_generate mode with L = 39\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-49645.6172, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-49645.6172, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-834.9502, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 39, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-3334.1799, device='cuda:0')\n",
      "Residual states sum =  tensor(-834.9502, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-49645.6172, device='cuda:0')\n",
      "Hidden states sum =  tensor(3728.4238, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 7 called in free_generate mode with L = 39\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(3728.4238, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(3728.4238, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-110.0736, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 39, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(689.4506, device='cuda:0')\n",
      "Residual states sum =  tensor(-110.0736, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(3728.4238, device='cuda:0')\n",
      "Hidden states sum =  tensor(6285.7153, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 8 called in free_generate mode with L = 39\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(6285.7153, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(6285.7153, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(462.4703, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 39, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1349.7354, device='cuda:0')\n",
      "Residual states sum =  tensor(462.4703, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(6285.7153, device='cuda:0')\n",
      "Hidden states sum =  tensor(4878.5498, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 9 called in free_generate mode with L = 39\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(4878.5498, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(4878.5498, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(443.0292, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 39, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(265.1199, device='cuda:0')\n",
      "Residual states sum =  tensor(443.0292, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(4878.5498, device='cuda:0')\n",
      "Hidden states sum =  tensor(-1128.6597, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 10 called in free_generate mode with L = 39\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-1128.6597, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-1128.6597, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-336.6826, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 39, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1865.8623, device='cuda:0')\n",
      "Residual states sum =  tensor(-336.6826, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-1128.6597, device='cuda:0')\n",
      "Hidden states sum =  tensor(17769.2578, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 11 called in free_generate mode with L = 39\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(17769.2578, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(17769.2578, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(2879.1829, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 39, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-3160.1931, device='cuda:0')\n",
      "Residual states sum =  tensor(2879.1829, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(17769.2578, device='cuda:0')\n",
      "Hidden states sum =  tensor(-7840.3936, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 12 called in free_generate mode with L = 39\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-7840.3936, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-7840.3936, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-839.6168, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 39, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-327.0759, device='cuda:0')\n",
      "Residual states sum =  tensor(-839.6168, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-7840.3936, device='cuda:0')\n",
      "Hidden states sum =  tensor(-3424.6003, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 13 called in free_generate mode with L = 39\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-3424.6003, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-3424.6003, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-315.9677, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 39, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2573.1646, device='cuda:0')\n",
      "Residual states sum =  tensor(-315.9677, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-3424.6003, device='cuda:0')\n",
      "Hidden states sum =  tensor(7924.5640, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 14 called in free_generate mode with L = 39\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(7924.5640, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(7924.5640, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1461.1572, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 39, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(6572.4736, device='cuda:0')\n",
      "Residual states sum =  tensor(1461.1572, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(7924.5640, device='cuda:0')\n",
      "Hidden states sum =  tensor(4634.4424, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 15 called in free_generate mode with L = 39\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(4634.4424, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(4634.4424, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1145.9556, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 39, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-6094.9419, device='cuda:0')\n",
      "Residual states sum =  tensor(1145.9556, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(4634.4424, device='cuda:0')\n",
      "Hidden states sum =  tensor(8715.7520, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 16 called in free_generate mode with L = 39\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(8715.7520, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(8715.7520, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1149.5085, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 39, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-10105.8213, device='cuda:0')\n",
      "Residual states sum =  tensor(1149.5085, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(8715.7520, device='cuda:0')\n",
      "Hidden states sum =  tensor(-23193.0605, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 17 called in free_generate mode with L = 39\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-23193.0605, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-23193.0605, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1136.7452, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 39, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(6718.1523, device='cuda:0')\n",
      "Residual states sum =  tensor(-1136.7452, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-23193.0605, device='cuda:0')\n",
      "Hidden states sum =  tensor(75236.9375, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 18 called in free_generate mode with L = 39\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(75236.9375, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(75236.9375, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(2339.4741, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 39, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(65.1666, device='cuda:0')\n",
      "Residual states sum =  tensor(2339.4741, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(75236.9375, device='cuda:0')\n",
      "Hidden states sum =  tensor(-15418.5596, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 19 called in free_generate mode with L = 39\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-15418.5596, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-15418.5596, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-759.5273, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 39, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2058.7556, device='cuda:0')\n",
      "Residual states sum =  tensor(-759.5273, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-15418.5596, device='cuda:0')\n",
      "Hidden states sum =  tensor(-15003.8760, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 20 called in free_generate mode with L = 39\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-15003.8760, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-15003.8760, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-231.9273, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 39, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(419.8950, device='cuda:0')\n",
      "Residual states sum =  tensor(-231.9273, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-15003.8760, device='cuda:0')\n",
      "Hidden states sum =  tensor(6459.4971, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 21 called in free_generate mode with L = 39\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(6459.4971, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(6459.4971, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-136.5406, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 39, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(6150.4492, device='cuda:0')\n",
      "Residual states sum =  tensor(-136.5406, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(6459.4971, device='cuda:0')\n",
      "Hidden states sum =  tensor(-6126.4111, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 22 called in free_generate mode with L = 39\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-6126.4111, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-6126.4111, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-39.2747, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 39, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-3101.1553, device='cuda:0')\n",
      "Residual states sum =  tensor(-39.2747, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-6126.4111, device='cuda:0')\n",
      "Hidden states sum =  tensor(2493.1582, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 23 called in free_generate mode with L = 39\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(2493.1582, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(2493.1582, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(334.5419, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 39, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(3497.7036, device='cuda:0')\n",
      "Residual states sum =  tensor(334.5419, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(2493.1582, device='cuda:0')\n",
      "Hidden states sum =  tensor(27642.1797, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 24 called in free_generate mode with L = 39\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(27642.1797, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(27642.1797, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(938.4427, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 39, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2197.3970, device='cuda:0')\n",
      "Residual states sum =  tensor(938.4427, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(27642.1797, device='cuda:0')\n",
      "Hidden states sum =  tensor(-14815.9629, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 25 called in free_generate mode with L = 39\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-14815.9629, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-14815.9629, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-882.9218, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 39, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(4104.6582, device='cuda:0')\n",
      "Residual states sum =  tensor(-882.9218, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-14815.9629, device='cuda:0')\n",
      "Hidden states sum =  tensor(-6365.7197, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 26 called in free_generate mode with L = 39\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-6365.7197, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-6365.7197, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-47.3179, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 39, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(10122.0078, device='cuda:0')\n",
      "Residual states sum =  tensor(-47.3179, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-6365.7197, device='cuda:0')\n",
      "Hidden states sum =  tensor(12801.0908, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 27 called in free_generate mode with L = 39\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(12801.0908, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(12801.0908, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-146.3404, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 39, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(17085.8672, device='cuda:0')\n",
      "Residual states sum =  tensor(-146.3404, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(12801.0908, device='cuda:0')\n",
      "Hidden states sum =  tensor(-11328., device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 0 called in free_generate mode with L = 40\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(20.9694, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(20.9694, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(148.1767, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 40, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(582.8530, device='cuda:0')\n",
      "Residual states sum =  tensor(148.1767, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(20.9694, device='cuda:0')\n",
      "Hidden states sum =  tensor(641.6301, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 1 called in free_generate mode with L = 40\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(641.6301, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(641.6301, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(168.6067, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 40, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(569.5391, device='cuda:0')\n",
      "Residual states sum =  tensor(168.6067, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(641.6301, device='cuda:0')\n",
      "Hidden states sum =  tensor(1332.9077, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 2 called in free_generate mode with L = 40\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(1332.9077, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(1332.9077, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-2.7124, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 40, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(235.4204, device='cuda:0')\n",
      "Residual states sum =  tensor(-2.7124, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(1332.9077, device='cuda:0')\n",
      "Hidden states sum =  tensor(13386.1426, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 3 called in free_generate mode with L = 40\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(13386.1426, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(13386.1426, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(339.2902, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 40, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-987.7511, device='cuda:0')\n",
      "Residual states sum =  tensor(339.2902, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(13386.1426, device='cuda:0')\n",
      "Hidden states sum =  tensor(-9371.1543, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 4 called in free_generate mode with L = 40\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-9371.1543, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-9371.1543, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-611.6089, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 40, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2134.7180, device='cuda:0')\n",
      "Residual states sum =  tensor(-611.6089, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-9371.1543, device='cuda:0')\n",
      "Hidden states sum =  tensor(-14179.2539, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 5 called in free_generate mode with L = 40\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-14179.2539, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-14179.2539, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1349.9072, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 40, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1299.9235, device='cuda:0')\n",
      "Residual states sum =  tensor(-1349.9072, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-14179.2539, device='cuda:0')\n",
      "Hidden states sum =  tensor(-50756.1016, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 6 called in free_generate mode with L = 40\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-50756.1016, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-50756.1016, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-855.1456, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 40, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-3407.6299, device='cuda:0')\n",
      "Residual states sum =  tensor(-855.1456, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-50756.1016, device='cuda:0')\n",
      "Hidden states sum =  tensor(3788.0618, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 7 called in free_generate mode with L = 40\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(3788.0618, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(3788.0618, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-112.3856, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 40, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(712.3187, device='cuda:0')\n",
      "Residual states sum =  tensor(-112.3856, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(3788.0618, device='cuda:0')\n",
      "Hidden states sum =  tensor(6478.7354, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 8 called in free_generate mode with L = 40\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(6478.7354, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(6478.7354, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(481.7231, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 40, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1377.7791, device='cuda:0')\n",
      "Residual states sum =  tensor(481.7231, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(6478.7354, device='cuda:0')\n",
      "Hidden states sum =  tensor(5021.0488, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 9 called in free_generate mode with L = 40\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(5021.0488, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(5021.0488, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(456.5880, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 40, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(261.4883, device='cuda:0')\n",
      "Residual states sum =  tensor(456.5880, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(5021.0488, device='cuda:0')\n",
      "Hidden states sum =  tensor(-1156.1309, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 10 called in free_generate mode with L = 40\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-1156.1309, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-1156.1309, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-348.7120, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 40, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1928.1580, device='cuda:0')\n",
      "Residual states sum =  tensor(-348.7120, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-1156.1309, device='cuda:0')\n",
      "Hidden states sum =  tensor(18213.5156, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 11 called in free_generate mode with L = 40\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(18213.5156, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(18213.5156, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(2953.2805, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 40, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-3246.0508, device='cuda:0')\n",
      "Residual states sum =  tensor(2953.2805, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(18213.5156, device='cuda:0')\n",
      "Hidden states sum =  tensor(-8012.3838, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 12 called in free_generate mode with L = 40\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-8012.3838, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-8012.3838, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-857.8225, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 40, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-334.9873, device='cuda:0')\n",
      "Residual states sum =  tensor(-857.8225, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-8012.3838, device='cuda:0')\n",
      "Hidden states sum =  tensor(-3492.5376, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 13 called in free_generate mode with L = 40\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-3492.5376, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-3492.5376, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-322.5964, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 40, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2646.7925, device='cuda:0')\n",
      "Residual states sum =  tensor(-322.5964, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-3492.5376, device='cuda:0')\n",
      "Hidden states sum =  tensor(8145.4419, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 14 called in free_generate mode with L = 40\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(8145.4419, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(8145.4419, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1501.1996, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 40, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(6743.4209, device='cuda:0')\n",
      "Residual states sum =  tensor(1501.1996, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(8145.4419, device='cuda:0')\n",
      "Hidden states sum =  tensor(4753.7012, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 15 called in free_generate mode with L = 40\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(4753.7012, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(4753.7012, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1175.0569, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 40, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-6255.3208, device='cuda:0')\n",
      "Residual states sum =  tensor(1175.0569, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(4753.7012, device='cuda:0')\n",
      "Hidden states sum =  tensor(8927.6035, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 16 called in free_generate mode with L = 40\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(8927.6035, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(8927.6035, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1178.0864, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 40, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-10364.6680, device='cuda:0')\n",
      "Residual states sum =  tensor(1178.0864, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(8927.6035, device='cuda:0')\n",
      "Hidden states sum =  tensor(-23794.4805, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 17 called in free_generate mode with L = 40\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-23794.4805, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-23794.4805, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1166.2323, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 40, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(6890.4385, device='cuda:0')\n",
      "Residual states sum =  tensor(-1166.2323, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-23794.4805, device='cuda:0')\n",
      "Hidden states sum =  tensor(77167.0078, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 18 called in free_generate mode with L = 40\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(77167.0078, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(77167.0078, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(2399.4556, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 40, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(66.8655, device='cuda:0')\n",
      "Residual states sum =  tensor(2399.4556, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(77167.0078, device='cuda:0')\n",
      "Hidden states sum =  tensor(-15814.1641, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 19 called in free_generate mode with L = 40\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-15814.1641, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-15814.1641, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-779.0093, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 40, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2111.5571, device='cuda:0')\n",
      "Residual states sum =  tensor(-779.0093, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-15814.1641, device='cuda:0')\n",
      "Hidden states sum =  tensor(-15388.7363, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 20 called in free_generate mode with L = 40\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-15388.7363, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-15388.7363, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-237.8834, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 40, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(430.6627, device='cuda:0')\n",
      "Residual states sum =  tensor(-237.8834, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-15388.7363, device='cuda:0')\n",
      "Hidden states sum =  tensor(6625.1543, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 21 called in free_generate mode with L = 40\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(6625.1543, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(6625.1543, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-140.0405, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 40, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(6308.1553, device='cuda:0')\n",
      "Residual states sum =  tensor(-140.0405, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(6625.1543, device='cuda:0')\n",
      "Hidden states sum =  tensor(-6283.4961, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 22 called in free_generate mode with L = 40\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-6283.4961, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-6283.4961, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-40.2816, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 40, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-3180.6726, device='cuda:0')\n",
      "Residual states sum =  tensor(-40.2816, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-6283.4961, device='cuda:0')\n",
      "Hidden states sum =  tensor(2557.0820, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 23 called in free_generate mode with L = 40\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(2557.0820, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(2557.0820, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(343.1196, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 40, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(3587.3892, device='cuda:0')\n",
      "Residual states sum =  tensor(343.1196, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(2557.0820, device='cuda:0')\n",
      "Hidden states sum =  tensor(28350.9531, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 24 called in free_generate mode with L = 40\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(28350.9531, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(28350.9531, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(962.5054, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 40, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2253.7400, device='cuda:0')\n",
      "Residual states sum =  tensor(962.5054, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(28350.9531, device='cuda:0')\n",
      "Hidden states sum =  tensor(-15195.8652, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 25 called in free_generate mode with L = 40\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-15195.8652, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-15195.8652, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-905.5607, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 40, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(4209.9058, device='cuda:0')\n",
      "Residual states sum =  tensor(-905.5607, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-15195.8652, device='cuda:0')\n",
      "Hidden states sum =  tensor(-6528.9458, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 26 called in free_generate mode with L = 40\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-6528.9458, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-6528.9458, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-48.5311, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 40, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(10381.5449, device='cuda:0')\n",
      "Residual states sum =  tensor(-48.5311, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-6528.9458, device='cuda:0')\n",
      "Hidden states sum =  tensor(13129.3223, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 27 called in free_generate mode with L = 40\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(13129.3223, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(13129.3223, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-150.0932, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 40, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(17523.9668, device='cuda:0')\n",
      "Residual states sum =  tensor(-150.0932, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(13129.3223, device='cuda:0')\n",
      "Hidden states sum =  tensor(-11618.4619, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 0 called in free_generate mode with L = 41\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(21.5576, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(21.5576, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(148.2686, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 41, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(608.5447, device='cuda:0')\n",
      "Residual states sum =  tensor(148.2686, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(21.5576, device='cuda:0')\n",
      "Hidden states sum =  tensor(663.1749, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 1 called in free_generate mode with L = 41\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(663.1749, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(663.1749, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(172.6190, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 41, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(582.0106, device='cuda:0')\n",
      "Residual states sum =  tensor(172.6190, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(663.1749, device='cuda:0')\n",
      "Hidden states sum =  tensor(1305.8394, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 2 called in free_generate mode with L = 41\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(1305.8394, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(1305.8394, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-6.9218, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 41, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(191.5661, device='cuda:0')\n",
      "Residual states sum =  tensor(-6.9218, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(1305.8394, device='cuda:0')\n",
      "Hidden states sum =  tensor(13327.4863, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 3 called in free_generate mode with L = 41\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(13327.4863, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(13327.4863, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(334.0093, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 41, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1045.6686, device='cuda:0')\n",
      "Residual states sum =  tensor(334.0093, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(13327.4863, device='cuda:0')\n",
      "Hidden states sum =  tensor(-9559.3301, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 4 called in free_generate mode with L = 41\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-9559.3301, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-9559.3301, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-626.9222, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 41, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2173.6628, device='cuda:0')\n",
      "Residual states sum =  tensor(-626.9222, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-9559.3301, device='cuda:0')\n",
      "Hidden states sum =  tensor(-14387.6484, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 5 called in free_generate mode with L = 41\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-14387.6484, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-14387.6484, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1372.4260, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 41, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1332.7461, device='cuda:0')\n",
      "Residual states sum =  tensor(-1372.4260, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-14387.6484, device='cuda:0')\n",
      "Hidden states sum =  tensor(-51984.6250, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 6 called in free_generate mode with L = 41\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-51984.6250, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-51984.6250, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-877.1805, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 41, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-3479.3823, device='cuda:0')\n",
      "Residual states sum =  tensor(-877.1805, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-51984.6250, device='cuda:0')\n",
      "Hidden states sum =  tensor(3847.6160, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 7 called in free_generate mode with L = 41\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(3847.6160, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(3847.6160, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-114.4584, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 41, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(735.0944, device='cuda:0')\n",
      "Residual states sum =  tensor(-114.4584, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(3847.6160, device='cuda:0')\n",
      "Hidden states sum =  tensor(6675.5879, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 8 called in free_generate mode with L = 41\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(6675.5879, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(6675.5879, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(501.6813, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 41, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1404.8638, device='cuda:0')\n",
      "Residual states sum =  tensor(501.6813, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(6675.5879, device='cuda:0')\n",
      "Hidden states sum =  tensor(5162.8462, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 9 called in free_generate mode with L = 41\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(5162.8462, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(5162.8462, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(470.1635, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 41, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(257.6791, device='cuda:0')\n",
      "Residual states sum =  tensor(470.1635, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(5162.8462, device='cuda:0')\n",
      "Hidden states sum =  tensor(-1184.8345, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 10 called in free_generate mode with L = 41\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-1184.8345, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-1184.8345, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-360.9583, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 41, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1991.3723, device='cuda:0')\n",
      "Residual states sum =  tensor(-360.9583, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-1184.8345, device='cuda:0')\n",
      "Hidden states sum =  tensor(18657.1133, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 11 called in free_generate mode with L = 41\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(18657.1133, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(18657.1133, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(3027.4214, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 41, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-3331.8784, device='cuda:0')\n",
      "Residual states sum =  tensor(3027.4214, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(18657.1133, device='cuda:0')\n",
      "Hidden states sum =  tensor(-8182.4199, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 12 called in free_generate mode with L = 41\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-8182.4199, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-8182.4199, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-875.8256, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 41, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-342.9099, device='cuda:0')\n",
      "Residual states sum =  tensor(-875.8256, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-8182.4199, device='cuda:0')\n",
      "Hidden states sum =  tensor(-3558.9897, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 13 called in free_generate mode with L = 41\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-3558.9897, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-3558.9897, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-329.1006, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 41, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2721.1729, device='cuda:0')\n",
      "Residual states sum =  tensor(-329.1006, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-3558.9897, device='cuda:0')\n",
      "Hidden states sum =  tensor(8367.9482, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 14 called in free_generate mode with L = 41\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(8367.9482, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(8367.9482, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1541.4812, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 41, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(6914.6665, device='cuda:0')\n",
      "Residual states sum =  tensor(1541.4812, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(8367.9482, device='cuda:0')\n",
      "Hidden states sum =  tensor(4872.6128, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 15 called in free_generate mode with L = 41\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(4872.6128, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(4872.6128, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1204.1049, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 41, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-6416.0620, device='cuda:0')\n",
      "Residual states sum =  tensor(1204.1049, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(4872.6128, device='cuda:0')\n",
      "Hidden states sum =  tensor(9139.2354, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 16 called in free_generate mode with L = 41\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(9139.2354, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(9139.2354, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1206.6578, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 41, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-10623.4834, device='cuda:0')\n",
      "Residual states sum =  tensor(1206.6578, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(9139.2354, device='cuda:0')\n",
      "Hidden states sum =  tensor(-24396.6543, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 17 called in free_generate mode with L = 41\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-24396.6543, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-24396.6543, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1195.7533, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 41, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(7062.7119, device='cuda:0')\n",
      "Residual states sum =  tensor(-1195.7533, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-24396.6543, device='cuda:0')\n",
      "Hidden states sum =  tensor(79097.2031, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 18 called in free_generate mode with L = 41\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(79097.2031, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(79097.2031, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(2459.4385, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 41, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(68.5667, device='cuda:0')\n",
      "Residual states sum =  tensor(2459.4385, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(79097.2031, device='cuda:0')\n",
      "Hidden states sum =  tensor(-16209.7822, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 19 called in free_generate mode with L = 41\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-16209.7822, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-16209.7822, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-798.4911, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 41, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2164.3608, device='cuda:0')\n",
      "Residual states sum =  tensor(-798.4911, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-16209.7822, device='cuda:0')\n",
      "Hidden states sum =  tensor(-15773.6055, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 20 called in free_generate mode with L = 41\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-15773.6055, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-15773.6055, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-243.8399, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 41, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(441.4305, device='cuda:0')\n",
      "Residual states sum =  tensor(-243.8399, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-15773.6055, device='cuda:0')\n",
      "Hidden states sum =  tensor(6790.8120, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 21 called in free_generate mode with L = 41\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(6790.8120, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(6790.8120, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-143.5403, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 41, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(6465.8589, device='cuda:0')\n",
      "Residual states sum =  tensor(-143.5403, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(6790.8120, device='cuda:0')\n",
      "Hidden states sum =  tensor(-6440.5840, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 22 called in free_generate mode with L = 41\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-6440.5840, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-6440.5840, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-41.2888, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 41, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-3260.1899, device='cuda:0')\n",
      "Residual states sum =  tensor(-41.2888, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-6440.5840, device='cuda:0')\n",
      "Hidden states sum =  tensor(2621.0010, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 23 called in free_generate mode with L = 41\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(2621.0010, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(2621.0010, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(351.6975, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 41, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(3677.0742, device='cuda:0')\n",
      "Residual states sum =  tensor(351.6975, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(2621.0010, device='cuda:0')\n",
      "Hidden states sum =  tensor(29059.7227, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 24 called in free_generate mode with L = 41\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(29059.7227, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(29059.7227, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(986.5679, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 41, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2310.0857, device='cuda:0')\n",
      "Residual states sum =  tensor(986.5679, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(29059.7227, device='cuda:0')\n",
      "Hidden states sum =  tensor(-15575.7568, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 25 called in free_generate mode with L = 41\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-15575.7568, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-15575.7568, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-928.1998, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 41, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(4315.1538, device='cuda:0')\n",
      "Residual states sum =  tensor(-928.1998, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-15575.7568, device='cuda:0')\n",
      "Hidden states sum =  tensor(-6692.1689, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 26 called in free_generate mode with L = 41\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-6692.1689, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-6692.1689, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-49.7445, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 41, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(10641.0850, device='cuda:0')\n",
      "Residual states sum =  tensor(-49.7445, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-6692.1689, device='cuda:0')\n",
      "Hidden states sum =  tensor(13457.5527, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 27 called in free_generate mode with L = 41\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(13457.5527, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(13457.5527, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-153.8456, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 41, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(17962.0664, device='cuda:0')\n",
      "Residual states sum =  tensor(-153.8456, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(13457.5527, device='cuda:0')\n",
      "Hidden states sum =  tensor(-11908.9219, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 0 called in free_generate mode with L = 42\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(20.9333, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(20.9333, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(151.0897, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 42, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(603.1509, device='cuda:0')\n",
      "Residual states sum =  tensor(151.0897, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(20.9333, device='cuda:0')\n",
      "Hidden states sum =  tensor(701.3171, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 1 called in free_generate mode with L = 42\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(701.3171, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(701.3171, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(180.7024, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 42, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(577.2357, device='cuda:0')\n",
      "Residual states sum =  tensor(180.7024, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(701.3171, device='cuda:0')\n",
      "Hidden states sum =  tensor(1195.4880, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 2 called in free_generate mode with L = 42\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(1195.4880, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(1195.4880, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-43.1867, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 42, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(187.9376, device='cuda:0')\n",
      "Residual states sum =  tensor(-43.1867, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(1195.4880, device='cuda:0')\n",
      "Hidden states sum =  tensor(14327.2832, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 3 called in free_generate mode with L = 42\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(14327.2832, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(14327.2832, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(351.2266, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 42, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1109.4574, device='cuda:0')\n",
      "Residual states sum =  tensor(351.2266, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(14327.2832, device='cuda:0')\n",
      "Hidden states sum =  tensor(-9732.8672, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 4 called in free_generate mode with L = 42\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-9732.8672, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-9732.8672, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-644.3784, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 42, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2225.4690, device='cuda:0')\n",
      "Residual states sum =  tensor(-644.3784, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-9732.8672, device='cuda:0')\n",
      "Hidden states sum =  tensor(-14555.7129, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 5 called in free_generate mode with L = 42\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-14555.7129, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-14555.7129, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1398.4913, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 42, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1346.6321, device='cuda:0')\n",
      "Residual states sum =  tensor(-1398.4913, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-14555.7129, device='cuda:0')\n",
      "Hidden states sum =  tensor(-53262.3906, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 6 called in free_generate mode with L = 42\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-53262.3906, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-53262.3906, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-901.4370, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 42, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-3550.0791, device='cuda:0')\n",
      "Residual states sum =  tensor(-901.4370, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-53262.3906, device='cuda:0')\n",
      "Hidden states sum =  tensor(3905.7148, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 7 called in free_generate mode with L = 42\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(3905.7148, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(3905.7148, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-116.4000, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 42, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(757.9242, device='cuda:0')\n",
      "Residual states sum =  tensor(-116.4000, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(3905.7148, device='cuda:0')\n",
      "Hidden states sum =  tensor(6873.5693, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 8 called in free_generate mode with L = 42\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(6873.5693, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(6873.5693, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(521.8915, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 42, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1430.6970, device='cuda:0')\n",
      "Residual states sum =  tensor(521.8915, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(6873.5693, device='cuda:0')\n",
      "Hidden states sum =  tensor(5302.6260, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 9 called in free_generate mode with L = 42\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(5302.6260, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(5302.6260, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(483.6432, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 42, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(253.7730, device='cuda:0')\n",
      "Residual states sum =  tensor(483.6432, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(5302.6260, device='cuda:0')\n",
      "Hidden states sum =  tensor(-1213.3398, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 10 called in free_generate mode with L = 42\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-1213.3398, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-1213.3398, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-373.3972, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 42, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2055.5208, device='cuda:0')\n",
      "Residual states sum =  tensor(-373.3972, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-1213.3398, device='cuda:0')\n",
      "Hidden states sum =  tensor(19100.1094, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 11 called in free_generate mode with L = 42\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(19100.1094, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(19100.1094, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(3101.5732, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 42, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-3417.6794, device='cuda:0')\n",
      "Residual states sum =  tensor(3101.5732, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(19100.1094, device='cuda:0')\n",
      "Hidden states sum =  tensor(-8350.6562, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 12 called in free_generate mode with L = 42\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-8350.6562, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-8350.6562, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-893.6446, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 42, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-350.8401, device='cuda:0')\n",
      "Residual states sum =  tensor(-893.6446, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-8350.6562, device='cuda:0')\n",
      "Hidden states sum =  tensor(-3623.8960, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 13 called in free_generate mode with L = 42\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-3623.8960, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-3623.8960, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-335.4705, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 42, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2796.3577, device='cuda:0')\n",
      "Residual states sum =  tensor(-335.4705, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-3623.8960, device='cuda:0')\n",
      "Hidden states sum =  tensor(8592.3232, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 14 called in free_generate mode with L = 42\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(8592.3232, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(8592.3232, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1582.0303, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 42, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(7086.2251, device='cuda:0')\n",
      "Residual states sum =  tensor(1582.0303, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(8592.3232, device='cuda:0')\n",
      "Hidden states sum =  tensor(4991.0986, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 15 called in free_generate mode with L = 42\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(4991.0986, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(4991.0986, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1233.0948, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 42, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-6577.1709, device='cuda:0')\n",
      "Residual states sum =  tensor(1233.0948, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(4991.0986, device='cuda:0')\n",
      "Hidden states sum =  tensor(9350.5781, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 16 called in free_generate mode with L = 42\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(9350.5781, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(9350.5781, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1235.2214, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 42, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-10882.2617, device='cuda:0')\n",
      "Residual states sum =  tensor(1235.2214, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(9350.5781, device='cuda:0')\n",
      "Hidden states sum =  tensor(-24999.6152, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 17 called in free_generate mode with L = 42\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-24999.6152, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-24999.6152, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1225.3088, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 42, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(7234.9727, device='cuda:0')\n",
      "Residual states sum =  tensor(-1225.3088, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-24999.6152, device='cuda:0')\n",
      "Hidden states sum =  tensor(81027.5781, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 18 called in free_generate mode with L = 42\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(81027.5781, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(81027.5781, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(2519.4219, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 42, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(70.2712, device='cuda:0')\n",
      "Residual states sum =  tensor(2519.4219, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(81027.5781, device='cuda:0')\n",
      "Hidden states sum =  tensor(-16605.4180, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 19 called in free_generate mode with L = 42\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-16605.4180, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-16605.4180, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-817.9727, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 42, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2217.1653, device='cuda:0')\n",
      "Residual states sum =  tensor(-817.9727, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-16605.4180, device='cuda:0')\n",
      "Hidden states sum =  tensor(-16158.4883, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 20 called in free_generate mode with L = 42\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-16158.4883, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-16158.4883, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-249.7973, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 42, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(452.1982, device='cuda:0')\n",
      "Residual states sum =  tensor(-249.7973, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-16158.4883, device='cuda:0')\n",
      "Hidden states sum =  tensor(6956.4795, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 21 called in free_generate mode with L = 42\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(6956.4795, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(6956.4795, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-147.0399, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 42, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(6623.5640, device='cuda:0')\n",
      "Residual states sum =  tensor(-147.0399, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(6956.4795, device='cuda:0')\n",
      "Hidden states sum =  tensor(-6597.6724, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 22 called in free_generate mode with L = 42\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-6597.6724, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-6597.6724, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-42.2958, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 42, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-3339.7070, device='cuda:0')\n",
      "Residual states sum =  tensor(-42.2958, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-6597.6724, device='cuda:0')\n",
      "Hidden states sum =  tensor(2684.9248, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 23 called in free_generate mode with L = 42\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(2684.9248, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(2684.9248, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(360.2753, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 42, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(3766.7603, device='cuda:0')\n",
      "Residual states sum =  tensor(360.2753, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(2684.9248, device='cuda:0')\n",
      "Hidden states sum =  tensor(29768.4980, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 24 called in free_generate mode with L = 42\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(29768.4980, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(29768.4980, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1010.6304, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 42, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2366.4290, device='cuda:0')\n",
      "Residual states sum =  tensor(1010.6304, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(29768.4980, device='cuda:0')\n",
      "Hidden states sum =  tensor(-15955.6523, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 25 called in free_generate mode with L = 42\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-15955.6523, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-15955.6523, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-950.8387, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 42, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(4420.4004, device='cuda:0')\n",
      "Residual states sum =  tensor(-950.8387, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-15955.6523, device='cuda:0')\n",
      "Hidden states sum =  tensor(-6855.3916, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 26 called in free_generate mode with L = 42\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-6855.3916, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-6855.3916, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-50.9578, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 42, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(10900.6221, device='cuda:0')\n",
      "Residual states sum =  tensor(-50.9578, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-6855.3916, device='cuda:0')\n",
      "Hidden states sum =  tensor(13785.7822, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 27 called in free_generate mode with L = 42\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(13785.7822, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(13785.7822, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-157.5983, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 42, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(18400.1660, device='cuda:0')\n",
      "Residual states sum =  tensor(-157.5983, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(13785.7822, device='cuda:0')\n",
      "Hidden states sum =  tensor(-12199.3789, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 0 called in free_generate mode with L = 43\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(20.3119, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(20.3119, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(152.1362, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 43, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(576.5157, device='cuda:0')\n",
      "Residual states sum =  tensor(152.1362, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(20.3119, device='cuda:0')\n",
      "Hidden states sum =  tensor(679.2472, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 1 called in free_generate mode with L = 43\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(679.2472, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(679.2472, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(178.2636, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 43, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(572.6074, device='cuda:0')\n",
      "Residual states sum =  tensor(178.2636, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(679.2472, device='cuda:0')\n",
      "Hidden states sum =  tensor(1095.9248, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 2 called in free_generate mode with L = 43\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(1095.9248, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(1095.9248, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-75.1690, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 43, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(202.4944, device='cuda:0')\n",
      "Residual states sum =  tensor(-75.1690, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(1095.9248, device='cuda:0')\n",
      "Hidden states sum =  tensor(15065.2285, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 3 called in free_generate mode with L = 43\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(15065.2285, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(15065.2285, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(357.7226, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 43, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1153.3784, device='cuda:0')\n",
      "Residual states sum =  tensor(357.7226, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(15065.2285, device='cuda:0')\n",
      "Hidden states sum =  tensor(-9964.3008, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 4 called in free_generate mode with L = 43\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-9964.3008, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-9964.3008, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-663.5903, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 43, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2267.6248, device='cuda:0')\n",
      "Residual states sum =  tensor(-663.5903, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-9964.3008, device='cuda:0')\n",
      "Hidden states sum =  tensor(-14708.3770, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 5 called in free_generate mode with L = 43\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-14708.3770, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-14708.3770, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1423.1716, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 43, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1357.0712, device='cuda:0')\n",
      "Residual states sum =  tensor(-1423.1716, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-14708.3770, device='cuda:0')\n",
      "Hidden states sum =  tensor(-54559.5938, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 6 called in free_generate mode with L = 43\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-54559.5938, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-54559.5938, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-925.6497, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 43, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-3621.0200, device='cuda:0')\n",
      "Residual states sum =  tensor(-925.6497, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-54559.5938, device='cuda:0')\n",
      "Hidden states sum =  tensor(3960.9282, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 7 called in free_generate mode with L = 43\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(3960.9282, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(3960.9282, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-118.2753, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 43, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(781.4767, device='cuda:0')\n",
      "Residual states sum =  tensor(-118.2753, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(3960.9282, device='cuda:0')\n",
      "Hidden states sum =  tensor(7075.5625, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 8 called in free_generate mode with L = 43\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(7075.5625, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(7075.5625, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(542.7893, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 43, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1454.9122, device='cuda:0')\n",
      "Residual states sum =  tensor(542.7893, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(7075.5625, device='cuda:0')\n",
      "Hidden states sum =  tensor(5440.7861, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 9 called in free_generate mode with L = 43\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(5440.7861, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(5440.7861, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(497.0609, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 43, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(249.7449, device='cuda:0')\n",
      "Residual states sum =  tensor(497.0609, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(5440.7861, device='cuda:0')\n",
      "Hidden states sum =  tensor(-1240.9937, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 10 called in free_generate mode with L = 43\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-1240.9937, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-1240.9937, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-385.8875, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 43, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2120.4497, device='cuda:0')\n",
      "Residual states sum =  tensor(-385.8875, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-1240.9937, device='cuda:0')\n",
      "Hidden states sum =  tensor(19543.0781, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 11 called in free_generate mode with L = 43\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(19543.0781, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(19543.0781, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(3175.7915, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 43, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-3503.4050, device='cuda:0')\n",
      "Residual states sum =  tensor(3175.7915, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(19543.0781, device='cuda:0')\n",
      "Hidden states sum =  tensor(-8517.3174, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 12 called in free_generate mode with L = 43\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-8517.3174, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-8517.3174, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-911.3223, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 43, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-358.7837, device='cuda:0')\n",
      "Residual states sum =  tensor(-911.3223, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-8517.3174, device='cuda:0')\n",
      "Hidden states sum =  tensor(-3687.2583, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 13 called in free_generate mode with L = 43\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-3687.2583, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-3687.2583, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-341.6969, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 43, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2872.3823, device='cuda:0')\n",
      "Residual states sum =  tensor(-341.6969, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-3687.2583, device='cuda:0')\n",
      "Hidden states sum =  tensor(8818.6289, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 14 called in free_generate mode with L = 43\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(8818.6289, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(8818.6289, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1622.8523, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 43, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(7258.1045, device='cuda:0')\n",
      "Residual states sum =  tensor(1622.8523, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(8818.6289, device='cuda:0')\n",
      "Hidden states sum =  tensor(5109.1680, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 15 called in free_generate mode with L = 43\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(5109.1680, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(5109.1680, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1262.0316, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 43, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-6738.6680, device='cuda:0')\n",
      "Residual states sum =  tensor(1262.0316, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(5109.1680, device='cuda:0')\n",
      "Hidden states sum =  tensor(9561.5498, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 16 called in free_generate mode with L = 43\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(9561.5498, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(9561.5498, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1263.7723, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 43, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-11141.0020, device='cuda:0')\n",
      "Residual states sum =  tensor(1263.7723, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(9561.5498, device='cuda:0')\n",
      "Hidden states sum =  tensor(-25603.3613, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 17 called in free_generate mode with L = 43\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-25603.3613, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-25603.3613, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1254.9011, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 43, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(7407.2188, device='cuda:0')\n",
      "Residual states sum =  tensor(-1254.9011, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-25603.3613, device='cuda:0')\n",
      "Hidden states sum =  tensor(82958.1250, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 18 called in free_generate mode with L = 43\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(82958.1250, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(82958.1250, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(2579.4077, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 43, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(71.9794, device='cuda:0')\n",
      "Residual states sum =  tensor(2579.4077, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(82958.1250, device='cuda:0')\n",
      "Hidden states sum =  tensor(-17001.0723, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 19 called in free_generate mode with L = 43\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-17001.0723, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-17001.0723, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-837.4536, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 43, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2269.9729, device='cuda:0')\n",
      "Residual states sum =  tensor(-837.4536, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-17001.0723, device='cuda:0')\n",
      "Hidden states sum =  tensor(-16543.3828, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 20 called in free_generate mode with L = 43\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-16543.3828, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-16543.3828, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-255.7553, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 43, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(462.9667, device='cuda:0')\n",
      "Residual states sum =  tensor(-255.7553, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-16543.3828, device='cuda:0')\n",
      "Hidden states sum =  tensor(7122.1484, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 21 called in free_generate mode with L = 43\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(7122.1484, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(7122.1484, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-150.5394, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 43, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(6781.2686, device='cuda:0')\n",
      "Residual states sum =  tensor(-150.5394, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(7122.1484, device='cuda:0')\n",
      "Hidden states sum =  tensor(-6754.7603, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 22 called in free_generate mode with L = 43\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-6754.7603, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-6754.7603, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-43.3030, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 43, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-3419.2249, device='cuda:0')\n",
      "Residual states sum =  tensor(-43.3030, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-6754.7603, device='cuda:0')\n",
      "Hidden states sum =  tensor(2748.8428, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 23 called in free_generate mode with L = 43\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(2748.8428, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(2748.8428, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(368.8530, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 43, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(3856.4453, device='cuda:0')\n",
      "Residual states sum =  tensor(368.8530, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(2748.8428, device='cuda:0')\n",
      "Hidden states sum =  tensor(30477.2734, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 24 called in free_generate mode with L = 43\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(30477.2734, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(30477.2734, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1034.6931, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 43, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2422.7729, device='cuda:0')\n",
      "Residual states sum =  tensor(1034.6931, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(30477.2734, device='cuda:0')\n",
      "Hidden states sum =  tensor(-16335.5518, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 25 called in free_generate mode with L = 43\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-16335.5518, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-16335.5518, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-973.4779, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 43, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(4525.6494, device='cuda:0')\n",
      "Residual states sum =  tensor(-973.4779, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-16335.5518, device='cuda:0')\n",
      "Hidden states sum =  tensor(-7018.6162, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 26 called in free_generate mode with L = 43\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-7018.6162, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-7018.6162, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-52.1711, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 43, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(11160.1621, device='cuda:0')\n",
      "Residual states sum =  tensor(-52.1711, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-7018.6162, device='cuda:0')\n",
      "Hidden states sum =  tensor(14114.0137, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 27 called in free_generate mode with L = 43\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(14114.0137, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(14114.0137, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-161.3510, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 43, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(18838.2637, device='cuda:0')\n",
      "Residual states sum =  tensor(-161.3510, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(14114.0137, device='cuda:0')\n",
      "Hidden states sum =  tensor(-12489.8408, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 0 called in free_generate mode with L = 44\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(21.1661, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(21.1661, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(161.5032, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 44, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(591.2736, device='cuda:0')\n",
      "Residual states sum =  tensor(161.5032, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(21.1661, device='cuda:0')\n",
      "Hidden states sum =  tensor(726.8682, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 1 called in free_generate mode with L = 44\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(726.8682, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(726.8682, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(180.0567, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 44, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(582.1854, device='cuda:0')\n",
      "Residual states sum =  tensor(180.0567, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(726.8682, device='cuda:0')\n",
      "Hidden states sum =  tensor(1043.2305, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 2 called in free_generate mode with L = 44\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(1043.2305, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(1043.2305, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-92.2792, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 44, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(175.8345, device='cuda:0')\n",
      "Residual states sum =  tensor(-92.2792, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(1043.2305, device='cuda:0')\n",
      "Hidden states sum =  tensor(15078.6445, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 3 called in free_generate mode with L = 44\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(15078.6445, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(15078.6445, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(349.6810, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 44, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1172.7422, device='cuda:0')\n",
      "Residual states sum =  tensor(349.6810, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(15078.6445, device='cuda:0')\n",
      "Hidden states sum =  tensor(-10306.5898, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 4 called in free_generate mode with L = 44\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-10306.5898, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-10306.5898, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-694.0428, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 44, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2311.6238, device='cuda:0')\n",
      "Residual states sum =  tensor(-694.0428, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-10306.5898, device='cuda:0')\n",
      "Hidden states sum =  tensor(-14810.4043, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 5 called in free_generate mode with L = 44\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-14810.4043, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-14810.4043, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1439.6788, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 44, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1356.0413, device='cuda:0')\n",
      "Residual states sum =  tensor(-1439.6788, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-14810.4043, device='cuda:0')\n",
      "Hidden states sum =  tensor(-55776.8672, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 6 called in free_generate mode with L = 44\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-55776.8672, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-55776.8672, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-948.7417, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 44, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-3691.7029, device='cuda:0')\n",
      "Residual states sum =  tensor(-948.7417, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-55776.8672, device='cuda:0')\n",
      "Hidden states sum =  tensor(4012.2747, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 7 called in free_generate mode with L = 44\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(4012.2747, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(4012.2747, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-120.2763, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 44, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(805.4499, device='cuda:0')\n",
      "Residual states sum =  tensor(-120.2763, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(4012.2747, device='cuda:0')\n",
      "Hidden states sum =  tensor(7272.3477, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 8 called in free_generate mode with L = 44\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(7272.3477, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(7272.3477, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(563.5667, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 44, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1477.7006, device='cuda:0')\n",
      "Residual states sum =  tensor(563.5667, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(7272.3477, device='cuda:0')\n",
      "Hidden states sum =  tensor(5575.7144, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 9 called in free_generate mode with L = 44\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(5575.7144, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(5575.7144, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(510.2067, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 44, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(245.6807, device='cuda:0')\n",
      "Residual states sum =  tensor(510.2067, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(5575.7144, device='cuda:0')\n",
      "Hidden states sum =  tensor(-1266.4297, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 10 called in free_generate mode with L = 44\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-1266.4297, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-1266.4297, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-398.2819, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 44, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2185.8630, device='cuda:0')\n",
      "Residual states sum =  tensor(-398.2819, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-1266.4297, device='cuda:0')\n",
      "Hidden states sum =  tensor(19987.2773, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 11 called in free_generate mode with L = 44\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(19987.2773, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(19987.2773, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(3250.1851, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 44, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-3589.0747, device='cuda:0')\n",
      "Residual states sum =  tensor(3250.1851, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(19987.2773, device='cuda:0')\n",
      "Hidden states sum =  tensor(-8682.6523, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 12 called in free_generate mode with L = 44\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-8682.6523, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-8682.6523, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-928.8809, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 44, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-366.7493, device='cuda:0')\n",
      "Residual states sum =  tensor(-928.8809, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-8682.6523, device='cuda:0')\n",
      "Hidden states sum =  tensor(-3749.1787, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 13 called in free_generate mode with L = 44\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-3749.1787, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-3749.1787, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-347.7769, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 44, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2949.2588, device='cuda:0')\n",
      "Residual states sum =  tensor(-347.7769, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-3749.1787, device='cuda:0')\n",
      "Hidden states sum =  tensor(9046.9766, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 14 called in free_generate mode with L = 44\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(9046.9766, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(9046.9766, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1663.9572, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 44, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(7430.3042, device='cuda:0')\n",
      "Residual states sum =  tensor(1663.9572, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(9046.9766, device='cuda:0')\n",
      "Hidden states sum =  tensor(5226.8755, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 15 called in free_generate mode with L = 44\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(5226.8755, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(5226.8755, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1290.9238, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 44, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-6900.5835, device='cuda:0')\n",
      "Residual states sum =  tensor(1290.9238, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(5226.8755, device='cuda:0')\n",
      "Hidden states sum =  tensor(9772.0576, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 16 called in free_generate mode with L = 44\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(9772.0576, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(9772.0576, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1292.3030, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 44, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-11399.6973, device='cuda:0')\n",
      "Residual states sum =  tensor(1292.3030, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(9772.0576, device='cuda:0')\n",
      "Hidden states sum =  tensor(-26207.8691, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 17 called in free_generate mode with L = 44\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-26207.8691, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-26207.8691, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1284.5280, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 44, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(7579.4507, device='cuda:0')\n",
      "Residual states sum =  tensor(-1284.5280, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-26207.8691, device='cuda:0')\n",
      "Hidden states sum =  tensor(84888.8750, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 18 called in free_generate mode with L = 44\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(84888.8750, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(84888.8750, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(2639.3955, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 44, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(73.6919, device='cuda:0')\n",
      "Residual states sum =  tensor(2639.3955, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(84888.8750, device='cuda:0')\n",
      "Hidden states sum =  tensor(-17396.7402, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 19 called in free_generate mode with L = 44\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-17396.7402, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-17396.7402, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-856.9343, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 44, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2322.7847, device='cuda:0')\n",
      "Residual states sum =  tensor(-856.9343, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-17396.7402, device='cuda:0')\n",
      "Hidden states sum =  tensor(-16928.2891, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 20 called in free_generate mode with L = 44\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-16928.2891, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-16928.2891, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-261.7142, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 44, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(473.7350, device='cuda:0')\n",
      "Residual states sum =  tensor(-261.7142, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-16928.2891, device='cuda:0')\n",
      "Hidden states sum =  tensor(7287.8198, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 21 called in free_generate mode with L = 44\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(7287.8198, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(7287.8198, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-154.0386, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 44, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(6938.9741, device='cuda:0')\n",
      "Residual states sum =  tensor(-154.0386, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(7287.8198, device='cuda:0')\n",
      "Hidden states sum =  tensor(-6911.8501, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 22 called in free_generate mode with L = 44\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-6911.8501, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-6911.8501, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-44.3100, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 44, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-3498.7417, device='cuda:0')\n",
      "Residual states sum =  tensor(-44.3100, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-6911.8501, device='cuda:0')\n",
      "Hidden states sum =  tensor(2812.7637, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 23 called in free_generate mode with L = 44\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(2812.7637, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(2812.7637, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(377.4307, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 44, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(3946.1306, device='cuda:0')\n",
      "Residual states sum =  tensor(377.4307, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(2812.7637, device='cuda:0')\n",
      "Hidden states sum =  tensor(31186.0449, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 24 called in free_generate mode with L = 44\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(31186.0449, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(31186.0449, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1058.7554, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 44, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2479.1167, device='cuda:0')\n",
      "Residual states sum =  tensor(1058.7554, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(31186.0449, device='cuda:0')\n",
      "Hidden states sum =  tensor(-16715.4453, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 25 called in free_generate mode with L = 44\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-16715.4453, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-16715.4453, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-996.1169, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 44, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(4630.8970, device='cuda:0')\n",
      "Residual states sum =  tensor(-996.1169, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-16715.4453, device='cuda:0')\n",
      "Hidden states sum =  tensor(-7181.8428, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 26 called in free_generate mode with L = 44\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-7181.8428, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-7181.8428, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-53.3843, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 44, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(11419.6992, device='cuda:0')\n",
      "Residual states sum =  tensor(-53.3843, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-7181.8428, device='cuda:0')\n",
      "Hidden states sum =  tensor(14442.2461, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 27 called in free_generate mode with L = 44\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(14442.2461, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(14442.2461, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-165.1035, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 44, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(19276.3633, device='cuda:0')\n",
      "Residual states sum =  tensor(-165.1035, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(14442.2461, device='cuda:0')\n",
      "Hidden states sum =  tensor(-12780.3066, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 0 called in free_generate mode with L = 45\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(21.7543, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(21.7543, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(161.5951, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 45, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(619.5396, device='cuda:0')\n",
      "Residual states sum =  tensor(161.5951, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(21.7543, device='cuda:0')\n",
      "Hidden states sum =  tensor(719.0852, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 1 called in free_generate mode with L = 45\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(719.0852, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(719.0852, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(178.8341, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 45, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(571.7383, device='cuda:0')\n",
      "Residual states sum =  tensor(178.8341, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(719.0852, device='cuda:0')\n",
      "Hidden states sum =  tensor(1086.4539, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 2 called in free_generate mode with L = 45\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(1086.4539, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(1086.4539, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-79.4538, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 45, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(204.5165, device='cuda:0')\n",
      "Residual states sum =  tensor(-79.4538, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(1086.4539, device='cuda:0')\n",
      "Hidden states sum =  tensor(15607.9463, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 3 called in free_generate mode with L = 45\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(15607.9463, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(15607.9463, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(350.3235, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 45, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1208.0947, device='cuda:0')\n",
      "Residual states sum =  tensor(350.3235, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(15607.9463, device='cuda:0')\n",
      "Hidden states sum =  tensor(-10565.7803, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 4 called in free_generate mode with L = 45\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-10565.7803, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-10565.7803, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-718.7499, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 45, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2350.1152, device='cuda:0')\n",
      "Residual states sum =  tensor(-718.7499, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-10565.7803, device='cuda:0')\n",
      "Hidden states sum =  tensor(-14885.3018, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 5 called in free_generate mode with L = 45\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-14885.3018, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-14885.3018, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1454.6807, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 45, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1353.5564, device='cuda:0')\n",
      "Residual states sum =  tensor(-1454.6807, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-14885.3018, device='cuda:0')\n",
      "Hidden states sum =  tensor(-57021.1875, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 6 called in free_generate mode with L = 45\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-57021.1875, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-57021.1875, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-972.3982, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 45, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-3762.1094, device='cuda:0')\n",
      "Residual states sum =  tensor(-972.3982, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-57021.1875, device='cuda:0')\n",
      "Hidden states sum =  tensor(4064.4336, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 7 called in free_generate mode with L = 45\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(4064.4336, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(4064.4336, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-122.0631, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 45, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(829.6598, device='cuda:0')\n",
      "Residual states sum =  tensor(-122.0631, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(4064.4336, device='cuda:0')\n",
      "Hidden states sum =  tensor(7469.1567, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 8 called in free_generate mode with L = 45\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(7469.1567, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(7469.1567, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(584.6733, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 45, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1499.3782, device='cuda:0')\n",
      "Residual states sum =  tensor(584.6733, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(7469.1567, device='cuda:0')\n",
      "Hidden states sum =  tensor(5707.6279, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 9 called in free_generate mode with L = 45\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(5707.6279, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(5707.6279, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(523.1121, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 45, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(241.6664, device='cuda:0')\n",
      "Residual states sum =  tensor(523.1121, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(5707.6279, device='cuda:0')\n",
      "Hidden states sum =  tensor(-1289.0547, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 10 called in free_generate mode with L = 45\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-1289.0547, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-1289.0547, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-410.3136, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 45, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2251.5996, device='cuda:0')\n",
      "Residual states sum =  tensor(-410.3136, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-1289.0547, device='cuda:0')\n",
      "Hidden states sum =  tensor(20432.0957, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 11 called in free_generate mode with L = 45\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(20432.0957, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(20432.0957, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(3324.7107, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 45, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-3674.5776, device='cuda:0')\n",
      "Residual states sum =  tensor(3324.7107, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(20432.0957, device='cuda:0')\n",
      "Hidden states sum =  tensor(-8847.3203, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 12 called in free_generate mode with L = 45\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-8847.3203, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-8847.3203, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-946.4095, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 45, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-374.7656, device='cuda:0')\n",
      "Residual states sum =  tensor(-946.4095, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-8847.3203, device='cuda:0')\n",
      "Hidden states sum =  tensor(-3809.4797, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 13 called in free_generate mode with L = 45\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-3809.4797, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-3809.4797, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-353.6977, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 45, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(3026.9634, device='cuda:0')\n",
      "Residual states sum =  tensor(-353.6977, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-3809.4797, device='cuda:0')\n",
      "Hidden states sum =  tensor(9277.2666, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 14 called in free_generate mode with L = 45\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(9277.2666, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(9277.2666, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1705.3462, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 45, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(7602.8086, device='cuda:0')\n",
      "Residual states sum =  tensor(1705.3462, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(9277.2666, device='cuda:0')\n",
      "Hidden states sum =  tensor(5344.1899, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 15 called in free_generate mode with L = 45\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(5344.1899, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(5344.1899, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1319.7676, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 45, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-7062.9189, device='cuda:0')\n",
      "Residual states sum =  tensor(1319.7676, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(5344.1899, device='cuda:0')\n",
      "Hidden states sum =  tensor(9982.1240, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 16 called in free_generate mode with L = 45\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(9982.1240, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(9982.1240, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1320.8151, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 45, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-11658.3281, device='cuda:0')\n",
      "Residual states sum =  tensor(1320.8151, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(9982.1240, device='cuda:0')\n",
      "Hidden states sum =  tensor(-26812.9980, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 17 called in free_generate mode with L = 45\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-26812.9980, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-26812.9980, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1314.1777, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 45, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(7751.6738, device='cuda:0')\n",
      "Residual states sum =  tensor(-1314.1777, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-26812.9980, device='cuda:0')\n",
      "Hidden states sum =  tensor(86819.7422, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 18 called in free_generate mode with L = 45\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(86819.7422, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(86819.7422, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(2699.3835, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 45, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(75.4108, device='cuda:0')\n",
      "Residual states sum =  tensor(2699.3835, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(86819.7422, device='cuda:0')\n",
      "Hidden states sum =  tensor(-17792.4258, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 19 called in free_generate mode with L = 45\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-17792.4258, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-17792.4258, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-876.4146, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 45, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2375.5979, device='cuda:0')\n",
      "Residual states sum =  tensor(-876.4146, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-17792.4258, device='cuda:0')\n",
      "Hidden states sum =  tensor(-17313.2070, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 20 called in free_generate mode with L = 45\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-17313.2070, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-17313.2070, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-267.6740, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 45, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(484.5051, device='cuda:0')\n",
      "Residual states sum =  tensor(-267.6740, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-17313.2070, device='cuda:0')\n",
      "Hidden states sum =  tensor(7453.4966, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 21 called in free_generate mode with L = 45\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(7453.4966, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(7453.4966, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-157.5378, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 45, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(7096.6777, device='cuda:0')\n",
      "Residual states sum =  tensor(-157.5378, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(7453.4966, device='cuda:0')\n",
      "Hidden states sum =  tensor(-7068.9355, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 22 called in free_generate mode with L = 45\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-7068.9355, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-7068.9355, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-45.3171, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 45, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-3578.2593, device='cuda:0')\n",
      "Residual states sum =  tensor(-45.3171, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-7068.9355, device='cuda:0')\n",
      "Hidden states sum =  tensor(2876.6875, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 23 called in free_generate mode with L = 45\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(2876.6875, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(2876.6875, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(386.0082, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 45, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(4035.8167, device='cuda:0')\n",
      "Residual states sum =  tensor(386.0082, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(2876.6875, device='cuda:0')\n",
      "Hidden states sum =  tensor(31894.8164, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 24 called in free_generate mode with L = 45\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(31894.8164, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(31894.8164, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1082.8181, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 45, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2535.4614, device='cuda:0')\n",
      "Residual states sum =  tensor(1082.8181, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(31894.8164, device='cuda:0')\n",
      "Hidden states sum =  tensor(-17095.3438, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 25 called in free_generate mode with L = 45\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-17095.3438, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-17095.3438, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1018.7558, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 45, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(4736.1455, device='cuda:0')\n",
      "Residual states sum =  tensor(-1018.7558, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-17095.3438, device='cuda:0')\n",
      "Hidden states sum =  tensor(-7345.0664, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 26 called in free_generate mode with L = 45\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-7345.0664, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-7345.0664, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-54.5976, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 45, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(11679.2393, device='cuda:0')\n",
      "Residual states sum =  tensor(-54.5976, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-7345.0664, device='cuda:0')\n",
      "Hidden states sum =  tensor(14770.4756, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 27 called in free_generate mode with L = 45\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(14770.4756, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(14770.4756, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-168.8561, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 45, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(19714.4609, device='cuda:0')\n",
      "Residual states sum =  tensor(-168.8561, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(14770.4756, device='cuda:0')\n",
      "Hidden states sum =  tensor(-13070.7656, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 0 called in free_generate mode with L = 46\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(22.3426, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(22.3426, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(161.6870, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 46, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(648.7814, device='cuda:0')\n",
      "Residual states sum =  tensor(161.6870, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(22.3426, device='cuda:0')\n",
      "Hidden states sum =  tensor(711.2701, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 1 called in free_generate mode with L = 46\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(711.2701, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(711.2701, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(180.8475, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 46, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(576.2417, device='cuda:0')\n",
      "Residual states sum =  tensor(180.8475, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(711.2701, device='cuda:0')\n",
      "Hidden states sum =  tensor(1103.5537, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 2 called in free_generate mode with L = 46\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(1103.5537, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(1103.5537, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-65.1635, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 46, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(224.5623, device='cuda:0')\n",
      "Residual states sum =  tensor(-65.1635, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(1103.5537, device='cuda:0')\n",
      "Hidden states sum =  tensor(16780.6875, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 3 called in free_generate mode with L = 46\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(16780.6875, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(16780.6875, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(364.4330, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 46, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1264.8330, device='cuda:0')\n",
      "Residual states sum =  tensor(364.4330, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(16780.6875, device='cuda:0')\n",
      "Hidden states sum =  tensor(-10856.1387, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 4 called in free_generate mode with L = 46\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-10856.1387, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-10856.1387, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-743.6437, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 46, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2388.6802, device='cuda:0')\n",
      "Residual states sum =  tensor(-743.6437, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-10856.1387, device='cuda:0')\n",
      "Hidden states sum =  tensor(-14963.1904, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 5 called in free_generate mode with L = 46\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-14963.1904, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-14963.1904, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1469.2000, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 46, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1351.5092, device='cuda:0')\n",
      "Residual states sum =  tensor(-1469.2000, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-14963.1904, device='cuda:0')\n",
      "Hidden states sum =  tensor(-58278.1406, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 6 called in free_generate mode with L = 46\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-58278.1406, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-58278.1406, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-996.1351, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 46, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-3832.9421, device='cuda:0')\n",
      "Residual states sum =  tensor(-996.1351, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-58278.1406, device='cuda:0')\n",
      "Hidden states sum =  tensor(4110.7852, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 7 called in free_generate mode with L = 46\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(4110.7852, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(4110.7852, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-124.2691, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 46, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(853.8022, device='cuda:0')\n",
      "Residual states sum =  tensor(-124.2691, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(4110.7852, device='cuda:0')\n",
      "Hidden states sum =  tensor(7665.6201, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 8 called in free_generate mode with L = 46\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(7665.6201, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(7665.6201, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(606.1177, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 46, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1520.1663, device='cuda:0')\n",
      "Residual states sum =  tensor(606.1177, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(7665.6201, device='cuda:0')\n",
      "Hidden states sum =  tensor(5837.2573, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 9 called in free_generate mode with L = 46\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(5837.2573, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(5837.2573, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(535.8528, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 46, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(237.3365, device='cuda:0')\n",
      "Residual states sum =  tensor(535.8528, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(5837.2573, device='cuda:0')\n",
      "Hidden states sum =  tensor(-1310.5723, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 10 called in free_generate mode with L = 46\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-1310.5723, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-1310.5723, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-422.1512, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 46, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2317.7437, device='cuda:0')\n",
      "Residual states sum =  tensor(-422.1512, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-1310.5723, device='cuda:0')\n",
      "Hidden states sum =  tensor(20876.5664, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 11 called in free_generate mode with L = 46\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(20876.5664, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(20876.5664, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(3399.2329, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 46, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-3759.9211, device='cuda:0')\n",
      "Residual states sum =  tensor(3399.2329, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(20876.5664, device='cuda:0')\n",
      "Hidden states sum =  tensor(-9011.1699, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 12 called in free_generate mode with L = 46\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-9011.1699, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-9011.1699, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-963.8799, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 46, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-382.8831, device='cuda:0')\n",
      "Residual states sum =  tensor(-963.8799, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-9011.1699, device='cuda:0')\n",
      "Hidden states sum =  tensor(-3868.4133, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 13 called in free_generate mode with L = 46\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-3868.4133, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-3868.4133, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-359.4908, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 46, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(3105.4104, device='cuda:0')\n",
      "Residual states sum =  tensor(-359.4908, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-3868.4133, device='cuda:0')\n",
      "Hidden states sum =  tensor(9509.3740, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 14 called in free_generate mode with L = 46\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(9509.3740, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(9509.3740, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1747.0116, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 46, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(7775.5498, device='cuda:0')\n",
      "Residual states sum =  tensor(1747.0116, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(9509.3740, device='cuda:0')\n",
      "Hidden states sum =  tensor(5461.1948, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 15 called in free_generate mode with L = 46\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(5461.1948, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(5461.1948, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1348.5703, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 46, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-7225.6528, device='cuda:0')\n",
      "Residual states sum =  tensor(1348.5703, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(5461.1948, device='cuda:0')\n",
      "Hidden states sum =  tensor(10191.8965, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 16 called in free_generate mode with L = 46\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(10191.8965, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(10191.8965, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1349.3209, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 46, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-11916.8574, device='cuda:0')\n",
      "Residual states sum =  tensor(1349.3209, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(10191.8965, device='cuda:0')\n",
      "Hidden states sum =  tensor(-27418.4941, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 17 called in free_generate mode with L = 46\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-27418.4941, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-27418.4941, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1343.8284, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 46, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(7923.9053, device='cuda:0')\n",
      "Residual states sum =  tensor(-1343.8284, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-27418.4941, device='cuda:0')\n",
      "Hidden states sum =  tensor(88750.7188, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 18 called in free_generate mode with L = 46\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(88750.7188, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(88750.7188, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(2759.3726, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 46, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(77.1373, device='cuda:0')\n",
      "Residual states sum =  tensor(2759.3726, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(88750.7188, device='cuda:0')\n",
      "Hidden states sum =  tensor(-18188.1328, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 19 called in free_generate mode with L = 46\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-18188.1328, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-18188.1328, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-895.8945, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 46, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2428.4143, device='cuda:0')\n",
      "Residual states sum =  tensor(-895.8945, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-18188.1328, device='cuda:0')\n",
      "Hidden states sum =  tensor(-17698.1406, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 20 called in free_generate mode with L = 46\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-17698.1406, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-17698.1406, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-273.6348, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 46, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(495.2745, device='cuda:0')\n",
      "Residual states sum =  tensor(-273.6348, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-17698.1406, device='cuda:0')\n",
      "Hidden states sum =  tensor(7619.1816, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 21 called in free_generate mode with L = 46\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(7619.1816, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(7619.1816, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-161.0369, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 46, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(7254.3838, device='cuda:0')\n",
      "Residual states sum =  tensor(-161.0369, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(7619.1816, device='cuda:0')\n",
      "Hidden states sum =  tensor(-7226.0254, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 22 called in free_generate mode with L = 46\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-7226.0254, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-7226.0254, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-46.3242, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 46, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-3657.7764, device='cuda:0')\n",
      "Residual states sum =  tensor(-46.3242, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-7226.0254, device='cuda:0')\n",
      "Hidden states sum =  tensor(2940.5996, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 23 called in free_generate mode with L = 46\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(2940.5996, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(2940.5996, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(394.5863, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 46, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(4125.5020, device='cuda:0')\n",
      "Residual states sum =  tensor(394.5863, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(2940.5996, device='cuda:0')\n",
      "Hidden states sum =  tensor(32603.5879, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 24 called in free_generate mode with L = 46\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(32603.5879, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(32603.5879, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1106.8809, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 46, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2591.8047, device='cuda:0')\n",
      "Residual states sum =  tensor(1106.8809, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(32603.5879, device='cuda:0')\n",
      "Hidden states sum =  tensor(-17475.2344, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 25 called in free_generate mode with L = 46\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-17475.2344, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-17475.2344, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1041.3948, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 46, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(4841.3931, device='cuda:0')\n",
      "Residual states sum =  tensor(-1041.3948, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-17475.2344, device='cuda:0')\n",
      "Hidden states sum =  tensor(-7508.2900, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 26 called in free_generate mode with L = 46\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-7508.2900, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-7508.2900, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-55.8110, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 46, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(11938.7773, device='cuda:0')\n",
      "Residual states sum =  tensor(-55.8110, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-7508.2900, device='cuda:0')\n",
      "Hidden states sum =  tensor(15098.7051, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 27 called in free_generate mode with L = 46\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(15098.7051, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(15098.7051, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-172.6085, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 46, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(20152.5625, device='cuda:0')\n",
      "Residual states sum =  tensor(-172.6085, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(15098.7051, device='cuda:0')\n",
      "Hidden states sum =  tensor(-13361.2246, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 0 called in free_generate mode with L = 47\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(23.4018, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(23.4018, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(170.2505, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 47, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(646.5637, device='cuda:0')\n",
      "Residual states sum =  tensor(170.2505, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(23.4018, device='cuda:0')\n",
      "Hidden states sum =  tensor(742.0615, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 1 called in free_generate mode with L = 47\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(742.0615, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(742.0615, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(179.1903, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 47, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(587.1149, device='cuda:0')\n",
      "Residual states sum =  tensor(179.1903, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(742.0615, device='cuda:0')\n",
      "Hidden states sum =  tensor(1129.9189, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 2 called in free_generate mode with L = 47\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(1129.9189, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(1129.9189, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-56.7368, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 47, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(265.5628, device='cuda:0')\n",
      "Residual states sum =  tensor(-56.7368, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(1129.9189, device='cuda:0')\n",
      "Hidden states sum =  tensor(17718.8887, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 3 called in free_generate mode with L = 47\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(17718.8887, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(17718.8887, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(376.1859, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 47, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1315.5178, device='cuda:0')\n",
      "Residual states sum =  tensor(376.1859, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(17718.8887, device='cuda:0')\n",
      "Hidden states sum =  tensor(-11122.8965, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 4 called in free_generate mode with L = 47\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-11122.8965, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-11122.8965, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-766.3459, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 47, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2426.0786, device='cuda:0')\n",
      "Residual states sum =  tensor(-766.3459, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-11122.8965, device='cuda:0')\n",
      "Hidden states sum =  tensor(-15030.2627, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 5 called in free_generate mode with L = 47\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-15030.2627, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-15030.2627, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1482.3706, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 47, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1352.2983, device='cuda:0')\n",
      "Residual states sum =  tensor(-1482.3706, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-15030.2627, device='cuda:0')\n",
      "Hidden states sum =  tensor(-59547.3359, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 6 called in free_generate mode with L = 47\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-59547.3359, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-59547.3359, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1019.9956, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 47, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-3904.4321, device='cuda:0')\n",
      "Residual states sum =  tensor(-1019.9956, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-59547.3359, device='cuda:0')\n",
      "Hidden states sum =  tensor(4151.1968, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 7 called in free_generate mode with L = 47\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(4151.1968, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(4151.1968, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-126.8113, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 47, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(877.4910, device='cuda:0')\n",
      "Residual states sum =  tensor(-126.8113, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(4151.1968, device='cuda:0')\n",
      "Hidden states sum =  tensor(7861.6182, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 8 called in free_generate mode with L = 47\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(7861.6182, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(7861.6182, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(627.7828, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 47, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1539.9620, device='cuda:0')\n",
      "Residual states sum =  tensor(627.7828, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(7861.6182, device='cuda:0')\n",
      "Hidden states sum =  tensor(5964.3960, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 9 called in free_generate mode with L = 47\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(5964.3960, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(5964.3960, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(548.3557, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 47, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(232.2761, device='cuda:0')\n",
      "Residual states sum =  tensor(548.3557, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(5964.3960, device='cuda:0')\n",
      "Hidden states sum =  tensor(-1331.7222, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 10 called in free_generate mode with L = 47\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-1331.7222, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-1331.7222, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-433.9082, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 47, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2384.4556, device='cuda:0')\n",
      "Residual states sum =  tensor(-433.9082, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-1331.7222, device='cuda:0')\n",
      "Hidden states sum =  tensor(21320.3711, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 11 called in free_generate mode with L = 47\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(21320.3711, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(21320.3711, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(3473.7073, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 47, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-3845.1255, device='cuda:0')\n",
      "Residual states sum =  tensor(3473.7073, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(21320.3711, device='cuda:0')\n",
      "Hidden states sum =  tensor(-9173.8438, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 12 called in free_generate mode with L = 47\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-9173.8438, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-9173.8438, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-981.2407, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 47, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-391.1526, device='cuda:0')\n",
      "Residual states sum =  tensor(-981.2407, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-9173.8438, device='cuda:0')\n",
      "Hidden states sum =  tensor(-3926.3076, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 13 called in free_generate mode with L = 47\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-3926.3076, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-3926.3076, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-365.1915, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 47, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(3184.6243, device='cuda:0')\n",
      "Residual states sum =  tensor(-365.1915, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-3926.3076, device='cuda:0')\n",
      "Hidden states sum =  tensor(9743.4258, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 14 called in free_generate mode with L = 47\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(9743.4258, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(9743.4258, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1788.9612, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 47, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(7948.5068, device='cuda:0')\n",
      "Residual states sum =  tensor(1788.9612, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(9743.4258, device='cuda:0')\n",
      "Hidden states sum =  tensor(5577.8091, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 15 called in free_generate mode with L = 47\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(5577.8091, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(5577.8091, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1377.3157, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 47, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-7388.6895, device='cuda:0')\n",
      "Residual states sum =  tensor(1377.3157, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(5577.8091, device='cuda:0')\n",
      "Hidden states sum =  tensor(10401.4785, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 16 called in free_generate mode with L = 47\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(10401.4785, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(10401.4785, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1377.8218, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 47, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-12175.3096, device='cuda:0')\n",
      "Residual states sum =  tensor(1377.8218, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(10401.4785, device='cuda:0')\n",
      "Hidden states sum =  tensor(-28024.4023, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 17 called in free_generate mode with L = 47\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-28024.4023, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-28024.4023, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1373.4879, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 47, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(8096.1455, device='cuda:0')\n",
      "Residual states sum =  tensor(-1373.4879, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-28024.4023, device='cuda:0')\n",
      "Hidden states sum =  tensor(90681.7969, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 18 called in free_generate mode with L = 47\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(90681.7969, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(90681.7969, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(2819.3623, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 47, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(78.8707, device='cuda:0')\n",
      "Residual states sum =  tensor(2819.3623, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(90681.7969, device='cuda:0')\n",
      "Hidden states sum =  tensor(-18583.8613, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 19 called in free_generate mode with L = 47\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-18583.8613, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-18583.8613, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-915.3744, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 47, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2481.2349, device='cuda:0')\n",
      "Residual states sum =  tensor(-915.3744, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-18583.8613, device='cuda:0')\n",
      "Hidden states sum =  tensor(-18083.0918, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 20 called in free_generate mode with L = 47\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-18083.0918, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-18083.0918, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-279.5966, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 47, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(506.0439, device='cuda:0')\n",
      "Residual states sum =  tensor(-279.5966, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-18083.0918, device='cuda:0')\n",
      "Hidden states sum =  tensor(7784.8613, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 21 called in free_generate mode with L = 47\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(7784.8613, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(7784.8613, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-164.5356, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 47, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(7412.0894, device='cuda:0')\n",
      "Residual states sum =  tensor(-164.5356, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(7784.8613, device='cuda:0')\n",
      "Hidden states sum =  tensor(-7383.1113, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 22 called in free_generate mode with L = 47\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-7383.1113, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-7383.1113, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-47.3313, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 47, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-3737.2937, device='cuda:0')\n",
      "Residual states sum =  tensor(-47.3313, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-7383.1113, device='cuda:0')\n",
      "Hidden states sum =  tensor(3004.5215, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 23 called in free_generate mode with L = 47\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(3004.5215, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(3004.5215, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(403.1638, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 47, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(4215.1875, device='cuda:0')\n",
      "Residual states sum =  tensor(403.1638, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(3004.5215, device='cuda:0')\n",
      "Hidden states sum =  tensor(33312.3633, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 24 called in free_generate mode with L = 47\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(33312.3633, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(33312.3633, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1130.9432, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 47, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2648.1492, device='cuda:0')\n",
      "Residual states sum =  tensor(1130.9432, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(33312.3633, device='cuda:0')\n",
      "Hidden states sum =  tensor(-17855.1328, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 25 called in free_generate mode with L = 47\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-17855.1328, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-17855.1328, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1064.0338, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 47, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(4946.6406, device='cuda:0')\n",
      "Residual states sum =  tensor(-1064.0338, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-17855.1328, device='cuda:0')\n",
      "Hidden states sum =  tensor(-7671.5127, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 26 called in free_generate mode with L = 47\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-7671.5127, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-7671.5127, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-57.0241, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 47, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(12198.3164, device='cuda:0')\n",
      "Residual states sum =  tensor(-57.0241, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-7671.5127, device='cuda:0')\n",
      "Hidden states sum =  tensor(15426.9375, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 27 called in free_generate mode with L = 47\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(15426.9375, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(15426.9375, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-176.3610, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 47, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(20590.6582, device='cuda:0')\n",
      "Residual states sum =  tensor(-176.3610, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(15426.9375, device='cuda:0')\n",
      "Hidden states sum =  tensor(-13651.6895, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 0 called in free_generate mode with L = 48\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(24.6336, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(24.6336, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(179.4001, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 48, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(669.3312, device='cuda:0')\n",
      "Residual states sum =  tensor(179.4001, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(24.6336, device='cuda:0')\n",
      "Hidden states sum =  tensor(780.4026, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 1 called in free_generate mode with L = 48\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(780.4026, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(780.4026, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(181.1934, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 48, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(601.5247, device='cuda:0')\n",
      "Residual states sum =  tensor(181.1934, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(780.4026, device='cuda:0')\n",
      "Hidden states sum =  tensor(1166.1091, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 2 called in free_generate mode with L = 48\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(1166.1091, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(1166.1091, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-52.1038, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 48, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(254.5283, device='cuda:0')\n",
      "Residual states sum =  tensor(-52.1038, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(1166.1091, device='cuda:0')\n",
      "Hidden states sum =  tensor(18123.9590, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 3 called in free_generate mode with L = 48\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(18123.9590, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(18123.9590, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(376.8328, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 48, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1359.5037, device='cuda:0')\n",
      "Residual states sum =  tensor(376.8328, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(18123.9590, device='cuda:0')\n",
      "Hidden states sum =  tensor(-11426.1953, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 4 called in free_generate mode with L = 48\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-11426.1953, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-11426.1953, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-794.5768, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 48, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2461.9673, device='cuda:0')\n",
      "Residual states sum =  tensor(-794.5768, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-11426.1953, device='cuda:0')\n",
      "Hidden states sum =  tensor(-15075.3857, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 5 called in free_generate mode with L = 48\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-15075.3857, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-15075.3857, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1491.0903, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 48, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1347.4524, device='cuda:0')\n",
      "Residual states sum =  tensor(-1491.0903, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-15075.3857, device='cuda:0')\n",
      "Hidden states sum =  tensor(-60698.2773, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 6 called in free_generate mode with L = 48\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-60698.2773, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-60698.2773, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1042.2878, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 48, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-3976.2515, device='cuda:0')\n",
      "Residual states sum =  tensor(-1042.2878, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-60698.2773, device='cuda:0')\n",
      "Hidden states sum =  tensor(4190.7266, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 7 called in free_generate mode with L = 48\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(4190.7266, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(4190.7266, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-129.3128, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 48, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(900.8357, device='cuda:0')\n",
      "Residual states sum =  tensor(-129.3128, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(4190.7266, device='cuda:0')\n",
      "Hidden states sum =  tensor(8053.2969, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 8 called in free_generate mode with L = 48\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(8053.2969, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(8053.2969, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(649.1809, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 48, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1558.7621, device='cuda:0')\n",
      "Residual states sum =  tensor(649.1809, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(8053.2969, device='cuda:0')\n",
      "Hidden states sum =  tensor(6088.3398, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 9 called in free_generate mode with L = 48\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(6088.3398, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(6088.3398, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(560.5292, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 48, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(226.3319, device='cuda:0')\n",
      "Residual states sum =  tensor(560.5292, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(6088.3398, device='cuda:0')\n",
      "Hidden states sum =  tensor(-1353.0879, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 10 called in free_generate mode with L = 48\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-1353.0879, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-1353.0879, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-445.7186, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 48, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2451.7637, device='cuda:0')\n",
      "Residual states sum =  tensor(-445.7186, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-1353.0879, device='cuda:0')\n",
      "Hidden states sum =  tensor(21763.8984, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 11 called in free_generate mode with L = 48\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(21763.8984, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(21763.8984, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(3548.1707, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 48, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-3930.1606, device='cuda:0')\n",
      "Residual states sum =  tensor(3548.1707, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(21763.8984, device='cuda:0')\n",
      "Hidden states sum =  tensor(-9335.0449, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 12 called in free_generate mode with L = 48\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-9335.0449, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-9335.0449, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-998.4413, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 48, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-399.5806, device='cuda:0')\n",
      "Residual states sum =  tensor(-998.4413, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-9335.0449, device='cuda:0')\n",
      "Hidden states sum =  tensor(-3983.5840, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 13 called in free_generate mode with L = 48\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-3983.5840, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-3983.5840, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-370.8427, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 48, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(3264.6509, device='cuda:0')\n",
      "Residual states sum =  tensor(-370.8427, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-3983.5840, device='cuda:0')\n",
      "Hidden states sum =  tensor(9979.7559, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 14 called in free_generate mode with L = 48\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(9979.7559, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(9979.7559, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1831.2178, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 48, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(8121.7197, device='cuda:0')\n",
      "Residual states sum =  tensor(1831.2178, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(9979.7559, device='cuda:0')\n",
      "Hidden states sum =  tensor(5693.7710, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 15 called in free_generate mode with L = 48\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(5693.7710, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(5693.7710, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1405.9636, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 48, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-7551.9160, device='cuda:0')\n",
      "Residual states sum =  tensor(1405.9636, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(5693.7710, device='cuda:0')\n",
      "Hidden states sum =  tensor(10610.9023, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 16 called in free_generate mode with L = 48\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(10610.9023, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(10610.9023, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1406.3120, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 48, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-12433.7441, device='cuda:0')\n",
      "Residual states sum =  tensor(1406.3120, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(10610.9023, device='cuda:0')\n",
      "Hidden states sum =  tensor(-28630.8730, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 17 called in free_generate mode with L = 48\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-28630.8730, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-28630.8730, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1403.1765, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 48, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(8268.3984, device='cuda:0')\n",
      "Residual states sum =  tensor(-1403.1765, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-28630.8730, device='cuda:0')\n",
      "Hidden states sum =  tensor(92613.0312, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 18 called in free_generate mode with L = 48\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(92613.0312, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(92613.0312, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(2879.3535, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 48, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(80.6134, device='cuda:0')\n",
      "Residual states sum =  tensor(2879.3535, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(92613.0312, device='cuda:0')\n",
      "Hidden states sum =  tensor(-18979.6094, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 19 called in free_generate mode with L = 48\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-18979.6094, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-18979.6094, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-934.8547, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 48, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2534.0574, device='cuda:0')\n",
      "Residual states sum =  tensor(-934.8547, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-18979.6094, device='cuda:0')\n",
      "Hidden states sum =  tensor(-18468.0527, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 20 called in free_generate mode with L = 48\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-18468.0527, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-18468.0527, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-285.5600, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 48, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(516.8154, device='cuda:0')\n",
      "Residual states sum =  tensor(-285.5600, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-18468.0527, device='cuda:0')\n",
      "Hidden states sum =  tensor(7950.5508, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 21 called in free_generate mode with L = 48\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(7950.5508, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(7950.5508, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-168.0343, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 48, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(7569.7949, device='cuda:0')\n",
      "Residual states sum =  tensor(-168.0343, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(7950.5508, device='cuda:0')\n",
      "Hidden states sum =  tensor(-7540.1992, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 22 called in free_generate mode with L = 48\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-7540.1992, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-7540.1992, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-48.3385, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 48, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-3816.8113, device='cuda:0')\n",
      "Residual states sum =  tensor(-48.3385, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-7540.1992, device='cuda:0')\n",
      "Hidden states sum =  tensor(3068.4355, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 23 called in free_generate mode with L = 48\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(3068.4355, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(3068.4355, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(411.7415, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 48, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(4304.8721, device='cuda:0')\n",
      "Residual states sum =  tensor(411.7415, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(3068.4355, device='cuda:0')\n",
      "Hidden states sum =  tensor(34021.1328, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 24 called in free_generate mode with L = 48\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(34021.1328, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(34021.1328, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1155.0059, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 48, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2704.4939, device='cuda:0')\n",
      "Residual states sum =  tensor(1155.0059, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(34021.1328, device='cuda:0')\n",
      "Hidden states sum =  tensor(-18235.0332, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 25 called in free_generate mode with L = 48\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-18235.0332, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-18235.0332, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1086.6731, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 48, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(5051.8872, device='cuda:0')\n",
      "Residual states sum =  tensor(-1086.6731, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-18235.0332, device='cuda:0')\n",
      "Hidden states sum =  tensor(-7834.7354, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 26 called in free_generate mode with L = 48\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-7834.7354, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-7834.7354, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-58.2374, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 48, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(12457.8535, device='cuda:0')\n",
      "Residual states sum =  tensor(-58.2374, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-7834.7354, device='cuda:0')\n",
      "Hidden states sum =  tensor(15755.1660, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 27 called in free_generate mode with L = 48\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(15755.1660, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(15755.1660, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-180.1136, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 48, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(21028.7617, device='cuda:0')\n",
      "Residual states sum =  tensor(-180.1136, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(15755.1660, device='cuda:0')\n",
      "Hidden states sum =  tensor(-13942.1523, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 0 called in free_generate mode with L = 49\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(25.4878, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(25.4878, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(188.7671, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 49, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(690.4604, device='cuda:0')\n",
      "Residual states sum =  tensor(188.7671, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(25.4878, device='cuda:0')\n",
      "Hidden states sum =  tensor(827.2272, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 1 called in free_generate mode with L = 49\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(827.2272, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(827.2272, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(185.8295, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 49, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(634.3782, device='cuda:0')\n",
      "Residual states sum =  tensor(185.8295, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(827.2272, device='cuda:0')\n",
      "Hidden states sum =  tensor(1151.0857, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 2 called in free_generate mode with L = 49\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(1151.0857, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(1151.0857, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-56.7844, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 49, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(286.9528, device='cuda:0')\n",
      "Residual states sum =  tensor(-56.7844, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(1151.0857, device='cuda:0')\n",
      "Hidden states sum =  tensor(18608.9570, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 3 called in free_generate mode with L = 49\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(18608.9570, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(18608.9570, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(385.5762, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 49, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1420.1423, device='cuda:0')\n",
      "Residual states sum =  tensor(385.5762, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(18608.9570, device='cuda:0')\n",
      "Hidden states sum =  tensor(-11624.4785, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 4 called in free_generate mode with L = 49\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-11624.4785, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-11624.4785, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-815.3538, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 49, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2497.9668, device='cuda:0')\n",
      "Residual states sum =  tensor(-815.3538, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-11624.4785, device='cuda:0')\n",
      "Hidden states sum =  tensor(-15125.7422, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 5 called in free_generate mode with L = 49\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-15125.7422, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-15125.7422, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1502.1936, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 49, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1349.6410, device='cuda:0')\n",
      "Residual states sum =  tensor(-1502.1936, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-15125.7422, device='cuda:0')\n",
      "Hidden states sum =  tensor(-61923.9375, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 6 called in free_generate mode with L = 49\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-61923.9375, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-61923.9375, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1065.5405, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 49, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-4047.3557, device='cuda:0')\n",
      "Residual states sum =  tensor(-1065.5405, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-61923.9375, device='cuda:0')\n",
      "Hidden states sum =  tensor(4226.0791, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 7 called in free_generate mode with L = 49\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(4226.0791, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(4226.0791, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-131.9811, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 49, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(923.5607, device='cuda:0')\n",
      "Residual states sum =  tensor(-131.9811, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(4226.0791, device='cuda:0')\n",
      "Hidden states sum =  tensor(8246.5703, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 8 called in free_generate mode with L = 49\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(8246.5703, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(8246.5703, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(670.9483, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 49, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1576.4525, device='cuda:0')\n",
      "Residual states sum =  tensor(670.9483, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(8246.5703, device='cuda:0')\n",
      "Hidden states sum =  tensor(6211.9800, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 9 called in free_generate mode with L = 49\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(6211.9800, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(6211.9800, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(572.8157, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 49, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(219.5491, device='cuda:0')\n",
      "Residual states sum =  tensor(572.8157, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(6211.9800, device='cuda:0')\n",
      "Hidden states sum =  tensor(-1374.7871, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 10 called in free_generate mode with L = 49\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-1374.7871, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-1374.7871, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-457.5771, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 49, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2519.7168, device='cuda:0')\n",
      "Residual states sum =  tensor(-457.5771, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-1374.7871, device='cuda:0')\n",
      "Hidden states sum =  tensor(22206.9258, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 11 called in free_generate mode with L = 49\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(22206.9258, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(22206.9258, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(3622.6484, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 49, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-4014.9746, device='cuda:0')\n",
      "Residual states sum =  tensor(3622.6484, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(22206.9258, device='cuda:0')\n",
      "Hidden states sum =  tensor(-9494.8018, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 12 called in free_generate mode with L = 49\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-9494.8018, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-9494.8018, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1015.4760, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 49, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-408.1118, device='cuda:0')\n",
      "Residual states sum =  tensor(-1015.4760, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-9494.8018, device='cuda:0')\n",
      "Hidden states sum =  tensor(-4040.3003, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 13 called in free_generate mode with L = 49\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-4040.3003, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-4040.3003, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-376.4432, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 49, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(3345.5564, device='cuda:0')\n",
      "Residual states sum =  tensor(-376.4432, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-4040.3003, device='cuda:0')\n",
      "Hidden states sum =  tensor(10218.7480, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 14 called in free_generate mode with L = 49\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(10218.7480, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(10218.7480, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1873.8135, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 49, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(8295.2207, device='cuda:0')\n",
      "Residual states sum =  tensor(1873.8135, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(10218.7480, device='cuda:0')\n",
      "Hidden states sum =  tensor(5808.8467, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 15 called in free_generate mode with L = 49\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(5808.8467, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(5808.8467, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1434.4879, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 49, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-7715.2935, device='cuda:0')\n",
      "Residual states sum =  tensor(1434.4879, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(5808.8467, device='cuda:0')\n",
      "Hidden states sum =  tensor(10820.0586, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 16 called in free_generate mode with L = 49\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(10820.0586, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(10820.0586, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1434.7800, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 49, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-12692.1816, device='cuda:0')\n",
      "Residual states sum =  tensor(1434.7800, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(10820.0586, device='cuda:0')\n",
      "Hidden states sum =  tensor(-29237.9043, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 17 called in free_generate mode with L = 49\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-29237.9043, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-29237.9043, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1432.8982, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 49, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(8440.6660, device='cuda:0')\n",
      "Residual states sum =  tensor(-1432.8982, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-29237.9043, device='cuda:0')\n",
      "Hidden states sum =  tensor(94544.4062, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 18 called in free_generate mode with L = 49\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(94544.4062, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(94544.4062, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(2939.3474, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 49, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(82.3668, device='cuda:0')\n",
      "Residual states sum =  tensor(2939.3474, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(94544.4062, device='cuda:0')\n",
      "Hidden states sum =  tensor(-19375.3711, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 19 called in free_generate mode with L = 49\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-19375.3711, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-19375.3711, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-954.3356, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 49, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2586.8823, device='cuda:0')\n",
      "Residual states sum =  tensor(-954.3356, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-19375.3711, device='cuda:0')\n",
      "Hidden states sum =  tensor(-18853.0234, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 20 called in free_generate mode with L = 49\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-18853.0234, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-18853.0234, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-291.5248, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 49, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(527.5885, device='cuda:0')\n",
      "Residual states sum =  tensor(-291.5248, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-18853.0234, device='cuda:0')\n",
      "Hidden states sum =  tensor(8116.2373, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 21 called in free_generate mode with L = 49\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(8116.2373, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(8116.2373, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-171.5330, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 49, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(7727.5000, device='cuda:0')\n",
      "Residual states sum =  tensor(-171.5330, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(8116.2373, device='cuda:0')\n",
      "Hidden states sum =  tensor(-7697.2891, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 22 called in free_generate mode with L = 49\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-7697.2891, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-7697.2891, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-49.3455, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 49, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-3896.3286, device='cuda:0')\n",
      "Residual states sum =  tensor(-49.3455, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-7697.2891, device='cuda:0')\n",
      "Hidden states sum =  tensor(3132.3516, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 23 called in free_generate mode with L = 49\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(3132.3516, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(3132.3516, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(420.3190, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 49, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(4394.5586, device='cuda:0')\n",
      "Residual states sum =  tensor(420.3190, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(3132.3516, device='cuda:0')\n",
      "Hidden states sum =  tensor(34729.9062, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 24 called in free_generate mode with L = 49\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(34729.9062, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(34729.9062, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1179.0682, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 49, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2760.8352, device='cuda:0')\n",
      "Residual states sum =  tensor(1179.0682, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(34729.9062, device='cuda:0')\n",
      "Hidden states sum =  tensor(-18614.9180, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 25 called in free_generate mode with L = 49\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-18614.9180, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-18614.9180, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1109.3113, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 49, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(5157.1328, device='cuda:0')\n",
      "Residual states sum =  tensor(-1109.3113, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-18614.9180, device='cuda:0')\n",
      "Hidden states sum =  tensor(-7997.9697, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 26 called in free_generate mode with L = 49\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-7997.9697, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-7997.9697, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-59.4509, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 49, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(12717.3916, device='cuda:0')\n",
      "Residual states sum =  tensor(-59.4509, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-7997.9697, device='cuda:0')\n",
      "Hidden states sum =  tensor(16083.4395, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 27 called in free_generate mode with L = 49\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(16083.4395, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(16083.4395, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-183.8625, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 49, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(21466.8555, device='cuda:0')\n",
      "Residual states sum =  tensor(-183.8625, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(16083.4395, device='cuda:0')\n",
      "Hidden states sum =  tensor(-14232.6104, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 0 called in free_generate mode with L = 50\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(27.3488, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(27.3488, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(196.3488, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 50, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(684.4554, device='cuda:0')\n",
      "Residual states sum =  tensor(196.3488, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(27.3488, device='cuda:0')\n",
      "Hidden states sum =  tensor(866.9354, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 1 called in free_generate mode with L = 50\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(866.9354, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(866.9354, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(184.2261, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 50, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(644.7206, device='cuda:0')\n",
      "Residual states sum =  tensor(184.2261, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(866.9354, device='cuda:0')\n",
      "Hidden states sum =  tensor(1208.3347, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 2 called in free_generate mode with L = 50\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(1208.3347, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(1208.3347, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-50.1897, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 50, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(288.0273, device='cuda:0')\n",
      "Residual states sum =  tensor(-50.1897, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(1208.3347, device='cuda:0')\n",
      "Hidden states sum =  tensor(18813.0234, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 3 called in free_generate mode with L = 50\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(18813.0234, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(18813.0234, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(390.6457, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 50, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1469.4709, device='cuda:0')\n",
      "Residual states sum =  tensor(390.6457, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(18813.0234, device='cuda:0')\n",
      "Hidden states sum =  tensor(-11904.4736, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 4 called in free_generate mode with L = 50\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-11904.4736, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-11904.4736, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-838.5245, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 50, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2537.3125, device='cuda:0')\n",
      "Residual states sum =  tensor(-838.5245, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-11904.4736, device='cuda:0')\n",
      "Hidden states sum =  tensor(-15173.9258, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 5 called in free_generate mode with L = 50\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-15173.9258, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-15173.9258, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1511.1938, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 50, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1344.0626, device='cuda:0')\n",
      "Residual states sum =  tensor(-1511.1938, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-15173.9258, device='cuda:0')\n",
      "Hidden states sum =  tensor(-62955.4922, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 6 called in free_generate mode with L = 50\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-62955.4922, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-62955.4922, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1085.9023, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 50, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-4119.9004, device='cuda:0')\n",
      "Residual states sum =  tensor(-1085.9023, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-62955.4922, device='cuda:0')\n",
      "Hidden states sum =  tensor(4255.8281, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 7 called in free_generate mode with L = 50\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(4255.8281, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(4255.8281, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-135.4200, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 50, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(945.8023, device='cuda:0')\n",
      "Residual states sum =  tensor(-135.4200, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(4255.8281, device='cuda:0')\n",
      "Hidden states sum =  tensor(8432.2715, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 8 called in free_generate mode with L = 50\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(8432.2715, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(8432.2715, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(692.0272, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 50, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1593.2747, device='cuda:0')\n",
      "Residual states sum =  tensor(692.0272, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(8432.2715, device='cuda:0')\n",
      "Hidden states sum =  tensor(6333.2705, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 9 called in free_generate mode with L = 50\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(6333.2705, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(6333.2705, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(585.0161, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 50, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(212.0087, device='cuda:0')\n",
      "Residual states sum =  tensor(585.0161, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(6333.2705, device='cuda:0')\n",
      "Hidden states sum =  tensor(-1397.1177, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 10 called in free_generate mode with L = 50\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-1397.1177, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-1397.1177, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-469.6223, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 50, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2588.3621, device='cuda:0')\n",
      "Residual states sum =  tensor(-469.6223, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-1397.1177, device='cuda:0')\n",
      "Hidden states sum =  tensor(22650.5723, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 11 called in free_generate mode with L = 50\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(22650.5723, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(22650.5723, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(3697.2178, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 50, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-4099.6113, device='cuda:0')\n",
      "Residual states sum =  tensor(3697.2178, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(22650.5723, device='cuda:0')\n",
      "Hidden states sum =  tensor(-9652.9502, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 12 called in free_generate mode with L = 50\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-9652.9502, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-9652.9502, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1032.3218, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 50, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-416.7095, device='cuda:0')\n",
      "Residual states sum =  tensor(-1032.3218, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-9652.9502, device='cuda:0')\n",
      "Hidden states sum =  tensor(-4096.7056, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 13 called in free_generate mode with L = 50\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-4096.7056, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-4096.7056, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-382.0126, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 50, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(3427.3860, device='cuda:0')\n",
      "Residual states sum =  tensor(-382.0126, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-4096.7056, device='cuda:0')\n",
      "Hidden states sum =  tensor(10460.5449, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 14 called in free_generate mode with L = 50\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(10460.5449, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(10460.5449, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1916.7529, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 50, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(8469.0381, device='cuda:0')\n",
      "Residual states sum =  tensor(1916.7529, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(10460.5449, device='cuda:0')\n",
      "Hidden states sum =  tensor(5922.8926, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 15 called in free_generate mode with L = 50\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(5922.8926, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(5922.8926, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1462.8762, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 50, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-7878.8403, device='cuda:0')\n",
      "Residual states sum =  tensor(1462.8762, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(5922.8926, device='cuda:0')\n",
      "Hidden states sum =  tensor(11028.7793, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 16 called in free_generate mode with L = 50\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(11028.7793, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(11028.7793, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1463.2155, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 50, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-12950.6191, device='cuda:0')\n",
      "Residual states sum =  tensor(1463.2155, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(11028.7793, device='cuda:0')\n",
      "Hidden states sum =  tensor(-29845.3984, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 17 called in free_generate mode with L = 50\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-29845.3984, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-29845.3984, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1462.6504, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 50, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(8612.9414, device='cuda:0')\n",
      "Residual states sum =  tensor(-1462.6504, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-29845.3984, device='cuda:0')\n",
      "Hidden states sum =  tensor(96475.9219, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 18 called in free_generate mode with L = 50\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(96475.9219, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(96475.9219, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(2999.3433, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 50, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(84.1310, device='cuda:0')\n",
      "Residual states sum =  tensor(2999.3433, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(96475.9219, device='cuda:0')\n",
      "Hidden states sum =  tensor(-19771.1562, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 19 called in free_generate mode with L = 50\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-19771.1562, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-19771.1562, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-973.8173, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 50, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2639.7095, device='cuda:0')\n",
      "Residual states sum =  tensor(-973.8173, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-19771.1562, device='cuda:0')\n",
      "Hidden states sum =  tensor(-19238.0039, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 20 called in free_generate mode with L = 50\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-19238.0039, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-19238.0039, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-297.4913, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 50, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(538.3601, device='cuda:0')\n",
      "Residual states sum =  tensor(-297.4913, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-19238.0039, device='cuda:0')\n",
      "Hidden states sum =  tensor(8281.9414, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 21 called in free_generate mode with L = 50\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(8281.9414, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(8281.9414, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-175.0316, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 50, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(7885.2061, device='cuda:0')\n",
      "Residual states sum =  tensor(-175.0316, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(8281.9414, device='cuda:0')\n",
      "Hidden states sum =  tensor(-7854.3774, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 22 called in free_generate mode with L = 50\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-7854.3774, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-7854.3774, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-50.3527, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 50, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-3975.8462, device='cuda:0')\n",
      "Residual states sum =  tensor(-50.3527, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-7854.3774, device='cuda:0')\n",
      "Hidden states sum =  tensor(3196.2637, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 23 called in free_generate mode with L = 50\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(3196.2637, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(3196.2637, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(428.8967, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 50, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(4484.2446, device='cuda:0')\n",
      "Residual states sum =  tensor(428.8967, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(3196.2637, device='cuda:0')\n",
      "Hidden states sum =  tensor(35438.6758, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 24 called in free_generate mode with L = 50\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(35438.6758, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(35438.6758, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1203.1309, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 50, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2817.1792, device='cuda:0')\n",
      "Residual states sum =  tensor(1203.1309, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(35438.6758, device='cuda:0')\n",
      "Hidden states sum =  tensor(-18994.8184, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 25 called in free_generate mode with L = 50\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-18994.8184, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-18994.8184, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1131.9502, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 50, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(5262.3809, device='cuda:0')\n",
      "Residual states sum =  tensor(-1131.9502, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-18994.8184, device='cuda:0')\n",
      "Hidden states sum =  tensor(-8161.1958, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 26 called in free_generate mode with L = 50\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-8161.1958, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-8161.1958, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-60.6642, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 50, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(12976.9297, device='cuda:0')\n",
      "Residual states sum =  tensor(-60.6642, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-8161.1958, device='cuda:0')\n",
      "Hidden states sum =  tensor(16411.6738, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 27 called in free_generate mode with L = 50\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(16411.6738, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(16411.6738, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-187.6148, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 50, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(21904.9531, device='cuda:0')\n",
      "Residual states sum =  tensor(-187.6148, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(16411.6738, device='cuda:0')\n",
      "Hidden states sum =  tensor(-14523.0723, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 0 called in free_generate mode with L = 51\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(28.4081, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(28.4081, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(204.9123, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 51, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(679.6707, device='cuda:0')\n",
      "Residual states sum =  tensor(204.9123, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(28.4081, device='cuda:0')\n",
      "Hidden states sum =  tensor(893.0883, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 1 called in free_generate mode with L = 51\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(893.0883, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(893.0883, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(182.3698, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 51, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(671.9120, device='cuda:0')\n",
      "Residual states sum =  tensor(182.3698, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(893.0883, device='cuda:0')\n",
      "Hidden states sum =  tensor(1236.1917, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 2 called in free_generate mode with L = 51\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(1236.1917, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(1236.1917, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-47.8774, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 51, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(299.1100, device='cuda:0')\n",
      "Residual states sum =  tensor(-47.8774, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(1236.1917, device='cuda:0')\n",
      "Hidden states sum =  tensor(19167.9688, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 3 called in free_generate mode with L = 51\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(19167.9688, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(19167.9688, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(393.8804, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 51, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1534.6003, device='cuda:0')\n",
      "Residual states sum =  tensor(393.8804, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(19167.9688, device='cuda:0')\n",
      "Hidden states sum =  tensor(-12075.9805, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 4 called in free_generate mode with L = 51\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-12075.9805, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-12075.9805, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-858.7780, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 51, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2577.8599, device='cuda:0')\n",
      "Residual states sum =  tensor(-858.7780, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-12075.9805, device='cuda:0')\n",
      "Hidden states sum =  tensor(-15227.3730, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 5 called in free_generate mode with L = 51\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-15227.3730, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-15227.3730, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1521.8381, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 51, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1335.3359, device='cuda:0')\n",
      "Residual states sum =  tensor(-1521.8381, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-15227.3730, device='cuda:0')\n",
      "Hidden states sum =  tensor(-64035.2227, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 6 called in free_generate mode with L = 51\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-64035.2227, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-64035.2227, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1108.2676, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 51, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-4193.4468, device='cuda:0')\n",
      "Residual states sum =  tensor(-1108.2676, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-64035.2227, device='cuda:0')\n",
      "Hidden states sum =  tensor(4283.8506, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 7 called in free_generate mode with L = 51\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(4283.8506, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(4283.8506, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-138.6596, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 51, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(967.3501, device='cuda:0')\n",
      "Residual states sum =  tensor(-138.6596, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(4283.8506, device='cuda:0')\n",
      "Hidden states sum =  tensor(8620.3447, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 8 called in free_generate mode with L = 51\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(8620.3447, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(8620.3447, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(713.5632, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 51, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1608.8076, device='cuda:0')\n",
      "Residual states sum =  tensor(713.5632, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(8620.3447, device='cuda:0')\n",
      "Hidden states sum =  tensor(6454.1982, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 9 called in free_generate mode with L = 51\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(6454.1982, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(6454.1982, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(597.3989, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 51, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(203.8022, device='cuda:0')\n",
      "Residual states sum =  tensor(597.3989, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(6454.1982, device='cuda:0')\n",
      "Hidden states sum =  tensor(-1419.1396, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 10 called in free_generate mode with L = 51\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-1419.1396, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-1419.1396, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-481.6823, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 51, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2657.7063, device='cuda:0')\n",
      "Residual states sum =  tensor(-481.6823, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-1419.1396, device='cuda:0')\n",
      "Hidden states sum =  tensor(23094.9082, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 11 called in free_generate mode with L = 51\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(23094.9082, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(23094.9082, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(3771.9282, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 51, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-4184.1045, device='cuda:0')\n",
      "Residual states sum =  tensor(3771.9282, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(23094.9082, device='cuda:0')\n",
      "Hidden states sum =  tensor(-9809.5381, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 12 called in free_generate mode with L = 51\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-9809.5381, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-9809.5381, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1048.9762, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 51, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-425.3623, device='cuda:0')\n",
      "Residual states sum =  tensor(-1048.9762, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-9809.5381, device='cuda:0')\n",
      "Hidden states sum =  tensor(-4152.8740, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 13 called in free_generate mode with L = 51\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-4152.8740, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-4152.8740, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-387.5464, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 51, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(3510.1536, device='cuda:0')\n",
      "Residual states sum =  tensor(-387.5464, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-4152.8740, device='cuda:0')\n",
      "Hidden states sum =  tensor(10705.0645, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 14 called in free_generate mode with L = 51\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(10705.0645, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(10705.0645, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1960.0254, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 51, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(8643.1816, device='cuda:0')\n",
      "Residual states sum =  tensor(1960.0254, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(10705.0645, device='cuda:0')\n",
      "Hidden states sum =  tensor(6035.7598, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 15 called in free_generate mode with L = 51\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(6035.7598, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(6035.7598, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1491.1077, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 51, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-8042.6147, device='cuda:0')\n",
      "Residual states sum =  tensor(1491.1077, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(6035.7598, device='cuda:0')\n",
      "Hidden states sum =  tensor(11237.0371, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 16 called in free_generate mode with L = 51\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(11237.0371, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(11237.0371, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1491.6182, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 51, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-13209.0596, device='cuda:0')\n",
      "Residual states sum =  tensor(1491.6182, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(11237.0371, device='cuda:0')\n",
      "Hidden states sum =  tensor(-30453.3242, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 17 called in free_generate mode with L = 51\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-30453.3242, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-30453.3242, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1492.4313, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 51, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(8785.2207, device='cuda:0')\n",
      "Residual states sum =  tensor(-1492.4313, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-30453.3242, device='cuda:0')\n",
      "Hidden states sum =  tensor(98407.6172, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 18 called in free_generate mode with L = 51\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(98407.6172, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(98407.6172, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(3059.3413, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 51, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(85.9069, device='cuda:0')\n",
      "Residual states sum =  tensor(3059.3413, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(98407.6172, device='cuda:0')\n",
      "Hidden states sum =  tensor(-20166.9629, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 19 called in free_generate mode with L = 51\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-20166.9629, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-20166.9629, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-993.2996, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 51, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2692.5400, device='cuda:0')\n",
      "Residual states sum =  tensor(-993.2996, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-20166.9629, device='cuda:0')\n",
      "Hidden states sum =  tensor(-19622.9844, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 20 called in free_generate mode with L = 51\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-19622.9844, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-19622.9844, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-303.4590, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 51, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(549.1348, device='cuda:0')\n",
      "Residual states sum =  tensor(-303.4590, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-19622.9844, device='cuda:0')\n",
      "Hidden states sum =  tensor(8447.6445, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 21 called in free_generate mode with L = 51\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(8447.6445, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(8447.6445, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-178.5300, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 51, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(8042.9111, device='cuda:0')\n",
      "Residual states sum =  tensor(-178.5300, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(8447.6445, device='cuda:0')\n",
      "Hidden states sum =  tensor(-8011.4692, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 22 called in free_generate mode with L = 51\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-8011.4692, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-8011.4692, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-51.3599, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 51, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-4055.3630, device='cuda:0')\n",
      "Residual states sum =  tensor(-51.3599, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-8011.4692, device='cuda:0')\n",
      "Hidden states sum =  tensor(3260.1758, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 23 called in free_generate mode with L = 51\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(3260.1758, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(3260.1758, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(437.4741, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 51, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(4573.9307, device='cuda:0')\n",
      "Residual states sum =  tensor(437.4741, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(3260.1758, device='cuda:0')\n",
      "Hidden states sum =  tensor(36147.4453, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 24 called in free_generate mode with L = 51\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(36147.4453, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(36147.4453, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1227.1934, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 51, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2873.5234, device='cuda:0')\n",
      "Residual states sum =  tensor(1227.1934, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(36147.4453, device='cuda:0')\n",
      "Hidden states sum =  tensor(-19374.7148, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 25 called in free_generate mode with L = 51\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-19374.7148, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-19374.7148, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1154.5894, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 51, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(5367.6284, device='cuda:0')\n",
      "Residual states sum =  tensor(-1154.5894, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-19374.7148, device='cuda:0')\n",
      "Hidden states sum =  tensor(-8324.4180, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 26 called in free_generate mode with L = 51\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-8324.4180, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-8324.4180, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-61.8774, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 51, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(13236.4688, device='cuda:0')\n",
      "Residual states sum =  tensor(-61.8774, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-8324.4180, device='cuda:0')\n",
      "Hidden states sum =  tensor(16739.9043, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 27 called in free_generate mode with L = 51\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(16739.9043, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(16739.9043, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-191.3670, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 51, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(22343.0547, device='cuda:0')\n",
      "Residual states sum =  tensor(-191.3670, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(16739.9043, device='cuda:0')\n",
      "Hidden states sum =  tensor(-14813.5332, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 0 called in free_generate mode with L = 52\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(28.1038, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(28.1038, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(203.0364, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 52, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(664.8226, device='cuda:0')\n",
      "Residual states sum =  tensor(203.0364, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(28.1038, device='cuda:0')\n",
      "Hidden states sum =  tensor(899.1297, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 1 called in free_generate mode with L = 52\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(899.1297, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(899.1297, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(187.2042, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 52, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(687.2493, device='cuda:0')\n",
      "Residual states sum =  tensor(187.2042, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(899.1297, device='cuda:0')\n",
      "Hidden states sum =  tensor(1171.4448, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 2 called in free_generate mode with L = 52\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(1171.4448, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(1171.4448, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-77.7859, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 52, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(326.5288, device='cuda:0')\n",
      "Residual states sum =  tensor(-77.7859, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(1171.4448, device='cuda:0')\n",
      "Hidden states sum =  tensor(19994.9570, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 3 called in free_generate mode with L = 52\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(19994.9570, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(19994.9570, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(402.4712, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 52, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1603.9128, device='cuda:0')\n",
      "Residual states sum =  tensor(402.4712, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(19994.9570, device='cuda:0')\n",
      "Hidden states sum =  tensor(-12343.6680, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 4 called in free_generate mode with L = 52\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-12343.6680, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-12343.6680, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-882.2122, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 52, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2617.2319, device='cuda:0')\n",
      "Residual states sum =  tensor(-882.2122, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-12343.6680, device='cuda:0')\n",
      "Hidden states sum =  tensor(-15259.6152, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 5 called in free_generate mode with L = 52\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-15259.6152, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-15259.6152, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1530.0558, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 52, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1330.1449, device='cuda:0')\n",
      "Residual states sum =  tensor(-1530.0558, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-15259.6152, device='cuda:0')\n",
      "Hidden states sum =  tensor(-65039.8164, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 6 called in free_generate mode with L = 52\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-65039.8164, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-65039.8164, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1129.6404, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 52, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-4269.1768, device='cuda:0')\n",
      "Residual states sum =  tensor(-1129.6404, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-65039.8164, device='cuda:0')\n",
      "Hidden states sum =  tensor(4305.6787, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 7 called in free_generate mode with L = 52\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(4305.6787, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(4305.6787, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-142.2776, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 52, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(988.2151, device='cuda:0')\n",
      "Residual states sum =  tensor(-142.2776, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(4305.6787, device='cuda:0')\n",
      "Hidden states sum =  tensor(8806.5938, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 8 called in free_generate mode with L = 52\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(8806.5938, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(8806.5938, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(735.2195, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 52, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1622.8705, device='cuda:0')\n",
      "Residual states sum =  tensor(735.2195, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(8806.5938, device='cuda:0')\n",
      "Hidden states sum =  tensor(6574.6226, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 9 called in free_generate mode with L = 52\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(6574.6226, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(6574.6226, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(609.9565, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 52, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(195.2963, device='cuda:0')\n",
      "Residual states sum =  tensor(609.9565, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(6574.6226, device='cuda:0')\n",
      "Hidden states sum =  tensor(-1441.4150, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 10 called in free_generate mode with L = 52\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-1441.4150, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-1441.4150, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-493.7392, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 52, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2727.6982, device='cuda:0')\n",
      "Residual states sum =  tensor(-493.7392, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-1441.4150, device='cuda:0')\n",
      "Hidden states sum =  tensor(23539.9473, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 11 called in free_generate mode with L = 52\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(23539.9473, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(23539.9473, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(3846.7314, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 52, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-4268.4106, device='cuda:0')\n",
      "Residual states sum =  tensor(3846.7314, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(23539.9473, device='cuda:0')\n",
      "Hidden states sum =  tensor(-9964.4395, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 12 called in free_generate mode with L = 52\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-9964.4395, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-9964.4395, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1065.4237, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 52, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-434.0942, device='cuda:0')\n",
      "Residual states sum =  tensor(-1065.4237, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-9964.4395, device='cuda:0')\n",
      "Hidden states sum =  tensor(-4208.7305, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 13 called in free_generate mode with L = 52\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-4208.7305, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-4208.7305, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-393.0233, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 52, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(3593.8523, device='cuda:0')\n",
      "Residual states sum =  tensor(-393.0233, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-4208.7305, device='cuda:0')\n",
      "Hidden states sum =  tensor(10952.1055, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 14 called in free_generate mode with L = 52\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(10952.1055, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(10952.1055, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(2003.6171, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 52, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(8817.6279, device='cuda:0')\n",
      "Residual states sum =  tensor(2003.6171, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(10952.1055, device='cuda:0')\n",
      "Hidden states sum =  tensor(6147.3218, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 15 called in free_generate mode with L = 52\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(6147.3218, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(6147.3218, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1519.1545, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 52, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-8206.6748, device='cuda:0')\n",
      "Residual states sum =  tensor(1519.1545, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(6147.3218, device='cuda:0')\n",
      "Hidden states sum =  tensor(11444.8770, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 16 called in free_generate mode with L = 52\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(11444.8770, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(11444.8770, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1519.9962, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 52, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-13467.5078, device='cuda:0')\n",
      "Residual states sum =  tensor(1519.9962, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(11444.8770, device='cuda:0')\n",
      "Hidden states sum =  tensor(-31061.6875, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 17 called in free_generate mode with L = 52\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-31061.6875, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-31061.6875, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1522.2428, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 52, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(8957.5000, device='cuda:0')\n",
      "Residual states sum =  tensor(-1522.2428, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-31061.6875, device='cuda:0')\n",
      "Hidden states sum =  tensor(100339.4688, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 18 called in free_generate mode with L = 52\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(100339.4688, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(100339.4688, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(3119.3416, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 52, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(87.6953, device='cuda:0')\n",
      "Residual states sum =  tensor(3119.3416, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(100339.4688, device='cuda:0')\n",
      "Hidden states sum =  tensor(-20562.7852, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 19 called in free_generate mode with L = 52\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-20562.7852, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-20562.7852, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1012.7821, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 52, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2745.3755, device='cuda:0')\n",
      "Residual states sum =  tensor(-1012.7821, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-20562.7852, device='cuda:0')\n",
      "Hidden states sum =  tensor(-20007.9824, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 20 called in free_generate mode with L = 52\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-20007.9824, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-20007.9824, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-309.4283, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 52, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(559.9099, device='cuda:0')\n",
      "Residual states sum =  tensor(-309.4283, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-20007.9824, device='cuda:0')\n",
      "Hidden states sum =  tensor(8613.3535, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 21 called in free_generate mode with L = 52\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(8613.3535, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(8613.3535, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-182.0281, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 52, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(8200.6172, device='cuda:0')\n",
      "Residual states sum =  tensor(-182.0281, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(8613.3535, device='cuda:0')\n",
      "Hidden states sum =  tensor(-8168.5591, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 22 called in free_generate mode with L = 52\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-8168.5591, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-8168.5591, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-52.3673, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 52, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-4134.8809, device='cuda:0')\n",
      "Residual states sum =  tensor(-52.3673, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-8168.5591, device='cuda:0')\n",
      "Hidden states sum =  tensor(3324.0898, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 23 called in free_generate mode with L = 52\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(3324.0898, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(3324.0898, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(446.0516, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 52, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(4663.6162, device='cuda:0')\n",
      "Residual states sum =  tensor(446.0516, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(3324.0898, device='cuda:0')\n",
      "Hidden states sum =  tensor(36856.2109, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 24 called in free_generate mode with L = 52\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(36856.2109, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(36856.2109, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1251.2560, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 52, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2929.8669, device='cuda:0')\n",
      "Residual states sum =  tensor(1251.2560, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(36856.2109, device='cuda:0')\n",
      "Hidden states sum =  tensor(-19754.6133, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 25 called in free_generate mode with L = 52\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-19754.6133, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-19754.6133, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1177.2286, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 52, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(5472.8770, device='cuda:0')\n",
      "Residual states sum =  tensor(-1177.2286, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-19754.6133, device='cuda:0')\n",
      "Hidden states sum =  tensor(-8487.6445, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 26 called in free_generate mode with L = 52\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-8487.6445, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-8487.6445, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-63.0909, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 52, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(13496.0068, device='cuda:0')\n",
      "Residual states sum =  tensor(-63.0909, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-8487.6445, device='cuda:0')\n",
      "Hidden states sum =  tensor(17068.1367, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 27 called in free_generate mode with L = 52\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(17068.1367, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(17068.1367, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-195.1197, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 52, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(22781.1465, device='cuda:0')\n",
      "Residual states sum =  tensor(-195.1197, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(17068.1367, device='cuda:0')\n",
      "Hidden states sum =  tensor(-15103.9941, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 0 called in free_generate mode with L = 53\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(27.6099, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(27.6099, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(203.9179, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 53, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(673.4835, device='cuda:0')\n",
      "Residual states sum =  tensor(203.9179, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(27.6099, device='cuda:0')\n",
      "Hidden states sum =  tensor(864.2090, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 1 called in free_generate mode with L = 53\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(864.2090, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(864.2090, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(183.1318, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 53, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(694.8167, device='cuda:0')\n",
      "Residual states sum =  tensor(183.1318, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(864.2090, device='cuda:0')\n",
      "Hidden states sum =  tensor(1143.0637, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 2 called in free_generate mode with L = 53\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(1143.0637, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(1143.0637, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-99.1145, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 53, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(357.7676, device='cuda:0')\n",
      "Residual states sum =  tensor(-99.1145, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(1143.0637, device='cuda:0')\n",
      "Hidden states sum =  tensor(20742.3164, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 3 called in free_generate mode with L = 53\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(20742.3164, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(20742.3164, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(408.7087, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 53, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1675.6069, device='cuda:0')\n",
      "Residual states sum =  tensor(408.7087, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(20742.3164, device='cuda:0')\n",
      "Hidden states sum =  tensor(-12572.5488, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 4 called in free_generate mode with L = 53\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-12572.5488, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-12572.5488, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-906.0883, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 53, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2656.8191, device='cuda:0')\n",
      "Residual states sum =  tensor(-906.0883, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-12572.5488, device='cuda:0')\n",
      "Hidden states sum =  tensor(-15297.3574, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 5 called in free_generate mode with L = 53\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-15297.3574, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-15297.3574, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1537.6692, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 53, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1325.8395, device='cuda:0')\n",
      "Residual states sum =  tensor(-1537.6692, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-15297.3574, device='cuda:0')\n",
      "Hidden states sum =  tensor(-66006.1094, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 6 called in free_generate mode with L = 53\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-66006.1094, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-66006.1094, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1150.3856, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 53, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-4347.6934, device='cuda:0')\n",
      "Residual states sum =  tensor(-1150.3856, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-66006.1094, device='cuda:0')\n",
      "Hidden states sum =  tensor(4325.4468, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 7 called in free_generate mode with L = 53\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(4325.4468, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(4325.4468, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-145.8123, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 53, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1008.5096, device='cuda:0')\n",
      "Residual states sum =  tensor(-145.8123, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(4325.4468, device='cuda:0')\n",
      "Hidden states sum =  tensor(8988.9785, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 8 called in free_generate mode with L = 53\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(8988.9785, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(8988.9785, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(756.7372, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 53, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1635.7725, device='cuda:0')\n",
      "Residual states sum =  tensor(756.7372, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(8988.9785, device='cuda:0')\n",
      "Hidden states sum =  tensor(6695.1562, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 9 called in free_generate mode with L = 53\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(6695.1562, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(6695.1562, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(622.7245, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 53, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(186.6057, device='cuda:0')\n",
      "Residual states sum =  tensor(622.7245, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(6695.1562, device='cuda:0')\n",
      "Hidden states sum =  tensor(-1465.5210, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 10 called in free_generate mode with L = 53\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-1465.5210, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-1465.5210, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-505.9146, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 53, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2798.5745, device='cuda:0')\n",
      "Residual states sum =  tensor(-505.9146, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-1465.5210, device='cuda:0')\n",
      "Hidden states sum =  tensor(23985.8770, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 11 called in free_generate mode with L = 53\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(23985.8770, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(23985.8770, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(3921.6018, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 53, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-4352.4385, device='cuda:0')\n",
      "Residual states sum =  tensor(3921.6018, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(23985.8770, device='cuda:0')\n",
      "Hidden states sum =  tensor(-10117.4902, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 12 called in free_generate mode with L = 53\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-10117.4902, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-10117.4902, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1081.6422, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 53, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-442.9607, device='cuda:0')\n",
      "Residual states sum =  tensor(-1081.6422, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-10117.4902, device='cuda:0')\n",
      "Hidden states sum =  tensor(-4264.3159, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 13 called in free_generate mode with L = 53\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-4264.3159, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-4264.3159, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-398.4559, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 53, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(3678.4531, device='cuda:0')\n",
      "Residual states sum =  tensor(-398.4559, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-4264.3159, device='cuda:0')\n",
      "Hidden states sum =  tensor(11201.6484, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 14 called in free_generate mode with L = 53\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(11201.6484, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(11201.6484, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(2047.5286, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 53, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(8992.3389, device='cuda:0')\n",
      "Residual states sum =  tensor(2047.5286, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(11201.6484, device='cuda:0')\n",
      "Hidden states sum =  tensor(6257.4937, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 15 called in free_generate mode with L = 53\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(6257.4937, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(6257.4937, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1546.9946, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 53, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-8371.0527, device='cuda:0')\n",
      "Residual states sum =  tensor(1546.9946, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(6257.4937, device='cuda:0')\n",
      "Hidden states sum =  tensor(11652.3594, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 16 called in free_generate mode with L = 53\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(11652.3594, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(11652.3594, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1548.3590, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 53, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-13725.9805, device='cuda:0')\n",
      "Residual states sum =  tensor(1548.3590, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(11652.3594, device='cuda:0')\n",
      "Hidden states sum =  tensor(-31670.6152, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 17 called in free_generate mode with L = 53\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-31670.6152, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-31670.6152, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1552.0977, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 53, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(9129.7793, device='cuda:0')\n",
      "Residual states sum =  tensor(-1552.0977, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-31670.6152, device='cuda:0')\n",
      "Hidden states sum =  tensor(102271.5078, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 18 called in free_generate mode with L = 53\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(102271.5078, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(102271.5078, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(3179.3445, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 53, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(89.4990, device='cuda:0')\n",
      "Residual states sum =  tensor(3179.3445, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(102271.5078, device='cuda:0')\n",
      "Hidden states sum =  tensor(-20958.6289, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 19 called in free_generate mode with L = 53\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-20958.6289, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-20958.6289, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1032.2644, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 53, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2798.2161, device='cuda:0')\n",
      "Residual states sum =  tensor(-1032.2644, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-20958.6289, device='cuda:0')\n",
      "Hidden states sum =  tensor(-20392.9805, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 20 called in free_generate mode with L = 53\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-20392.9805, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-20392.9805, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-315.3986, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 53, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(570.6846, device='cuda:0')\n",
      "Residual states sum =  tensor(-315.3986, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-20392.9805, device='cuda:0')\n",
      "Hidden states sum =  tensor(8779.0693, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 21 called in free_generate mode with L = 53\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(8779.0693, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(8779.0693, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-185.5257, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 53, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(8358.3223, device='cuda:0')\n",
      "Residual states sum =  tensor(-185.5257, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(8779.0693, device='cuda:0')\n",
      "Hidden states sum =  tensor(-8325.6514, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 22 called in free_generate mode with L = 53\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-8325.6514, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-8325.6514, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-53.3744, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 53, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-4214.3975, device='cuda:0')\n",
      "Residual states sum =  tensor(-53.3744, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-8325.6514, device='cuda:0')\n",
      "Hidden states sum =  tensor(3388.0039, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 23 called in free_generate mode with L = 53\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(3388.0039, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(3388.0039, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(454.6293, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 53, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(4753.3022, device='cuda:0')\n",
      "Residual states sum =  tensor(454.6293, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(3388.0039, device='cuda:0')\n",
      "Hidden states sum =  tensor(37564.9883, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 24 called in free_generate mode with L = 53\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(37564.9883, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(37564.9883, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1275.3185, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 53, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2986.2107, device='cuda:0')\n",
      "Residual states sum =  tensor(1275.3185, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(37564.9883, device='cuda:0')\n",
      "Hidden states sum =  tensor(-20134.5098, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 25 called in free_generate mode with L = 53\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-20134.5098, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-20134.5098, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1199.8671, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 53, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(5578.1235, device='cuda:0')\n",
      "Residual states sum =  tensor(-1199.8671, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-20134.5098, device='cuda:0')\n",
      "Hidden states sum =  tensor(-8650.8672, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 26 called in free_generate mode with L = 53\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-8650.8672, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-8650.8672, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-64.3040, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 53, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(13755.5449, device='cuda:0')\n",
      "Residual states sum =  tensor(-64.3040, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-8650.8672, device='cuda:0')\n",
      "Hidden states sum =  tensor(17396.3730, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 27 called in free_generate mode with L = 53\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(17396.3730, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(17396.3730, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-198.8719, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 53, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(23219.2500, device='cuda:0')\n",
      "Residual states sum =  tensor(-198.8719, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(17396.3730, device='cuda:0')\n",
      "Hidden states sum =  tensor(-15394.4512, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 0 called in free_generate mode with L = 54\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(28.1636, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(28.1636, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(206.7732, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 54, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(706.6901, device='cuda:0')\n",
      "Residual states sum =  tensor(206.7732, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(28.1636, device='cuda:0')\n",
      "Hidden states sum =  tensor(915.3873, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 1 called in free_generate mode with L = 54\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(915.3873, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(915.3873, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(189.9973, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 54, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(713.9581, device='cuda:0')\n",
      "Residual states sum =  tensor(189.9973, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(915.3873, device='cuda:0')\n",
      "Hidden states sum =  tensor(1253.4521, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 2 called in free_generate mode with L = 54\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(1253.4521, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(1253.4521, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-80.9780, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 54, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(442.8341, device='cuda:0')\n",
      "Residual states sum =  tensor(-80.9780, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(1253.4521, device='cuda:0')\n",
      "Hidden states sum =  tensor(21577.3242, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 3 called in free_generate mode with L = 54\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(21577.3242, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(21577.3242, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(434.8775, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 54, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1754.9900, device='cuda:0')\n",
      "Residual states sum =  tensor(434.8775, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(21577.3242, device='cuda:0')\n",
      "Hidden states sum =  tensor(-12737.7402, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 4 called in free_generate mode with L = 54\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-12737.7402, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-12737.7402, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-921.5518, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 54, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2694.4336, device='cuda:0')\n",
      "Residual states sum =  tensor(-921.5518, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-12737.7402, device='cuda:0')\n",
      "Hidden states sum =  tensor(-15373.6426, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 5 called in free_generate mode with L = 54\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-15373.6426, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-15373.6426, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1550.0269, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 54, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1322.1283, device='cuda:0')\n",
      "Residual states sum =  tensor(-1550.0269, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-15373.6426, device='cuda:0')\n",
      "Hidden states sum =  tensor(-66980.8672, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 6 called in free_generate mode with L = 54\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-66980.8672, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-66980.8672, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1170.3342, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 54, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-4426.6211, device='cuda:0')\n",
      "Residual states sum =  tensor(-1170.3342, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-66980.8672, device='cuda:0')\n",
      "Hidden states sum =  tensor(4345.9897, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 7 called in free_generate mode with L = 54\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(4345.9897, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(4345.9897, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-149.0679, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 54, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1028.0219, device='cuda:0')\n",
      "Residual states sum =  tensor(-149.0679, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(4345.9897, device='cuda:0')\n",
      "Hidden states sum =  tensor(9170.0254, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 8 called in free_generate mode with L = 54\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(9170.0254, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(9170.0254, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(778.5486, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 54, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1647.7209, device='cuda:0')\n",
      "Residual states sum =  tensor(778.5486, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(9170.0254, device='cuda:0')\n",
      "Hidden states sum =  tensor(6815.9888, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 9 called in free_generate mode with L = 54\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(6815.9888, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(6815.9888, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(635.6475, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 54, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(177.7339, device='cuda:0')\n",
      "Residual states sum =  tensor(635.6475, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(6815.9888, device='cuda:0')\n",
      "Hidden states sum =  tensor(-1493.5996, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 10 called in free_generate mode with L = 54\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-1493.5996, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-1493.5996, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-518.4707, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 54, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2870.3403, device='cuda:0')\n",
      "Residual states sum =  tensor(-518.4707, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-1493.5996, device='cuda:0')\n",
      "Hidden states sum =  tensor(24432.4062, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 11 called in free_generate mode with L = 54\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(24432.4062, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(24432.4062, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(3996.5249, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 54, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-4436.0996, device='cuda:0')\n",
      "Residual states sum =  tensor(3996.5249, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(24432.4062, device='cuda:0')\n",
      "Hidden states sum =  tensor(-10268.6689, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 12 called in free_generate mode with L = 54\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-10268.6689, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-10268.6689, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1097.6322, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 54, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-451.9868, device='cuda:0')\n",
      "Residual states sum =  tensor(-1097.6322, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-10268.6689, device='cuda:0')\n",
      "Hidden states sum =  tensor(-4319.9062, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 13 called in free_generate mode with L = 54\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-4319.9062, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-4319.9062, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-403.8898, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 54, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(3763.9438, device='cuda:0')\n",
      "Residual states sum =  tensor(-403.8898, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-4319.9062, device='cuda:0')\n",
      "Hidden states sum =  tensor(11453.7441, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 14 called in free_generate mode with L = 54\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(11453.7441, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(11453.7441, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(2091.7678, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 54, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(9167.2666, device='cuda:0')\n",
      "Residual states sum =  tensor(2091.7678, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(11453.7441, device='cuda:0')\n",
      "Hidden states sum =  tensor(6366.2949, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 15 called in free_generate mode with L = 54\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(6366.2949, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(6366.2949, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1574.6279, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 54, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-8535.7588, device='cuda:0')\n",
      "Residual states sum =  tensor(1574.6279, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(6366.2949, device='cuda:0')\n",
      "Hidden states sum =  tensor(11859.5098, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 16 called in free_generate mode with L = 54\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(11859.5098, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(11859.5098, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1576.7120, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 54, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-13984.4932, device='cuda:0')\n",
      "Residual states sum =  tensor(1576.7120, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(11859.5098, device='cuda:0')\n",
      "Hidden states sum =  tensor(-32280.2656, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 17 called in free_generate mode with L = 54\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-32280.2656, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-32280.2656, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1582.0142, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 54, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(9302.0557, device='cuda:0')\n",
      "Residual states sum =  tensor(-1582.0142, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-32280.2656, device='cuda:0')\n",
      "Hidden states sum =  tensor(104203.7422, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 18 called in free_generate mode with L = 54\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(104203.7422, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(104203.7422, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(3239.3501, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 54, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(91.3154, device='cuda:0')\n",
      "Residual states sum =  tensor(3239.3501, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(104203.7422, device='cuda:0')\n",
      "Hidden states sum =  tensor(-21354.4805, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 19 called in free_generate mode with L = 54\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-21354.4805, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-21354.4805, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1051.7462, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 54, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2851.0645, device='cuda:0')\n",
      "Residual states sum =  tensor(-1051.7462, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-21354.4805, device='cuda:0')\n",
      "Hidden states sum =  tensor(-20777.9805, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 20 called in free_generate mode with L = 54\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-20777.9805, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-20777.9805, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-321.3705, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 54, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(581.4629, device='cuda:0')\n",
      "Residual states sum =  tensor(-321.3705, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-20777.9805, device='cuda:0')\n",
      "Hidden states sum =  tensor(8944.7949, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 21 called in free_generate mode with L = 54\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(8944.7949, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(8944.7949, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-189.0234, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 54, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(8516.0293, device='cuda:0')\n",
      "Residual states sum =  tensor(-189.0234, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(8944.7949, device='cuda:0')\n",
      "Hidden states sum =  tensor(-8482.7422, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 22 called in free_generate mode with L = 54\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-8482.7422, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-8482.7422, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-54.3815, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 54, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-4293.9150, device='cuda:0')\n",
      "Residual states sum =  tensor(-54.3815, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-8482.7422, device='cuda:0')\n",
      "Hidden states sum =  tensor(3451.9141, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 23 called in free_generate mode with L = 54\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(3451.9141, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(3451.9141, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(463.2067, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 54, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(4842.9888, device='cuda:0')\n",
      "Residual states sum =  tensor(463.2067, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(3451.9141, device='cuda:0')\n",
      "Hidden states sum =  tensor(38273.7539, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 24 called in free_generate mode with L = 54\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(38273.7539, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(38273.7539, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1299.3809, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 54, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-3042.5557, device='cuda:0')\n",
      "Residual states sum =  tensor(1299.3809, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(38273.7539, device='cuda:0')\n",
      "Hidden states sum =  tensor(-20514.4062, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 25 called in free_generate mode with L = 54\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-20514.4062, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-20514.4062, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1222.5062, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 54, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(5683.3716, device='cuda:0')\n",
      "Residual states sum =  tensor(-1222.5062, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-20514.4062, device='cuda:0')\n",
      "Hidden states sum =  tensor(-8814.0938, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 26 called in free_generate mode with L = 54\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-8814.0938, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-8814.0938, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-65.5173, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 54, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(14015.0830, device='cuda:0')\n",
      "Residual states sum =  tensor(-65.5173, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-8814.0938, device='cuda:0')\n",
      "Hidden states sum =  tensor(17724.6035, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 27 called in free_generate mode with L = 54\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(17724.6035, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(17724.6035, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-202.6244, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 54, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(23657.3516, device='cuda:0')\n",
      "Residual states sum =  tensor(-202.6244, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(17724.6035, device='cuda:0')\n",
      "Hidden states sum =  tensor(-15684.9150, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 0 called in free_generate mode with L = 55\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(29.9216, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(29.9216, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(217.4192, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 55, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(725.5017, device='cuda:0')\n",
      "Residual states sum =  tensor(217.4192, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(29.9216, device='cuda:0')\n",
      "Hidden states sum =  tensor(909.6589, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 1 called in free_generate mode with L = 55\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(909.6589, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(909.6589, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(190.9405, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 55, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(725.3356, device='cuda:0')\n",
      "Residual states sum =  tensor(190.9405, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(909.6589, device='cuda:0')\n",
      "Hidden states sum =  tensor(1253.3149, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 2 called in free_generate mode with L = 55\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(1253.3149, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(1253.3149, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-89.6895, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 55, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(421.0190, device='cuda:0')\n",
      "Residual states sum =  tensor(-89.6895, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(1253.3149, device='cuda:0')\n",
      "Hidden states sum =  tensor(21921.7734, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 3 called in free_generate mode with L = 55\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(21921.7734, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(21921.7734, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(435.3963, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 55, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1786.1875, device='cuda:0')\n",
      "Residual states sum =  tensor(435.3963, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(21921.7734, device='cuda:0')\n",
      "Hidden states sum =  tensor(-13053.7646, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 4 called in free_generate mode with L = 55\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-13053.7646, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-13053.7646, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-954.6938, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 55, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2734.9502, device='cuda:0')\n",
      "Residual states sum =  tensor(-954.6938, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-13053.7646, device='cuda:0')\n",
      "Hidden states sum =  tensor(-15426.1260, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 5 called in free_generate mode with L = 55\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-15426.1260, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-15426.1260, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1555.2682, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 55, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1312.8590, device='cuda:0')\n",
      "Residual states sum =  tensor(-1555.2682, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-15426.1260, device='cuda:0')\n",
      "Hidden states sum =  tensor(-67751.9531, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 6 called in free_generate mode with L = 55\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-67751.9531, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-67751.9531, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1186.1459, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 55, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-4509.4326, device='cuda:0')\n",
      "Residual states sum =  tensor(-1186.1459, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-67751.9531, device='cuda:0')\n",
      "Hidden states sum =  tensor(4373.9346, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 7 called in free_generate mode with L = 55\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(4373.9346, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(4373.9346, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-150.8424, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 55, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1047.0464, device='cuda:0')\n",
      "Residual states sum =  tensor(-150.8424, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(4373.9346, device='cuda:0')\n",
      "Hidden states sum =  tensor(9343.1836, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 8 called in free_generate mode with L = 55\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(9343.1836, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(9343.1836, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(799.7042, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 55, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1658.5952, device='cuda:0')\n",
      "Residual states sum =  tensor(799.7042, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(9343.1836, device='cuda:0')\n",
      "Hidden states sum =  tensor(6935.4727, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 9 called in free_generate mode with L = 55\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(6935.4727, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(6935.4727, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(648.5937, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 55, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(168.6959, device='cuda:0')\n",
      "Residual states sum =  tensor(648.5937, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(6935.4727, device='cuda:0')\n",
      "Hidden states sum =  tensor(-1530.0195, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 10 called in free_generate mode with L = 55\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-1530.0195, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-1530.0195, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-532.0698, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 55, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2942.9910, device='cuda:0')\n",
      "Residual states sum =  tensor(-532.0698, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-1530.0195, device='cuda:0')\n",
      "Hidden states sum =  tensor(24880.0898, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 11 called in free_generate mode with L = 55\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(24880.0898, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(24880.0898, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(4071.5049, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 55, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-4519.3906, device='cuda:0')\n",
      "Residual states sum =  tensor(4071.5049, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(24880.0898, device='cuda:0')\n",
      "Hidden states sum =  tensor(-10418.0840, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 12 called in free_generate mode with L = 55\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-10418.0840, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-10418.0840, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1113.3922, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 55, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-461.1465, device='cuda:0')\n",
      "Residual states sum =  tensor(-1113.3922, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-10418.0840, device='cuda:0')\n",
      "Hidden states sum =  tensor(-4375.7207, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 13 called in free_generate mode with L = 55\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-4375.7207, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-4375.7207, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-409.3472, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 55, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(3850.3428, device='cuda:0')\n",
      "Residual states sum =  tensor(-409.3472, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-4375.7207, device='cuda:0')\n",
      "Hidden states sum =  tensor(11708.5703, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 14 called in free_generate mode with L = 55\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(11708.5703, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(11708.5703, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(2136.3538, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 55, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(9342.3730, device='cuda:0')\n",
      "Residual states sum =  tensor(2136.3538, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(11708.5703, device='cuda:0')\n",
      "Hidden states sum =  tensor(6473.8149, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 15 called in free_generate mode with L = 55\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(6473.8149, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(6473.8149, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1602.0754, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 55, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-8700.7861, device='cuda:0')\n",
      "Residual states sum =  tensor(1602.0754, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(6473.8149, device='cuda:0')\n",
      "Hidden states sum =  tensor(12066.3018, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 16 called in free_generate mode with L = 55\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(12066.3018, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(12066.3018, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1605.0566, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 55, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-14243.0645, device='cuda:0')\n",
      "Residual states sum =  tensor(1605.0566, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(12066.3018, device='cuda:0')\n",
      "Hidden states sum =  tensor(-32890.7461, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 17 called in free_generate mode with L = 55\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-32890.7461, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-32890.7461, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1612.0048, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 55, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(9474.3262, device='cuda:0')\n",
      "Residual states sum =  tensor(-1612.0048, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-32890.7461, device='cuda:0')\n",
      "Hidden states sum =  tensor(106136.1406, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 18 called in free_generate mode with L = 55\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(106136.1406, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(106136.1406, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(3299.3591, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 55, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(93.1465, device='cuda:0')\n",
      "Residual states sum =  tensor(3299.3591, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(106136.1406, device='cuda:0')\n",
      "Hidden states sum =  tensor(-21750.3438, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 19 called in free_generate mode with L = 55\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-21750.3438, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-21750.3438, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1071.2280, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 55, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2903.9214, device='cuda:0')\n",
      "Residual states sum =  tensor(-1071.2280, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-21750.3438, device='cuda:0')\n",
      "Hidden states sum =  tensor(-21162.9824, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 20 called in free_generate mode with L = 55\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-21162.9824, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-21162.9824, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-327.3437, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 55, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(592.2435, device='cuda:0')\n",
      "Residual states sum =  tensor(-327.3437, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-21162.9824, device='cuda:0')\n",
      "Hidden states sum =  tensor(9110.5342, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 21 called in free_generate mode with L = 55\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(9110.5342, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(9110.5342, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-192.5205, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 55, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(8673.7344, device='cuda:0')\n",
      "Residual states sum =  tensor(-192.5205, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(9110.5342, device='cuda:0')\n",
      "Hidden states sum =  tensor(-8639.8320, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 22 called in free_generate mode with L = 55\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-8639.8320, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-8639.8320, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-55.3889, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 55, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-4373.4326, device='cuda:0')\n",
      "Residual states sum =  tensor(-55.3889, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-8639.8320, device='cuda:0')\n",
      "Hidden states sum =  tensor(3515.8262, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 23 called in free_generate mode with L = 55\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(3515.8262, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(3515.8262, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(471.7842, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 55, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(4932.6738, device='cuda:0')\n",
      "Residual states sum =  tensor(471.7842, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(3515.8262, device='cuda:0')\n",
      "Hidden states sum =  tensor(38982.5234, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 24 called in free_generate mode with L = 55\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(38982.5234, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(38982.5234, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1323.4437, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 55, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-3098.8999, device='cuda:0')\n",
      "Residual states sum =  tensor(1323.4437, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(38982.5234, device='cuda:0')\n",
      "Hidden states sum =  tensor(-20894.2969, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 25 called in free_generate mode with L = 55\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-20894.2969, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-20894.2969, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1245.1450, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 55, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(5788.6196, device='cuda:0')\n",
      "Residual states sum =  tensor(-1245.1450, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-20894.2969, device='cuda:0')\n",
      "Hidden states sum =  tensor(-8977.3154, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 26 called in free_generate mode with L = 55\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-8977.3154, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-8977.3154, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-66.7305, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 55, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(14274.6221, device='cuda:0')\n",
      "Residual states sum =  tensor(-66.7305, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-8977.3154, device='cuda:0')\n",
      "Hidden states sum =  tensor(18052.8379, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 27 called in free_generate mode with L = 55\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(18052.8379, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(18052.8379, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-206.3767, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 55, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(24095.4531, device='cuda:0')\n",
      "Residual states sum =  tensor(-206.3767, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(18052.8379, device='cuda:0')\n",
      "Hidden states sum =  tensor(-15975.3770, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 0 called in free_generate mode with L = 56\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(30.9360, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(30.9360, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(221.0916, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 56, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(726.1251, device='cuda:0')\n",
      "Residual states sum =  tensor(221.0916, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(30.9360, device='cuda:0')\n",
      "Hidden states sum =  tensor(920.5670, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 1 called in free_generate mode with L = 56\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(920.5670, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(920.5670, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(191.1904, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 56, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(721.2573, device='cuda:0')\n",
      "Residual states sum =  tensor(191.1904, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(920.5670, device='cuda:0')\n",
      "Hidden states sum =  tensor(1270.2439, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 2 called in free_generate mode with L = 56\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(1270.2439, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(1270.2439, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-90.5739, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 56, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(425.6023, device='cuda:0')\n",
      "Residual states sum =  tensor(-90.5739, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(1270.2439, device='cuda:0')\n",
      "Hidden states sum =  tensor(22066.6621, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 3 called in free_generate mode with L = 56\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(22066.6621, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(22066.6621, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(438.6528, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 56, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1847.4021, device='cuda:0')\n",
      "Residual states sum =  tensor(438.6528, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(22066.6621, device='cuda:0')\n",
      "Hidden states sum =  tensor(-13316.7783, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 4 called in free_generate mode with L = 56\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-13316.7783, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-13316.7783, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-977.6886, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 56, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2774.5674, device='cuda:0')\n",
      "Residual states sum =  tensor(-977.6886, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-13316.7783, device='cuda:0')\n",
      "Hidden states sum =  tensor(-15508.4775, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 5 called in free_generate mode with L = 56\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-15508.4775, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-15508.4775, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1568.2147, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 56, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1303.4540, device='cuda:0')\n",
      "Residual states sum =  tensor(-1568.2147, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-15508.4775, device='cuda:0')\n",
      "Hidden states sum =  tensor(-68680.6875, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 6 called in free_generate mode with L = 56\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-68680.6875, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-68680.6875, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1205.7347, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 56, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-4589.3706, device='cuda:0')\n",
      "Residual states sum =  tensor(-1205.7347, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-68680.6875, device='cuda:0')\n",
      "Hidden states sum =  tensor(4395.8369, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 7 called in free_generate mode with L = 56\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(4395.8369, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(4395.8369, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-152.9434, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 56, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1065.4980, device='cuda:0')\n",
      "Residual states sum =  tensor(-152.9434, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(4395.8369, device='cuda:0')\n",
      "Hidden states sum =  tensor(9520.1162, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 8 called in free_generate mode with L = 56\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(9520.1162, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(9520.1162, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(821.8845, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 56, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1667.7660, device='cuda:0')\n",
      "Residual states sum =  tensor(821.8845, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(9520.1162, device='cuda:0')\n",
      "Hidden states sum =  tensor(7056.7588, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 9 called in free_generate mode with L = 56\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(7056.7588, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(7056.7588, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(661.8350, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 56, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(159.5054, device='cuda:0')\n",
      "Residual states sum =  tensor(661.8350, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(7056.7588, device='cuda:0')\n",
      "Hidden states sum =  tensor(-1573.1680, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 10 called in free_generate mode with L = 56\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-1573.1680, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-1573.1680, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-546.5320, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 56, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(3016.2551, device='cuda:0')\n",
      "Residual states sum =  tensor(-546.5320, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-1573.1680, device='cuda:0')\n",
      "Hidden states sum =  tensor(25329.4219, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 11 called in free_generate mode with L = 56\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(25329.4219, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(25329.4219, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(4146.6997, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 56, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-4602.3730, device='cuda:0')\n",
      "Residual states sum =  tensor(4146.6997, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(25329.4219, device='cuda:0')\n",
      "Hidden states sum =  tensor(-10566.3555, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 12 called in free_generate mode with L = 56\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-10566.3555, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-10566.3555, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1128.9845, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 56, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-470.4089, device='cuda:0')\n",
      "Residual states sum =  tensor(-1128.9845, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-10566.3555, device='cuda:0')\n",
      "Hidden states sum =  tensor(-4431.9878, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 13 called in free_generate mode with L = 56\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-4431.9878, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-4431.9878, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-414.8327, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 56, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(3937.7031, device='cuda:0')\n",
      "Residual states sum =  tensor(-414.8327, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-4431.9878, device='cuda:0')\n",
      "Hidden states sum =  tensor(11966.3184, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 14 called in free_generate mode with L = 56\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(11966.3184, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(11966.3184, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(2181.3018, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 56, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(9517.6328, device='cuda:0')\n",
      "Residual states sum =  tensor(2181.3018, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(11966.3184, device='cuda:0')\n",
      "Hidden states sum =  tensor(6580.1016, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 15 called in free_generate mode with L = 56\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(6580.1016, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(6580.1016, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1629.3566, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 56, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-8866.1250, device='cuda:0')\n",
      "Residual states sum =  tensor(1629.3566, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(6580.1016, device='cuda:0')\n",
      "Hidden states sum =  tensor(12272.6602, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 16 called in free_generate mode with L = 56\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(12272.6602, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(12272.6602, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1633.3864, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 56, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-14501.7158, device='cuda:0')\n",
      "Residual states sum =  tensor(1633.3864, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(12272.6602, device='cuda:0')\n",
      "Hidden states sum =  tensor(-33502.0859, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 17 called in free_generate mode with L = 56\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-33502.0859, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-33502.0859, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1642.0737, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 56, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(9646.5859, device='cuda:0')\n",
      "Residual states sum =  tensor(-1642.0737, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-33502.0859, device='cuda:0')\n",
      "Hidden states sum =  tensor(108068.7344, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 18 called in free_generate mode with L = 56\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(108068.7344, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(108068.7344, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(3359.3716, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 56, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(94.9950, device='cuda:0')\n",
      "Residual states sum =  tensor(3359.3716, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(108068.7344, device='cuda:0')\n",
      "Hidden states sum =  tensor(-22146.2207, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 19 called in free_generate mode with L = 56\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-22146.2207, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-22146.2207, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1090.7101, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 56, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(2956.7869, device='cuda:0')\n",
      "Residual states sum =  tensor(-1090.7101, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-22146.2207, device='cuda:0')\n",
      "Hidden states sum =  tensor(-21547.9844, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 20 called in free_generate mode with L = 56\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-21547.9844, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-21547.9844, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-333.3182, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 56, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(603.0245, device='cuda:0')\n",
      "Residual states sum =  tensor(-333.3182, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-21547.9844, device='cuda:0')\n",
      "Hidden states sum =  tensor(9276.2754, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 21 called in free_generate mode with L = 56\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(9276.2754, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(9276.2754, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-196.0172, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 56, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(8831.4404, device='cuda:0')\n",
      "Residual states sum =  tensor(-196.0172, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(9276.2754, device='cuda:0')\n",
      "Hidden states sum =  tensor(-8796.9238, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 22 called in free_generate mode with L = 56\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-8796.9238, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-8796.9238, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-56.3963, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 56, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-4452.9492, device='cuda:0')\n",
      "Residual states sum =  tensor(-56.3963, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-8796.9238, device='cuda:0')\n",
      "Hidden states sum =  tensor(3579.7305, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 23 called in free_generate mode with L = 56\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(3579.7305, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(3579.7305, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(480.3615, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 56, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(5022.3594, device='cuda:0')\n",
      "Residual states sum =  tensor(480.3615, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(3579.7305, device='cuda:0')\n",
      "Hidden states sum =  tensor(39691.3008, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 24 called in free_generate mode with L = 56\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(39691.3008, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(39691.3008, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1347.5062, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 56, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-3155.2449, device='cuda:0')\n",
      "Residual states sum =  tensor(1347.5062, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(39691.3008, device='cuda:0')\n",
      "Hidden states sum =  tensor(-21274.1973, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 25 called in free_generate mode with L = 56\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-21274.1973, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-21274.1973, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1267.7842, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 56, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(5893.8677, device='cuda:0')\n",
      "Residual states sum =  tensor(-1267.7842, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-21274.1973, device='cuda:0')\n",
      "Hidden states sum =  tensor(-9140.5410, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 26 called in free_generate mode with L = 56\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-9140.5410, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-9140.5410, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-67.9439, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 56, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(14534.1621, device='cuda:0')\n",
      "Residual states sum =  tensor(-67.9439, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-9140.5410, device='cuda:0')\n",
      "Hidden states sum =  tensor(18381.0723, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 27 called in free_generate mode with L = 56\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(18381.0723, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(18381.0723, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-210.1288, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 56, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(24533.5527, device='cuda:0')\n",
      "Residual states sum =  tensor(-210.1288, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(18381.0723, device='cuda:0')\n",
      "Hidden states sum =  tensor(-16265.8359, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 0 called in free_generate mode with L = 57\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(30.6512, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(30.6512, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(220.7254, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 57, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(759.2053, device='cuda:0')\n",
      "Residual states sum =  tensor(220.7254, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(30.6512, device='cuda:0')\n",
      "Hidden states sum =  tensor(979.8217, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 1 called in free_generate mode with L = 57\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(979.8217, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(979.8217, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(201.5808, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 57, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(719.6541, device='cuda:0')\n",
      "Residual states sum =  tensor(201.5808, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(979.8217, device='cuda:0')\n",
      "Hidden states sum =  tensor(1235.1565, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 2 called in free_generate mode with L = 57\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(1235.1565, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(1235.1565, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-106.3407, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 57, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(424.8334, device='cuda:0')\n",
      "Residual states sum =  tensor(-106.3407, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(1235.1565, device='cuda:0')\n",
      "Hidden states sum =  tensor(22275.6348, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 3 called in free_generate mode with L = 57\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(22275.6348, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(22275.6348, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(438.0974, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 57, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1907.4236, device='cuda:0')\n",
      "Residual states sum =  tensor(438.0974, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(22275.6348, device='cuda:0')\n",
      "Hidden states sum =  tensor(-13484.0859, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 4 called in free_generate mode with L = 57\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-13484.0859, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-13484.0859, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-997.1949, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 57, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2817.3279, device='cuda:0')\n",
      "Residual states sum =  tensor(-997.1949, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-13484.0859, device='cuda:0')\n",
      "Hidden states sum =  tensor(-15562.3818, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 5 called in free_generate mode with L = 57\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-15562.3818, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-15562.3818, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1575.6245, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 57, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1293.0286, device='cuda:0')\n",
      "Residual states sum =  tensor(-1575.6245, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-15562.3818, device='cuda:0')\n",
      "Hidden states sum =  tensor(-69568.7578, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 6 called in free_generate mode with L = 57\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-69568.7578, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-69568.7578, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1224.2234, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 57, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-4669.6484, device='cuda:0')\n",
      "Residual states sum =  tensor(-1224.2234, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-69568.7578, device='cuda:0')\n",
      "Hidden states sum =  tensor(4420.9932, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 7 called in free_generate mode with L = 57\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(4420.9932, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(4420.9932, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-154.6418, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 57, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1083.3761, device='cuda:0')\n",
      "Residual states sum =  tensor(-154.6418, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(4420.9932, device='cuda:0')\n",
      "Hidden states sum =  tensor(9692.4297, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 8 called in free_generate mode with L = 57\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(9692.4297, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(9692.4297, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(843.5147, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 57, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1675.2534, device='cuda:0')\n",
      "Residual states sum =  tensor(843.5147, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(9692.4297, device='cuda:0')\n",
      "Hidden states sum =  tensor(7177.9380, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 9 called in free_generate mode with L = 57\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(7177.9380, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(7177.9380, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(675.1844, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 57, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(150.0524, device='cuda:0')\n",
      "Residual states sum =  tensor(675.1844, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(7177.9380, device='cuda:0')\n",
      "Hidden states sum =  tensor(-1624.0664, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 10 called in free_generate mode with L = 57\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-1624.0664, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-1624.0664, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-562.2130, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 57, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(3090.3640, device='cuda:0')\n",
      "Residual states sum =  tensor(-562.2130, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-1624.0664, device='cuda:0')\n",
      "Hidden states sum =  tensor(25781.4160, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 11 called in free_generate mode with L = 57\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(25781.4160, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(25781.4160, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(4222.1787, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 57, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-4685.0146, device='cuda:0')\n",
      "Residual states sum =  tensor(4222.1787, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(25781.4160, device='cuda:0')\n",
      "Hidden states sum =  tensor(-10713.6523, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 12 called in free_generate mode with L = 57\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-10713.6523, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-10713.6523, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1144.4082, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 57, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-479.7581, device='cuda:0')\n",
      "Residual states sum =  tensor(-1144.4082, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-10713.6523, device='cuda:0')\n",
      "Hidden states sum =  tensor(-4488.8574, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 13 called in free_generate mode with L = 57\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-4488.8574, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-4488.8574, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-420.3432, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 57, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(4026.0718, device='cuda:0')\n",
      "Residual states sum =  tensor(-420.3432, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-4488.8574, device='cuda:0')\n",
      "Hidden states sum =  tensor(12227.0664, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 14 called in free_generate mode with L = 57\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(12227.0664, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(12227.0664, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(2226.6079, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 57, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(9693.0234, device='cuda:0')\n",
      "Residual states sum =  tensor(2226.6079, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(12227.0664, device='cuda:0')\n",
      "Hidden states sum =  tensor(6685.1484, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 15 called in free_generate mode with L = 57\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(6685.1484, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(6685.1484, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1656.4771, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 57, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-9031.7793, device='cuda:0')\n",
      "Residual states sum =  tensor(1656.4771, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(6685.1484, device='cuda:0')\n",
      "Hidden states sum =  tensor(12478.4688, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 16 called in free_generate mode with L = 57\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(12478.4688, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(12478.4688, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1661.6926, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 57, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-14760.4492, device='cuda:0')\n",
      "Residual states sum =  tensor(1661.6926, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(12478.4688, device='cuda:0')\n",
      "Hidden states sum =  tensor(-34114.2500, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 17 called in free_generate mode with L = 57\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-34114.2500, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-34114.2500, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1672.2235, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 57, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(9818.8271, device='cuda:0')\n",
      "Residual states sum =  tensor(-1672.2235, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-34114.2500, device='cuda:0')\n",
      "Hidden states sum =  tensor(110001.5156, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 18 called in free_generate mode with L = 57\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(110001.5156, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(110001.5156, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(3419.3882, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 57, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(96.8619, device='cuda:0')\n",
      "Residual states sum =  tensor(3419.3882, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(110001.5156, device='cuda:0')\n",
      "Hidden states sum =  tensor(-22542.1191, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 19 called in free_generate mode with L = 57\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-22542.1191, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-22542.1191, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1110.1932, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 57, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(3009.6641, device='cuda:0')\n",
      "Residual states sum =  tensor(-1110.1932, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-22542.1191, device='cuda:0')\n",
      "Hidden states sum =  tensor(-21932.9824, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 20 called in free_generate mode with L = 57\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-21932.9824, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-21932.9824, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-339.2946, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 57, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(613.8077, device='cuda:0')\n",
      "Residual states sum =  tensor(-339.2946, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-21932.9824, device='cuda:0')\n",
      "Hidden states sum =  tensor(9442.0303, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 21 called in free_generate mode with L = 57\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(9442.0303, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(9442.0303, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-199.5140, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 57, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(8989.1465, device='cuda:0')\n",
      "Residual states sum =  tensor(-199.5140, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(9442.0303, device='cuda:0')\n",
      "Hidden states sum =  tensor(-8954.0156, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 22 called in free_generate mode with L = 57\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-8954.0156, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-8954.0156, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-57.4034, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 57, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-4532.4678, device='cuda:0')\n",
      "Residual states sum =  tensor(-57.4034, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-8954.0156, device='cuda:0')\n",
      "Hidden states sum =  tensor(3643.6406, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 23 called in free_generate mode with L = 57\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(3643.6406, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(3643.6406, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(488.9391, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 57, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(5112.0459, device='cuda:0')\n",
      "Residual states sum =  tensor(488.9391, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(3643.6406, device='cuda:0')\n",
      "Hidden states sum =  tensor(40400.0742, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 24 called in free_generate mode with L = 57\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(40400.0742, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(40400.0742, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1371.5686, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 57, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-3211.5874, device='cuda:0')\n",
      "Residual states sum =  tensor(1371.5686, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(40400.0742, device='cuda:0')\n",
      "Hidden states sum =  tensor(-21654.0859, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 25 called in free_generate mode with L = 57\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-21654.0859, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-21654.0859, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1290.4233, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 57, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(5999.1162, device='cuda:0')\n",
      "Residual states sum =  tensor(-1290.4233, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-21654.0859, device='cuda:0')\n",
      "Hidden states sum =  tensor(-9303.7656, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 26 called in free_generate mode with L = 57\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-9303.7656, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-9303.7656, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-69.1573, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 57, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(14793.6992, device='cuda:0')\n",
      "Residual states sum =  tensor(-69.1573, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-9303.7656, device='cuda:0')\n",
      "Hidden states sum =  tensor(18709.3047, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 27 called in free_generate mode with L = 57\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(18709.3047, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(18709.3047, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-213.8817, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 57, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(24971.6484, device='cuda:0')\n",
      "Residual states sum =  tensor(-213.8817, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(18709.3047, device='cuda:0')\n",
      "Hidden states sum =  tensor(-16556.2930, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 0 called in free_generate mode with L = 58\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(31.1829, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(31.1829, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(222.8006, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 58, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(759.8224, device='cuda:0')\n",
      "Residual states sum =  tensor(222.8006, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(31.1829, device='cuda:0')\n",
      "Hidden states sum =  tensor(997.7087, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 1 called in free_generate mode with L = 58\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(997.7087, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(997.7087, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(210.3878, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 58, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(723.6919, device='cuda:0')\n",
      "Residual states sum =  tensor(210.3878, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(997.7087, device='cuda:0')\n",
      "Hidden states sum =  tensor(1149.7913, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 2 called in free_generate mode with L = 58\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(1149.7913, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(1149.7913, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-127.6815, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 58, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(418.6094, device='cuda:0')\n",
      "Residual states sum =  tensor(-127.6815, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(1149.7913, device='cuda:0')\n",
      "Hidden states sum =  tensor(22470.2852, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 3 called in free_generate mode with L = 58\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(22470.2852, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(22470.2852, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(446.9944, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 58, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1972.3694, device='cuda:0')\n",
      "Residual states sum =  tensor(446.9944, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(22470.2852, device='cuda:0')\n",
      "Hidden states sum =  tensor(-13506.3311, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 4 called in free_generate mode with L = 58\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-13506.3311, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-13506.3311, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1004.9693, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 58, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2857.1768, device='cuda:0')\n",
      "Residual states sum =  tensor(-1004.9693, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-13506.3311, device='cuda:0')\n",
      "Hidden states sum =  tensor(-15617.7744, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 5 called in free_generate mode with L = 58\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-15617.7744, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-15617.7744, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1582.6748, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 58, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1287.1359, device='cuda:0')\n",
      "Residual states sum =  tensor(-1582.6748, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-15617.7744, device='cuda:0')\n",
      "Hidden states sum =  tensor(-70402.7344, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 6 called in free_generate mode with L = 58\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-70402.7344, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-70402.7344, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1241.1257, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 58, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-4750.7012, device='cuda:0')\n",
      "Residual states sum =  tensor(-1241.1257, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-70402.7344, device='cuda:0')\n",
      "Hidden states sum =  tensor(4448.2871, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 7 called in free_generate mode with L = 58\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(4448.2871, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(4448.2871, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-155.9852, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 58, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1100.9103, device='cuda:0')\n",
      "Residual states sum =  tensor(-155.9852, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(4448.2871, device='cuda:0')\n",
      "Hidden states sum =  tensor(9864.6602, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 8 called in free_generate mode with L = 58\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(9864.6602, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(9864.6602, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(865.3903, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 58, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1681.1208, device='cuda:0')\n",
      "Residual states sum =  tensor(865.3903, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(9864.6602, device='cuda:0')\n",
      "Hidden states sum =  tensor(7299.8101, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 9 called in free_generate mode with L = 58\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(7299.8101, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(7299.8101, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(688.6751, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 58, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(140.1965, device='cuda:0')\n",
      "Residual states sum =  tensor(688.6751, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(7299.8101, device='cuda:0')\n",
      "Hidden states sum =  tensor(-1679.4756, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 10 called in free_generate mode with L = 58\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-1679.4756, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-1679.4756, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-578.7883, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 58, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(3165.3215, device='cuda:0')\n",
      "Residual states sum =  tensor(-578.7883, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-1679.4756, device='cuda:0')\n",
      "Hidden states sum =  tensor(26236.5273, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 11 called in free_generate mode with L = 58\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(26236.5273, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(26236.5273, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(4298.0093, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 58, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-4767.2393, device='cuda:0')\n",
      "Residual states sum =  tensor(4298.0093, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(26236.5273, device='cuda:0')\n",
      "Hidden states sum =  tensor(-10860.1797, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 12 called in free_generate mode with L = 58\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-10860.1797, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-10860.1797, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1159.6926, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 58, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-489.1797, device='cuda:0')\n",
      "Residual states sum =  tensor(-1159.6926, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-10860.1797, device='cuda:0')\n",
      "Hidden states sum =  tensor(-4546.6499, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 13 called in free_generate mode with L = 58\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-4546.6499, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-4546.6499, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-425.8797, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 58, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(4115.4697, device='cuda:0')\n",
      "Residual states sum =  tensor(-425.8797, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-4546.6499, device='cuda:0')\n",
      "Hidden states sum =  tensor(12490.6973, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 14 called in free_generate mode with L = 58\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(12490.6973, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(12490.6973, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(2272.2437, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 58, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(9868.5391, device='cuda:0')\n",
      "Residual states sum =  tensor(2272.2437, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(12490.6973, device='cuda:0')\n",
      "Hidden states sum =  tensor(6788.8594, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 15 called in free_generate mode with L = 58\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(6788.8594, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(6788.8594, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1683.4202, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 58, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-9197.7793, device='cuda:0')\n",
      "Residual states sum =  tensor(1683.4202, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(6788.8594, device='cuda:0')\n",
      "Hidden states sum =  tensor(12683.6338, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 16 called in free_generate mode with L = 58\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(12683.6338, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(12683.6338, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1689.9629, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 58, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-15019.2852, device='cuda:0')\n",
      "Residual states sum =  tensor(1689.9629, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(12683.6338, device='cuda:0')\n",
      "Hidden states sum =  tensor(-34727.1875, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 17 called in free_generate mode with L = 58\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-34727.1875, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-34727.1875, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1702.4556, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 58, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(9991.0527, device='cuda:0')\n",
      "Residual states sum =  tensor(-1702.4556, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-34727.1875, device='cuda:0')\n",
      "Hidden states sum =  tensor(111934.4844, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 18 called in free_generate mode with L = 58\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(111934.4844, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(111934.4844, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(3479.4097, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 58, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(98.7477, device='cuda:0')\n",
      "Residual states sum =  tensor(3479.4097, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(111934.4844, device='cuda:0')\n",
      "Hidden states sum =  tensor(-22938.0391, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 19 called in free_generate mode with L = 58\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-22938.0391, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-22938.0391, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1129.6775, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 58, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(3062.5518, device='cuda:0')\n",
      "Residual states sum =  tensor(-1129.6775, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-22938.0391, device='cuda:0')\n",
      "Hidden states sum =  tensor(-22317.9824, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 20 called in free_generate mode with L = 58\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-22317.9824, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-22317.9824, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-345.2728, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 58, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(624.5906, device='cuda:0')\n",
      "Residual states sum =  tensor(-345.2728, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-22317.9824, device='cuda:0')\n",
      "Hidden states sum =  tensor(9607.7900, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 21 called in free_generate mode with L = 58\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(9607.7900, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(9607.7900, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-203.0099, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 58, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(9146.8516, device='cuda:0')\n",
      "Residual states sum =  tensor(-203.0099, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(9607.7900, device='cuda:0')\n",
      "Hidden states sum =  tensor(-9111.1074, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 22 called in free_generate mode with L = 58\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-9111.1074, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-9111.1074, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-58.4106, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 58, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-4611.9844, device='cuda:0')\n",
      "Residual states sum =  tensor(-58.4106, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-9111.1074, device='cuda:0')\n",
      "Hidden states sum =  tensor(3707.5469, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 23 called in free_generate mode with L = 58\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(3707.5469, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(3707.5469, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(497.5160, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 58, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(5201.7324, device='cuda:0')\n",
      "Residual states sum =  tensor(497.5160, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(3707.5469, device='cuda:0')\n",
      "Hidden states sum =  tensor(41108.8438, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 24 called in free_generate mode with L = 58\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(41108.8438, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(41108.8438, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1395.6312, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 58, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-3267.9324, device='cuda:0')\n",
      "Residual states sum =  tensor(1395.6312, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(41108.8438, device='cuda:0')\n",
      "Hidden states sum =  tensor(-22033.9883, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 25 called in free_generate mode with L = 58\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-22033.9883, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-22033.9883, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1313.0623, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 58, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(6104.3633, device='cuda:0')\n",
      "Residual states sum =  tensor(-1313.0623, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-22033.9883, device='cuda:0')\n",
      "Hidden states sum =  tensor(-9466.9893, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 26 called in free_generate mode with L = 58\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-9466.9893, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-9466.9893, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-70.3705, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 58, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(15053.2383, device='cuda:0')\n",
      "Residual states sum =  tensor(-70.3705, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-9466.9893, device='cuda:0')\n",
      "Hidden states sum =  tensor(19037.5371, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 27 called in free_generate mode with L = 58\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(19037.5371, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(19037.5371, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-217.6338, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 58, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(25409.7461, device='cuda:0')\n",
      "Residual states sum =  tensor(-217.6338, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(19037.5371, device='cuda:0')\n",
      "Hidden states sum =  tensor(-16846.7539, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 0 called in free_generate mode with L = 59\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(30.2504, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(30.2504, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(217.8222, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 59, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(750.5959, device='cuda:0')\n",
      "Residual states sum =  tensor(217.8222, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(30.2504, device='cuda:0')\n",
      "Hidden states sum =  tensor(955.0827, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 1 called in free_generate mode with L = 59\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(955.0827, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(955.0827, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(202.6889, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 59, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(725.1407, device='cuda:0')\n",
      "Residual states sum =  tensor(202.6889, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(955.0827, device='cuda:0')\n",
      "Hidden states sum =  tensor(1225.2920, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 2 called in free_generate mode with L = 59\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(1225.2920, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(1225.2920, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-112.6603, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 59, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(393.2200, device='cuda:0')\n",
      "Residual states sum =  tensor(-112.6603, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(1225.2920, device='cuda:0')\n",
      "Hidden states sum =  tensor(23002.0820, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 3 called in free_generate mode with L = 59\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(23002.0820, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(23002.0820, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(465.5668, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 59, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2026.4858, device='cuda:0')\n",
      "Residual states sum =  tensor(465.5668, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(23002.0820, device='cuda:0')\n",
      "Hidden states sum =  tensor(-13815.8184, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 4 called in free_generate mode with L = 59\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-13815.8184, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-13815.8184, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1033.4995, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 59, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-2903.0938, device='cuda:0')\n",
      "Residual states sum =  tensor(-1033.4995, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-13815.8184, device='cuda:0')\n",
      "Hidden states sum =  tensor(-15635.9873, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 5 called in free_generate mode with L = 59\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-15635.9873, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-15635.9873, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1583.0232, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 59, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-1280.6339, device='cuda:0')\n",
      "Residual states sum =  tensor(-1583.0232, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-15635.9873, device='cuda:0')\n",
      "Hidden states sum =  tensor(-71135.9688, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 6 called in free_generate mode with L = 59\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-71135.9688, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-71135.9688, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1255.5822, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 59, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-4832.4902, device='cuda:0')\n",
      "Residual states sum =  tensor(-1255.5822, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-71135.9688, device='cuda:0')\n",
      "Hidden states sum =  tensor(4479.8057, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 7 called in free_generate mode with L = 59\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(4479.8057, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(4479.8057, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-156.6067, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 59, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1118.1005, device='cuda:0')\n",
      "Residual states sum =  tensor(-156.6067, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(4479.8057, device='cuda:0')\n",
      "Hidden states sum =  tensor(10031.0723, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 8 called in free_generate mode with L = 59\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(10031.0723, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(10031.0723, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(886.7877, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 59, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(1685.7605, device='cuda:0')\n",
      "Residual states sum =  tensor(886.7877, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(10031.0723, device='cuda:0')\n",
      "Hidden states sum =  tensor(7424.1641, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 9 called in free_generate mode with L = 59\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(7424.1641, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(7424.1641, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(702.5684, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 59, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(130.2402, device='cuda:0')\n",
      "Residual states sum =  tensor(702.5684, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(7424.1641, device='cuda:0')\n",
      "Hidden states sum =  tensor(-1740.5327, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 10 called in free_generate mode with L = 59\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-1740.5327, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-1740.5327, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-596.3525, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 59, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(3241.2134, device='cuda:0')\n",
      "Residual states sum =  tensor(-596.3525, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-1740.5327, device='cuda:0')\n",
      "Hidden states sum =  tensor(26694.8340, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 11 called in free_generate mode with L = 59\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(26694.8340, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(26694.8340, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(4374.1533, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 59, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-4848.9487, device='cuda:0')\n",
      "Residual states sum =  tensor(4374.1533, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(26694.8340, device='cuda:0')\n",
      "Hidden states sum =  tensor(-11005.6641, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 12 called in free_generate mode with L = 59\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-11005.6641, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-11005.6641, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1174.8241, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 59, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-498.6858, device='cuda:0')\n",
      "Residual states sum =  tensor(-1174.8241, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-11005.6641, device='cuda:0')\n",
      "Hidden states sum =  tensor(-4605.2529, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 13 called in free_generate mode with L = 59\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-4605.2529, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-4605.2529, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-431.3957, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 59, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(4205.8711, device='cuda:0')\n",
      "Residual states sum =  tensor(-431.3957, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-4605.2529, device='cuda:0')\n",
      "Hidden states sum =  tensor(12757.1445, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 14 called in free_generate mode with L = 59\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(12757.1445, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(12757.1445, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(2318.1895, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 59, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(10044.1787, device='cuda:0')\n",
      "Residual states sum =  tensor(2318.1895, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(12757.1445, device='cuda:0')\n",
      "Hidden states sum =  tensor(6891.1675, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 15 called in free_generate mode with L = 59\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(6891.1675, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(6891.1675, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1710.1682, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 59, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-9364.1523, device='cuda:0')\n",
      "Residual states sum =  tensor(1710.1682, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(6891.1675, device='cuda:0')\n",
      "Hidden states sum =  tensor(12888.1338, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 16 called in free_generate mode with L = 59\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(12888.1338, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(12888.1338, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1718.1936, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 59, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-15278.2295, device='cuda:0')\n",
      "Residual states sum =  tensor(1718.1936, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(12888.1338, device='cuda:0')\n",
      "Hidden states sum =  tensor(-35340.8594, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 17 called in free_generate mode with L = 59\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-35340.8594, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-35340.8594, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1732.7732, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 59, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(10163.2588, device='cuda:0')\n",
      "Residual states sum =  tensor(-1732.7732, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-35340.8594, device='cuda:0')\n",
      "Hidden states sum =  tensor(113867.6406, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 18 called in free_generate mode with L = 59\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(113867.6406, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(113867.6406, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(3539.4373, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 59, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(100.6552, device='cuda:0')\n",
      "Residual states sum =  tensor(3539.4373, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(113867.6406, device='cuda:0')\n",
      "Hidden states sum =  tensor(-23333.9824, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 19 called in free_generate mode with L = 59\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-23333.9824, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-23333.9824, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1149.1633, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 59, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(3115.4507, device='cuda:0')\n",
      "Residual states sum =  tensor(-1149.1633, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-23333.9824, device='cuda:0')\n",
      "Hidden states sum =  tensor(-22702.9805, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 20 called in free_generate mode with L = 59\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-22702.9805, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-22702.9805, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-351.2529, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 59, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(635.3768, device='cuda:0')\n",
      "Residual states sum =  tensor(-351.2529, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-22702.9805, device='cuda:0')\n",
      "Hidden states sum =  tensor(9773.5859, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 21 called in free_generate mode with L = 59\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(9773.5859, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(9773.5859, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-206.5057, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 59, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(9304.5586, device='cuda:0')\n",
      "Residual states sum =  tensor(-206.5057, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(9773.5859, device='cuda:0')\n",
      "Hidden states sum =  tensor(-9268.2002, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 22 called in free_generate mode with L = 59\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-9268.2002, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-9268.2002, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-59.4182, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 59, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-4691.5020, device='cuda:0')\n",
      "Residual states sum =  tensor(-59.4182, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-9268.2002, device='cuda:0')\n",
      "Hidden states sum =  tensor(3771.4512, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 23 called in free_generate mode with L = 59\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(3771.4512, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(3771.4512, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(506.0933, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 59, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(5291.4194, device='cuda:0')\n",
      "Residual states sum =  tensor(506.0933, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(3771.4512, device='cuda:0')\n",
      "Hidden states sum =  tensor(41817.6172, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 24 called in free_generate mode with L = 59\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(41817.6172, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(41817.6172, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(1419.6937, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 59, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(-3324.2778, device='cuda:0')\n",
      "Residual states sum =  tensor(1419.6937, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(41817.6172, device='cuda:0')\n",
      "Hidden states sum =  tensor(-22413.8828, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 25 called in free_generate mode with L = 59\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-22413.8828, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-22413.8828, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-1335.7012, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 59, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(6209.6108, device='cuda:0')\n",
      "Residual states sum =  tensor(-1335.7012, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-22413.8828, device='cuda:0')\n",
      "Hidden states sum =  tensor(-9630.2129, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 26 called in free_generate mode with L = 59\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(-9630.2129, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(-9630.2129, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-71.5836, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 59, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(15312.7783, device='cuda:0')\n",
      "Residual states sum =  tensor(-71.5836, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(-9630.2129, device='cuda:0')\n",
      "Hidden states sum =  tensor(19365.7695, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n",
      "Layer 27 called in free_generate mode with L = 59\n",
      "==================================================\n",
      "Entering the computation. Hidden states sum =  tensor(19365.7695, device='cuda:0')\n",
      "Before LayerNorm: Hidden states sum =  tensor(19365.7695, device='cuda:0')\n",
      "After LayerNorm: Hidden states sum =  tensor(-221.3862, device='cuda:0')\n",
      "Hidden states shape =  torch.Size([1, 59, 1536])\n",
      "--------------------------------------------------\n",
      "After attention\n",
      "Hidden states sum =  tensor(25847.8477, device='cuda:0')\n",
      "Residual states sum =  tensor(-221.3862, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "After MLP\n",
      "Original hidden states sum =  tensor(19365.7695, device='cuda:0')\n",
      "Hidden states sum =  tensor(-17137.2227, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Output attentions = False\n",
      "Exiting patched layer\n",
      "================================================== \n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<｜begin▁of▁sentence｜><｜Assistant｜> You are a helpful programming tutor.\\n<｜User｜> Explain the concept of recursion in programming.\\n<｜Assistant｜> \\n-elementsabcdefgh /^-elements /^ )\"chef...\\'-xs #[chef messed fen...\\'pane/blue [[\" )\" \"\\\\\" \"()chefyyyy(CH...\",chefchef mex \"!...\",bidden mex crawler-corner Php \\'((/blue [[\" fenabcdefgh messed'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"Explain the concept of recursion in programming.\"\n",
    "system_prompt = \"You are a helpful programming tutor.\"\n",
    "prefiller = \"\"\n",
    "with torch.no_grad():\n",
    "    free_generate_response, _ = generate_text(\n",
    "        model=model,\n",
    "        prompt=prompt,\n",
    "        system_prompt=system_prompt,\n",
    "        prefiller=prefiller,\n",
    "        tokenizer=tokenizer,\n",
    "        generation_config=config['generation'],\n",
    "        device=device\n",
    "    )\n",
    "free_generate_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99c2cb82-edec-42ee-a1f8-9df6f9f4ec27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<｜begin▁of▁sentence｜><｜Assistant｜> You are a helpful programming tutor.\\n<｜User｜> Explain the concept of recursion in programming.\\n<｜Assistant｜> \\n-elementsabcdefgh /^-elements /^ )\"chef...\\'-xs #[chef messed fen...\\'pane/blue [[\" )\" \"\\\\\" \"()chefyyyy(CH...\",chefchef mex \"!...\",bidden mex crawler-corner Php \\'((/blue [[\" fenabcdefgh messed'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "free_generate_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df9414b-5118-40a8-b2b1-73db9c3e7714",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "def print_forward_sequence(model):\n",
    "    # Track execution order\n",
    "    execution_order = []\n",
    "    \n",
    "    def create_hook(name):\n",
    "        def hook_fn(module, input, output):\n",
    "            # Get input shapes\n",
    "            if isinstance(input, tuple):\n",
    "                input_shapes = [x.shape if hasattr(x, 'shape') else type(x) for x in input]\n",
    "            else:\n",
    "                input_shapes = input.shape if hasattr(input, 'shape') else type(input)\n",
    "            \n",
    "            # Get output shapes\n",
    "            if isinstance(output, tuple):\n",
    "                output_shapes = [x.shape if hasattr(x, 'shape') else type(x) for x in output]\n",
    "            else:\n",
    "                output_shapes = output.shape if hasattr(output, 'shape') else type(output)\n",
    "            \n",
    "            execution_order.append(f\"{name}: {input_shapes} -> {output_shapes}\")\n",
    "        return hook_fn\n",
    "    \n",
    "    # Register hooks on all modules\n",
    "    hooks = []\n",
    "    for name, module in model.named_modules():\n",
    "        if name:  # Skip the root module\n",
    "            hook = module.register_forward_hook(create_hook(name))\n",
    "            hooks.append(hook)\n",
    "    \n",
    "    # Run a forward pass\n",
    "    text = \"Hello, how are you?\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to('cuda')\n",
    "    \n",
    "    print(\"=== FORWARD PASS SEQUENCE ===\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Print execution order\n",
    "    for i, op in enumerate(execution_order):\n",
    "        print(f\"{i+1:2d}. {op}\")\n",
    "    \n",
    "    # Clean up hooks\n",
    "    for hook in hooks:\n",
    "        hook.remove()\n",
    "\n",
    "# Run the sequence printer\n",
    "print_forward_sequence(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e646dbd9-aaf8-42c0-9b36-d2bd92a7934b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): DynamicallyTypedModelWithReadout(\n",
       "      (model): Qwen2Model(\n",
       "        (embed_tokens): Embedding(151936, 1536)\n",
       "        (layers): ModuleList(\n",
       "          (0): DynamicallyTypedLayerWithExit(\n",
       "            (self_attn): Qwen2Attention(\n",
       "              (q_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (early_exiter): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (early_exiter): Linear(in_features=1536, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (early_exiter): Linear(in_features=8, out_features=1536, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1536, out_features=256, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (early_exiter): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (early_exiter): Linear(in_features=1536, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (early_exiter): Linear(in_features=8, out_features=256, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1536, out_features=256, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (early_exiter): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (early_exiter): Linear(in_features=1536, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (early_exiter): Linear(in_features=8, out_features=256, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (early_exiter): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (early_exiter): Linear(in_features=1536, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (early_exiter): Linear(in_features=8, out_features=1536, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (mlp): Qwen2MLP(\n",
       "              (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "              (up_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "              (down_proj): Linear(in_features=8960, out_features=1536, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "            (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "            (early_exit_decision_weights): Linear(in_features=1536, out_features=1, bias=True)\n",
       "          )\n",
       "          (1-27): 27 x Qwen2DecoderLayer(\n",
       "            (self_attn): Qwen2Attention(\n",
       "              (q_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (early_exiter): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (early_exiter): Linear(in_features=1536, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (early_exiter): Linear(in_features=8, out_features=1536, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1536, out_features=256, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (early_exiter): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (early_exiter): Linear(in_features=1536, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (early_exiter): Linear(in_features=8, out_features=256, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1536, out_features=256, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (early_exiter): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (early_exiter): Linear(in_features=1536, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (early_exiter): Linear(in_features=8, out_features=256, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (early_exiter): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (early_exiter): Linear(in_features=1536, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (early_exiter): Linear(in_features=8, out_features=1536, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (mlp): Qwen2MLP(\n",
       "              (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "              (up_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "              (down_proj): Linear(in_features=8960, out_features=1536, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "            (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "          )\n",
       "        )\n",
       "        (norm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "        (rotary_emb): Qwen2RotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=1536, out_features=151936, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc52e107-c1f4-4c69-8951-46ce424e63a8",
   "metadata": {},
   "source": [
    "## Checking with the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6eb6a1e-b145-4ebe-8d8f-e72b5959f732",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"<｜begin▁of▁sentence｜><｜Assistant｜> You are a helpful programming tutor.\\n<｜User｜> Explain the concept of recursion in programming.\\n<｜Assistant｜>\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "with torch.no_grad():\n",
    "    outputs = base_model(**inputs, output_hidden_states=True)\n",
    "    hidden_states = outputs.hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd7587e8-2328-4b82-8301-4c4ae7bd0650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 20, 1536])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states[11].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4fb49f7-d430-4a78-8900-acc713a51b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer = 0| Sum = 12.375\n",
      "Layer = 1| Sum = 756.0\n",
      "Layer = 2| Sum = 1688.0\n",
      "Layer = 3| Sum = -2448.0\n",
      "Layer = 4| Sum = -2432.0\n",
      "Layer = 5| Sum = -2208.0\n",
      "Layer = 6| Sum = -2656.0\n",
      "Layer = 7| Sum = -2528.0\n",
      "Layer = 8| Sum = -2608.0\n",
      "Layer = 9| Sum = -2576.0\n"
     ]
    }
   ],
   "source": [
    "for layer_idx in range(10):\n",
    "    print(f\"Layer = {layer_idx}|\", f\"Sum = {hidden_states[layer_idx].sum().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c123a557-487a-46ca-b390-7e9c86d48100",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
