{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "661aa913-9bd0-4d06-8a16-631b6c239911",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from shared_utils.data import CSVPromptDataset\n",
    "from shared_utils.load import get_model, get_tokenizer, configs_from_yaml\n",
    "from shared_utils.generate import generate_text\n",
    "\n",
    "from early_exit.patching import replace_attention_layers, set_transformer_early_exit_mode\n",
    "\n",
    "import wandb\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47cc87f3-6953-4ca3-8be0-cab2f1e7077b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD IN EXPERIMENT ARGS\n",
    "# num_epoch = 1                     # args.num_epoch\n",
    "num_exit_samples = 1                  # args.num_exit_samples\n",
    "device = \"cuda\"                    # args.device\n",
    "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"                    # args.model_name\n",
    "model_config_path = \"../config_deepseek.yaml\"                     # args.model_config_path\n",
    "dataset_path = \"../results_and_data/early_exit_sft_dataset/test/data.csv\"                  # args.dataset_path\n",
    "prompt_config_path = \"../results_and_data/early_exit_sft_dataset/test/prompt_config.json\"                    # args.prompt_config_path\n",
    "batch_size = 1                    # args.batch_size -- might want to sort out batching, but increasing num_exit_samples might be better + less effort\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "847aa673-2067-4280-837b-97724f70ccb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replacing layer model.layers.0\n",
      "replacing layer model.layers.5\n",
      "replacing layer model.layers.10\n",
      "replacing layer model.layers.15\n",
      "replacing layer model.layers.20\n",
      "replacing layer model.layers.25\n",
      "address this hack!\n",
      "trainable params: 2,179,072 || all params: 1,779,276,294 || trainable%: 0.1225\n"
     ]
    }
   ],
   "source": [
    "# LOAD IN THE MODEL AND TOKENIZER\n",
    "tokenizer = get_tokenizer(model_name)\n",
    "config = configs_from_yaml(model_config_path, tokenizer.eos_token_id)\n",
    "model = get_model(model_name, config['model'], device)\n",
    "\n",
    "\n",
    "# LOAD IN DATASET\n",
    "dataset = CSVPromptDataset(dataset_path, prompt_config_path)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, collate_fn=dataset.collate_fn, shuffle=True)\n",
    "\n",
    "\n",
    "# ENABLE EARLY EXITING\n",
    "model = replace_attention_layers(model, config['lora'], device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab955367-3761-492a-b199-c06751456441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transform_conversations currently only for Deepseek models!\n",
      "full_tokenize currently only for Deepseek models!\n",
      "prompt tokens shape: torch.Size([1, 20])\n",
      "CRUDE KL\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Explain the concept of recursion in programming.\"\n",
    "system_prompt = \"You are a helpful programming tutor.\"\n",
    "prefiller = \"\"\n",
    "\n",
    "set_transformer_early_exit_mode(model, 'sft_teacher')\n",
    "\n",
    "with torch.no_grad():\n",
    "    sft_teacher_response, (sft_teacher_generated_tokens, \n",
    "                          sft_teacher_final_layer_logprobs, \n",
    "                          gathered_early_exit_hidden_states) = generate_text(\n",
    "        model=model,\n",
    "        prompt=prompt,\n",
    "        system_prompt=system_prompt,\n",
    "        prefiller=prefiller,\n",
    "        tokenizer=tokenizer,\n",
    "        generation_config=config['generation'],\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    early_output_log_probs = model.early_exit_hidden_state_readout(gathered_early_exit_hidden_states)\n",
    "    \n",
    "    early_exit_probs = model.early_exit_target_probs(\n",
    "        early_output_log_probs=early_output_log_probs,\n",
    "        teacher_final_layer_log_probs=sft_teacher_final_layer_logprobs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86af1573-318b-4985-95df-aa2d5130a3bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<｜begin▁of▁sentence｜><｜Assistant｜> You are a helpful programming tutor.\\n<｜User｜> Explain the concept of recursion in programming.\\n<｜Assistant｜> \\nAlright, so I need to explain recursion in programming. Hmm, recursion is a method where a function calls itself to solve a problem. I remember it's used in many algorithms, especially those that can be broken down into smaller, similar subproblems. \\n\\nWait, how does it work exactly? I think you have a base case that stops the recursion. Like, if I have a function that calculates the factorial of a number, the base case would be when the number is 0 or 1 because 0! and 1! are both 1. \\n\\nBut then, for other numbers, I call the function again with a smaller number. So, for example, factorial(n) would call factorial(n-1) and multiply by n. That makes sense because if I keep doing that, it will eventually reach the base case.\\n\\nI should also mention why recursion is useful. It can simplify code, especially for problems that have a natural recursive structure. But I need to be careful with stack overflow because each recursive call adds to the call stack. \\n\\nOh, right, in some cases, like deep recursion, Python might not handle it well and could cause a maximum recursion depth error. So, it's important to set a limit or use iteration where possible.\\n\\nAlso, I should note that recursion can be tricky and might require careful testing to avoid infinite loops. Maybe I should give an example of a problem solved with recursion, like traversing a tree or calculating Fibonacci numbers.\\n\\nWait, let me think of the Fibonacci sequence. Each number is the sum of the two preceding ones. So, to compute Fibonacci(n), you can compute Fibonacci(n-1) + Fibonacci(n-2). That's a good example because it shows how recursion breaks down the problem into smaller parts.\\n\\nI should also mention the advantages: it's often more concise, easier to understand, and sometimes more efficient than iterative methods. But it's also important to know the trade-offs, especially with stack limitations.\\n\\nI\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sft_teacher_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4332e58c-40ec-4210-bdb4-4523551e827a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting exit layers to inf for sft_student\n",
      "Minimum in prescribed_exit_layer_idxs = inf\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    batch, gen_len, elayers = early_exit_probs.shape \n",
    "    full_len = sft_teacher_generated_tokens.shape[1]\n",
    "    repeated_sft_teacher_generated_tokens = sft_teacher_generated_tokens.expand(num_exit_samples * batch, full_len)   \n",
    "    set_transformer_early_exit_mode(model, 'sft_student')\n",
    "    \n",
    "    # Create prescribed exit layer idxs filled with torch.inf (always exit on last layer)\n",
    "    batch_samples, seq_len = repeated_sft_teacher_generated_tokens.shape\n",
    "    print(\"Setting exit layers to inf for sft_student\")\n",
    "    prescribed_exit_layer_idxs = torch.full((batch_samples, gen_len), torch.inf, \\\n",
    "                                            device=repeated_sft_teacher_generated_tokens.device)\n",
    "    print(f\"Minimum in prescribed_exit_layer_idxs = {torch.min(prescribed_exit_layer_idxs)}\")\n",
    "    sft_student_output_scores, collected_exit_logits = model(repeated_sft_teacher_generated_tokens,\\\n",
    "                                                             prescribed_exit_layer_idxs=prescribed_exit_layer_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cce8e989-53ef-4da3-9f64-1dee10178b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRUDE KL AND MAKE SURE PROBS ARE ALIGNED\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(30.1700, device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print('CRUDE KL AND MAKE SURE PROBS ARE ALIGNED')\n",
    "    eps = 1e-16\n",
    "    sft_teacher_probs = sft_teacher_final_layer_logprobs.softmax(-1)                        # [batch * samples, gen len, vocabulary]\n",
    "    sft_student_probs = sft_student_output_scores.logits[:,-gen_len:].softmax(-1)           # [batch * samples, gen len, vocabulary]\n",
    "    token_logits_kl_div = (sft_student_probs * ((sft_student_probs + eps) / (sft_teacher_probs + eps)).log()).sum(-1)   # [batch * samples, gen len]\n",
    "    \n",
    "    mean_logit_kl = token_logits_kl_div.mean()\n",
    "\n",
    "mean_logit_kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4bbf043-2dcb-4814-8221-688d6a38ab92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style='display: flex; flex-wrap: wrap;'><div style='flex: 1; min-width: 300px; padding: 10px;'><h4>Student NTP for token 5</h4><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Token ID</th>\n",
       "      <th>Token String</th>\n",
       "      <th>Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>' ('</td>\n",
       "      <td>0.2374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>659</td>\n",
       "      <td>' .'</td>\n",
       "      <td>0.0463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>328</td>\n",
       "      <td>' S'</td>\n",
       "      <td>0.0300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1725</td>\n",
       "      <td>'./'</td>\n",
       "      <td>0.0288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1182</td>\n",
       "      <td>' back'</td>\n",
       "      <td>0.0131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div><div style='flex: 1; min-width: 300px; padding: 10px;'><h4>Student NTP for token 6</h4><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Token ID</th>\n",
       "      <th>Token String</th>\n",
       "      <th>Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>' ('</td>\n",
       "      <td>0.2391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>659</td>\n",
       "      <td>' .'</td>\n",
       "      <td>0.0400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1725</td>\n",
       "      <td>'./'</td>\n",
       "      <td>0.0271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>328</td>\n",
       "      <td>' S'</td>\n",
       "      <td>0.0269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1182</td>\n",
       "      <td>' back'</td>\n",
       "      <td>0.0146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div><div style='flex: 1; min-width: 300px; padding: 10px;'><h4>Student NTP for token 7</h4><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Token ID</th>\n",
       "      <th>Token String</th>\n",
       "      <th>Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>' ('</td>\n",
       "      <td>0.2353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>659</td>\n",
       "      <td>' .'</td>\n",
       "      <td>0.0478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>328</td>\n",
       "      <td>' S'</td>\n",
       "      <td>0.0302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1725</td>\n",
       "      <td>'./'</td>\n",
       "      <td>0.0294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1182</td>\n",
       "      <td>' back'</td>\n",
       "      <td>0.0126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div><div style='flex: 1; min-width: 300px; padding: 10px;'><h4>Student NTP for token 8</h4><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Token ID</th>\n",
       "      <th>Token String</th>\n",
       "      <th>Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>' ('</td>\n",
       "      <td>0.2499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>659</td>\n",
       "      <td>' .'</td>\n",
       "      <td>0.0439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>328</td>\n",
       "      <td>' S'</td>\n",
       "      <td>0.0300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1725</td>\n",
       "      <td>'./'</td>\n",
       "      <td>0.0261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1182</td>\n",
       "      <td>' back'</td>\n",
       "      <td>0.0129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div><div style='flex: 1; min-width: 300px; padding: 10px;'><h4>Student NTP for token 9</h4><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Token ID</th>\n",
       "      <th>Token String</th>\n",
       "      <th>Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>' ('</td>\n",
       "      <td>0.2257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>659</td>\n",
       "      <td>' .'</td>\n",
       "      <td>0.0456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>328</td>\n",
       "      <td>' S'</td>\n",
       "      <td>0.0347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1725</td>\n",
       "      <td>'./'</td>\n",
       "      <td>0.0284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1182</td>\n",
       "      <td>' back'</td>\n",
       "      <td>0.0137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div><div style='flex: 1; min-width: 300px; padding: 10px;'><h4>Student NTP for token 10</h4><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Token ID</th>\n",
       "      <th>Token String</th>\n",
       "      <th>Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>' ('</td>\n",
       "      <td>0.2359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>659</td>\n",
       "      <td>' .'</td>\n",
       "      <td>0.0487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>328</td>\n",
       "      <td>' S'</td>\n",
       "      <td>0.0312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1725</td>\n",
       "      <td>'./'</td>\n",
       "      <td>0.0279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1182</td>\n",
       "      <td>' back'</td>\n",
       "      <td>0.0128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, Markdown, HTML\n",
    "\n",
    "def topk_to_df(prob_dist, tokenizer=None, k=5, title=\"Top-K Predictions\"):\n",
    "    \"\"\"\n",
    "    Return top-k predictions and probabilities as a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    top_values, top_indices = torch.topk(prob_dist, k=k)\n",
    "    \n",
    "    rows = []\n",
    "    for i, (idx, prob) in enumerate(zip(top_indices, top_values)):\n",
    "        token_id = idx.item()\n",
    "        prob_val = prob.item()\n",
    "        token_str = tokenizer.decode([token_id]) if tokenizer else str(token_id)\n",
    "        token_str = repr(token_str)  # Shows escape characters properly\n",
    "        \n",
    "        rows.append({\n",
    "            \"Token ID\": token_id,\n",
    "            \"Token String\": token_str,\n",
    "            \"Probability\": prob_val,\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(rows)\n",
    "    return title, df.round(4)\n",
    "\n",
    "# Example usage for your loop\n",
    "dfs = []\n",
    "for idx in range(5, 11):\n",
    "    title, df = topk_to_df(sft_student_probs[0, idx], tokenizer, k=5, title=f\"Student NTP for token {idx}\")\n",
    "    dfs.append((title, df))\n",
    "\n",
    "# Display in a grid\n",
    "html = \"<div style='display: flex; flex-wrap: wrap;'>\"\n",
    "for title, df in dfs:\n",
    "    html += \"<div style='flex: 1; min-width: 300px; padding: 10px;'>\"\n",
    "    html += f\"<h4>{title}</h4>\"\n",
    "    html += df.to_html(index=False)\n",
    "    html += \"</div>\"\n",
    "html += \"</div>\"\n",
    "\n",
    "display(HTML(html))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e707b44b-8e88-4f47-9e4b-bee64a51e393",
   "metadata": {},
   "source": [
    "### Very similar (and gibberish) next token predictions for all tokens. Something wrong!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bc7df80-150f-4302-8a42-0af37af5748f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replacing layer model.layers.0\n",
      "replacing layer model.layers.5\n",
      "replacing layer model.layers.10\n",
      "replacing layer model.layers.15\n",
      "replacing layer model.layers.20\n",
      "replacing layer model.layers.25\n",
      "address this hack!\n",
      "trainable params: 2,179,072 || all params: 1,779,276,294 || trainable%: 0.1225\n"
     ]
    }
   ],
   "source": [
    "# LOAD IN THE MODEL AND TOKENIZER\n",
    "tokenizer = get_tokenizer(model_name)\n",
    "config = configs_from_yaml(model_config_path, tokenizer.eos_token_id)\n",
    "config['generation']['use_cache'] = False\n",
    "model = get_model(model_name, config['model'], device)\n",
    "\n",
    "\n",
    "# ENABLE EARLY EXITING\n",
    "model = replace_attention_layers(model, config['lora'], device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18123cab-604c-4c64-b3be-c31cb8457b4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prompt = \"Explain the concept of recursion in programming.\"\n",
    "system_prompt = \"You are a helpful programming tutor.\"\n",
    "prefiller = \"\"\n",
    "\n",
    "set_transformer_early_exit_mode(model, 'free_generate')\n",
    "\n",
    "with torch.no_grad():\n",
    "    free_generate_response, _ = generate_text(\n",
    "        model=model,\n",
    "        prompt=prompt,\n",
    "        system_prompt=system_prompt,\n",
    "        prefiller=prefiller,\n",
    "        tokenizer=tokenizer,\n",
    "        generation_config=config['generation'],\n",
    "        device=device\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d383fc51-a4fa-4fbb-9b2f-231aadedd453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<｜begin▁of▁sentence｜><｜Assistant｜> You are a helpful programming tutor.\\n<｜User｜> Explain the concept of recursion in programming.\\n<｜Assistant｜> \\n multilineFire1 1 Th thinner thinner thinner litres litres收 litresShip litres litresbistractive litre.par antiqu bookings bookingstractive litres———— agr litres tombGOR litres walls mathsGORaroMathMath maths upright’B litresMath){\\n\\nd mathsdd�dd seventhMath formX四年MathMath mathsElMath:\\n\\n whereells />\\n\\n litres:\\n\\n,:\\n\\n, maths, — underneath suffers.parL04$\\\\L,\\\\,:\\n\\n\\\\:\\n\\n\\\\\\\\\\\\\\\\\\\\ \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ \\\\ use use\\\\求 \\\\以及:\\n\\n� \\\\ \\\\ \\\\ \\\\){\\n\\n]:\\n\\n出){\\n\\nlish \\\\ \\\\\\\\\\\\ \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\d\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ \\\\\\\\ \\\\\\\\\\\\\\\\ \\\\\\\\\\\\\\\\\\\\\\\\\\\\ \\\\\\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\\\\\\\\\\\t maths \\\\\\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\\\\\\\ \\\\\\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\\\‘ \\\\ — \\\\‘ —‘n‘ ‘‘‘‘’‘‘‘‘‘‘ –‘‘ —‘‘‘‘ \\\\ \\n‘‘‘\\\\\\n \\n‘‘ –‘ shining –‘‘ \\\\ manages(dict \\n‘inz \\\\ \\n \\n —\\\\\\n‘\\n — quotas \\\\‘‘‘‘‘‘‘‘\\\\\\n —‘‘ — \\n \\\\.\\n\\n ‘.\\n\\n \\n\\n\\n.\\n\\n.\\n\\n \\\\unting\\n‘\\n‘\\\\\\n.\\n\\n\\\\\\n‘ \\\\.\\n\\n \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\\\\\\\\\n \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\n \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\n \\\\ \\\\ \\\\\\n \\n \\n \\n \\n \\n \\n \\n,\\n \\n \\\\ \\n \\n \\n \\\\ \\n \\\\ \\\\ \\n \\n\\n \\\\ \\n \\\\ \\\\,,,,,,,,,\\n,'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "free_generate_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97148f69-77ae-40e0-afbb-8c81c1491dae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
