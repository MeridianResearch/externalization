{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "661aa913-9bd0-4d06-8a16-631b6c239911",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from shared_utils.data import CSVPromptDataset\n",
    "from shared_utils.load import get_model, get_tokenizer, configs_from_yaml\n",
    "from shared_utils.generate import generate_text\n",
    "\n",
    "from early_exit.patching import replace_attention_layers, set_transformer_early_exit_mode\n",
    "\n",
    "import wandb\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47cc87f3-6953-4ca3-8be0-cab2f1e7077b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD IN EXPERIMENT ARGS\n",
    "num_epoch = 1                     # args.num_epoch\n",
    "num_exit_samples = 1                  # args.num_exit_samples\n",
    "device = \"cuda\"                    # args.device\n",
    "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"                    # args.model_name\n",
    "model_config_path = \"../config_deepseek.yaml\"                     # args.model_config_path\n",
    "dataset_path = \"../results_and_data/early_exit_sft_dataset/test/data.csv\"                  # args.dataset_path\n",
    "prompt_config_path = \"../results_and_data/early_exit_sft_dataset/test/prompt_config.json\"                    # args.prompt_config_path\n",
    "batch_size = 1                    # args.batch_size -- might want to sort out batching, but increasing num_exit_samples might be better + less effort\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "847aa673-2067-4280-837b-97724f70ccb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replacing layer model.layers.0\n",
      "replacing layer model.layers.5\n",
      "replacing layer model.layers.10\n",
      "replacing layer model.layers.15\n",
      "replacing layer model.layers.20\n",
      "replacing layer model.layers.25\n",
      "address this hack!\n",
      "g++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
      "Copyright (C) 2021 Free Software Foundation, Inc.\n",
      "This is free software; see the source for copying conditions.  There is NO\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
      "\n",
      "trainable params: 2,179,072 || all params: 1,779,276,294 || trainable%: 0.1225\n"
     ]
    }
   ],
   "source": [
    "# LOAD IN THE MODEL AND TOKENIZER\n",
    "tokenizer = get_tokenizer(model_name)\n",
    "config = configs_from_yaml(model_config_path, tokenizer.eos_token_id)\n",
    "model = get_model(model_name, config['model'], device)\n",
    "\n",
    "\n",
    "# LOAD IN DATASET\n",
    "dataset = CSVPromptDataset(dataset_path, prompt_config_path)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, collate_fn=dataset.collate_fn, shuffle=True)\n",
    "\n",
    "\n",
    "# ENABLE EARLY EXITING\n",
    "model = replace_attention_layers(model, config['lora'], device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b88062d9-f776-437c-b09f-e1b9f0044e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transform_conversations currently only for Deepseek models!\n",
      "full_tokenize currently only for Deepseek models!\n",
      "prompt tokens shape: torch.Size([1, 20])\n",
      "CRUDE KL\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Explain the concept of recursion in programming.\"\n",
    "system_prompt = \"You are a helpful programming tutor.\"\n",
    "prefiller = \"\"\n",
    "\n",
    "set_transformer_early_exit_mode(model, 'sft_teacher')\n",
    "\n",
    "with torch.no_grad():\n",
    "    sft_teacher_response, (sft_teacher_generated_tokens, \n",
    "                          sft_teacher_final_layer_logprobs, \n",
    "                          gathered_early_exit_hidden_states) = generate_text(\n",
    "        model=model,\n",
    "        prompt=prompt,\n",
    "        system_prompt=system_prompt,\n",
    "        prefiller=prefiller,\n",
    "        tokenizer=tokenizer,\n",
    "        generation_config=config['generation'],\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    early_output_log_probs = model.early_exit_hidden_state_readout(gathered_early_exit_hidden_states)\n",
    "    \n",
    "    early_exit_probs = model.early_exit_target_probs(\n",
    "        early_output_log_probs=early_output_log_probs,\n",
    "        teacher_final_layer_log_probs=sft_teacher_final_layer_logprobs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86af1573-318b-4985-95df-aa2d5130a3bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<｜begin▁of▁sentence｜><｜Assistant｜> You are a helpful programming tutor.\\n<｜User｜> Explain the concept of recursion in programming.\\n<｜Assistant｜> \\nOkay, so I need to explain recursion in programming. Hmm, recursion is a programming concept where a function calls itself. That means the function will keep doing the same task over and over until it reaches a base case. \\n\\nWait, let me think about an example. Like, when you have a function that adds numbers from 1 to n. So, for n=3, it would call itself with n=2, and so on, until it gets to n=0 or n=1, which is the base case. \\n\\nBut wait, what's the base case again? Oh right, it's the simplest scenario that doesn't require further recursion. For the sum function, when n is 0 or 1, the sum is just n. \\n\\nI should also mention that recursion can make code cleaner and easier to understand because it's intuitive. Like, it's similar to how some problems are solved in everyday life, like climbing a mountain step by step. \\n\\nBut I should be careful and not go into too much detail. Maybe I should start with a simple example and then move on to a more complex one, like the factorial function or the Fibonacci sequence. \\n\\nWait, what's recursion in terms of data structures? Oh, right, it's often used in algorithms and data structures. For example, the merge sort algorithm uses recursion to sort arrays by dividing them into halves and then merging the sorted halves. \\n\\nOh, and in programming, it's important to handle the base case to prevent infinite recursion. If the base case isn't reached, the function will keep looping forever. \\n\\nSo, in summary, recursion is when a function solves a problem by breaking it down into smaller, similar problems. It uses the same function to solve each smaller problem until a base case is reached. This makes the code concise and easier to understand. \\n\\nI think that covers the basics. Maybe I can also mention some use cases and why it's useful in certain programming scenarios.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sft_teacher_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4332e58c-40ec-4210-bdb4-4523551e827a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting exit layers to inf for sft_student\n",
      "Minimum in prescribed_exit_layer_idxs = inf\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    batch, gen_len, elayers = early_exit_probs.shape \n",
    "    full_len = sft_teacher_generated_tokens.shape[1]\n",
    "    repeated_sft_teacher_generated_tokens = sft_teacher_generated_tokens.expand(num_exit_samples * batch, full_len)   \n",
    "    set_transformer_early_exit_mode(model, 'sft_student')\n",
    "    \n",
    "    # Create prescribed exit layer idxs filled with torch.inf (always exit on last layer)\n",
    "    batch_samples, seq_len = repeated_sft_teacher_generated_tokens.shape\n",
    "    print(\"Setting exit layers to inf for sft_student\")\n",
    "    prescribed_exit_layer_idxs = torch.full((batch_samples, gen_len), torch.inf, \\\n",
    "                                            device=repeated_sft_teacher_generated_tokens.device)\n",
    "    print(f\"Minimum in prescribed_exit_layer_idxs = {torch.min(prescribed_exit_layer_idxs)}\")\n",
    "    sft_student_output_scores, collected_exit_logits = model(repeated_sft_teacher_generated_tokens,\\\n",
    "                                                             prescribed_exit_layer_idxs=prescribed_exit_layer_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cce8e989-53ef-4da3-9f64-1dee10178b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRUDE KL AND MAKE SURE PROBS ARE ALIGNED\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(27.5847, device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print('CRUDE KL AND MAKE SURE PROBS ARE ALIGNED')\n",
    "    eps = 1e-16\n",
    "    sft_teacher_probs = sft_teacher_final_layer_logprobs.softmax(-1)                        # [batch * samples, gen len, vocabulary]\n",
    "    sft_student_probs = sft_student_output_scores.logits[:,-gen_len:].softmax(-1)           # [batch * samples, gen len, vocabulary]\n",
    "    token_logits_kl_div = (sft_student_probs * ((sft_student_probs + eps) / (sft_teacher_probs + eps)).log()).sum(-1)   # [batch * samples, gen len]\n",
    "    \n",
    "    mean_logit_kl = token_logits_kl_div.mean()\n",
    "\n",
    "mean_logit_kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e4bbf043-2dcb-4814-8221-688d6a38ab92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style='display: flex; flex-wrap: wrap;'><div style='flex: 1; min-width: 300px; padding: 10px;'><h4>Student NTP for token 5</h4><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Token ID</th>\n",
       "      <th>Token String</th>\n",
       "      <th>Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20162</td>\n",
       "      <td>' initiative'</td>\n",
       "      <td>0.0511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90884</td>\n",
       "      <td>' peripherals'</td>\n",
       "      <td>0.0142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79432</td>\n",
       "      <td>' Simone'</td>\n",
       "      <td>0.0082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82399</td>\n",
       "      <td>' Tooth'</td>\n",
       "      <td>0.0061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>471</td>\n",
       "      <td>'art'</td>\n",
       "      <td>0.0052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div><div style='flex: 1; min-width: 300px; padding: 10px;'><h4>Student NTP for token 6</h4><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Token ID</th>\n",
       "      <th>Token String</th>\n",
       "      <th>Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20162</td>\n",
       "      <td>' initiative'</td>\n",
       "      <td>0.0512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90884</td>\n",
       "      <td>' peripherals'</td>\n",
       "      <td>0.0146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79432</td>\n",
       "      <td>' Simone'</td>\n",
       "      <td>0.0083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82399</td>\n",
       "      <td>' Tooth'</td>\n",
       "      <td>0.0062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>471</td>\n",
       "      <td>'art'</td>\n",
       "      <td>0.0053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div><div style='flex: 1; min-width: 300px; padding: 10px;'><h4>Student NTP for token 7</h4><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Token ID</th>\n",
       "      <th>Token String</th>\n",
       "      <th>Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20162</td>\n",
       "      <td>' initiative'</td>\n",
       "      <td>0.0512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90884</td>\n",
       "      <td>' peripherals'</td>\n",
       "      <td>0.0145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79432</td>\n",
       "      <td>' Simone'</td>\n",
       "      <td>0.0082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82399</td>\n",
       "      <td>' Tooth'</td>\n",
       "      <td>0.0062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>471</td>\n",
       "      <td>'art'</td>\n",
       "      <td>0.0053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div><div style='flex: 1; min-width: 300px; padding: 10px;'><h4>Student NTP for token 8</h4><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Token ID</th>\n",
       "      <th>Token String</th>\n",
       "      <th>Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20162</td>\n",
       "      <td>' initiative'</td>\n",
       "      <td>0.0511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90884</td>\n",
       "      <td>' peripherals'</td>\n",
       "      <td>0.0140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79432</td>\n",
       "      <td>' Simone'</td>\n",
       "      <td>0.0082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82399</td>\n",
       "      <td>' Tooth'</td>\n",
       "      <td>0.0064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>471</td>\n",
       "      <td>'art'</td>\n",
       "      <td>0.0052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div><div style='flex: 1; min-width: 300px; padding: 10px;'><h4>Student NTP for token 9</h4><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Token ID</th>\n",
       "      <th>Token String</th>\n",
       "      <th>Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20162</td>\n",
       "      <td>' initiative'</td>\n",
       "      <td>0.0512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90884</td>\n",
       "      <td>' peripherals'</td>\n",
       "      <td>0.0147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79432</td>\n",
       "      <td>' Simone'</td>\n",
       "      <td>0.0084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82399</td>\n",
       "      <td>' Tooth'</td>\n",
       "      <td>0.0062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>471</td>\n",
       "      <td>'art'</td>\n",
       "      <td>0.0054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div><div style='flex: 1; min-width: 300px; padding: 10px;'><h4>Student NTP for token 10</h4><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Token ID</th>\n",
       "      <th>Token String</th>\n",
       "      <th>Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20162</td>\n",
       "      <td>' initiative'</td>\n",
       "      <td>0.0512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90884</td>\n",
       "      <td>' peripherals'</td>\n",
       "      <td>0.0142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79432</td>\n",
       "      <td>' Simone'</td>\n",
       "      <td>0.0082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82399</td>\n",
       "      <td>' Tooth'</td>\n",
       "      <td>0.0065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>471</td>\n",
       "      <td>'art'</td>\n",
       "      <td>0.0052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, Markdown, HTML\n",
    "\n",
    "def topk_to_df(prob_dist, tokenizer=None, k=5, title=\"Top-K Predictions\"):\n",
    "    \"\"\"\n",
    "    Return top-k predictions and probabilities as a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    top_values, top_indices = torch.topk(prob_dist, k=k)\n",
    "    \n",
    "    rows = []\n",
    "    for i, (idx, prob) in enumerate(zip(top_indices, top_values)):\n",
    "        token_id = idx.item()\n",
    "        prob_val = prob.item()\n",
    "        token_str = tokenizer.decode([token_id]) if tokenizer else str(token_id)\n",
    "        token_str = repr(token_str)  # Shows escape characters properly\n",
    "        \n",
    "        rows.append({\n",
    "            \"Token ID\": token_id,\n",
    "            \"Token String\": token_str,\n",
    "            \"Probability\": prob_val,\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(rows)\n",
    "    return title, df.round(4)\n",
    "\n",
    "# Example usage for your loop\n",
    "dfs = []\n",
    "for idx in range(5, 11):\n",
    "    title, df = topk_to_df(sft_student_probs[0, idx], tokenizer, k=5, title=f\"Student NTP for token {idx}\")\n",
    "    dfs.append((title, df))\n",
    "\n",
    "# Display in a grid\n",
    "html = \"<div style='display: flex; flex-wrap: wrap;'>\"\n",
    "for title, df in dfs:\n",
    "    html += \"<div style='flex: 1; min-width: 300px; padding: 10px;'>\"\n",
    "    html += f\"<h4>{title}</h4>\"\n",
    "    html += df.to_html(index=False)\n",
    "    html += \"</div>\"\n",
    "html += \"</div>\"\n",
    "\n",
    "display(HTML(html))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e707b44b-8e88-4f47-9e4b-bee64a51e393",
   "metadata": {},
   "source": [
    "### Very similar (and gibberish) next token predictions for all tokens. Something wrong!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
