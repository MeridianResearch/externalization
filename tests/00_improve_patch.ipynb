{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d849d143-f1bf-4ffc-a9a9-81c964be96c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a035a92-8fa6-41a8-ac2d-ccb4792b898f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.5.0) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-07-26 14:27:45.376495: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753540065.395408    4560 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753540065.401560    4560 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1753540065.419872    4560 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753540065.419887    4560 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753540065.419889    4560 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753540065.419891    4560 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from shared_utils.data import CSVPromptDataset\n",
    "from early_exit.util import get_model\n",
    "from shared_utils.load import get_tokenizer, configs_from_yaml\n",
    "from shared_utils.generate import generate_text\n",
    "\n",
    "from early_exit.patching import replace_attention_layers, set_transformer_early_exit_mode\n",
    "\n",
    "# import wandb\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0520810b-0c8d-46ff-b5fa-0f78a184993a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# LOAD IN EXPERIMENT ARGS\n",
    "# num_epoch = 1                     # args.num_epoch\n",
    "num_exit_samples = 1                  # args.num_exit_samples\n",
    "device = \"cuda\"                    # args.device\n",
    "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"                    # args.model_name\n",
    "model_config_path = \"./config_deepseek.yaml\"                     # args.model_config_path\n",
    "dataset_path = \"./results_and_data/early_exit_sft_dataset/test/data.csv\"                  # args.dataset_path\n",
    "prompt_config_path = \"./results_and_data/early_exit_sft_dataset/test/prompt_config.json\"                    # args.prompt_config_path\n",
    "batch_size = 1                    # args.batch_size -- might want to sort out batching, but increasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afbf3050-c207-4fa1-aec0-26afe13ae5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replacing layer model.layers.0\n",
      "replacing generate_layer_type_WITHOUT_early_exit_decision_head layer model.layers.1\n",
      "replacing generate_layer_type_WITHOUT_early_exit_decision_head layer model.layers.2\n",
      "replacing generate_layer_type_WITHOUT_early_exit_decision_head layer model.layers.3\n",
      "replacing generate_layer_type_WITHOUT_early_exit_decision_head layer model.layers.4\n",
      "replacing layer model.layers.5\n",
      "replacing generate_layer_type_WITHOUT_early_exit_decision_head layer model.layers.6\n",
      "replacing generate_layer_type_WITHOUT_early_exit_decision_head layer model.layers.7\n",
      "replacing generate_layer_type_WITHOUT_early_exit_decision_head layer model.layers.8\n",
      "replacing generate_layer_type_WITHOUT_early_exit_decision_head layer model.layers.9\n",
      "replacing layer model.layers.10\n",
      "replacing generate_layer_type_WITHOUT_early_exit_decision_head layer model.layers.11\n",
      "replacing generate_layer_type_WITHOUT_early_exit_decision_head layer model.layers.12\n",
      "replacing generate_layer_type_WITHOUT_early_exit_decision_head layer model.layers.13\n",
      "replacing generate_layer_type_WITHOUT_early_exit_decision_head layer model.layers.14\n",
      "replacing layer model.layers.15\n",
      "replacing generate_layer_type_WITHOUT_early_exit_decision_head layer model.layers.16\n",
      "replacing generate_layer_type_WITHOUT_early_exit_decision_head layer model.layers.17\n",
      "replacing generate_layer_type_WITHOUT_early_exit_decision_head layer model.layers.18\n",
      "replacing generate_layer_type_WITHOUT_early_exit_decision_head layer model.layers.19\n",
      "replacing layer model.layers.20\n",
      "replacing generate_layer_type_WITHOUT_early_exit_decision_head layer model.layers.21\n",
      "replacing generate_layer_type_WITHOUT_early_exit_decision_head layer model.layers.22\n",
      "replacing generate_layer_type_WITHOUT_early_exit_decision_head layer model.layers.23\n",
      "replacing generate_layer_type_WITHOUT_early_exit_decision_head layer model.layers.24\n",
      "replacing layer model.layers.25\n",
      "replacing generate_layer_type_WITHOUT_early_exit_decision_head layer model.layers.26\n",
      "replacing generate_layer_type_WITHOUT_early_exit_decision_head layer model.layers.27\n",
      "address this hack!\n",
      "trainable params: 2,179,072 || all params: 1,779,276,294 || trainable%: 0.1225\n"
     ]
    }
   ],
   "source": [
    "# LOAD IN THE MODEL AND TOKENIZER\n",
    "tokenizer = get_tokenizer(model_name)\n",
    "config = configs_from_yaml(model_config_path, tokenizer.eos_token_id)\n",
    "model = get_model(model_name, config['model'], device)\n",
    "\n",
    "\n",
    "# LOAD IN DATASET\n",
    "dataset = CSVPromptDataset(dataset_path, prompt_config_path)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, collate_fn=dataset.collate_fn, shuffle=True)\n",
    "\n",
    "\n",
    "# ENABLE EARLY EXITING\n",
    "model = replace_attention_layers(model, config['lora'], device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1314f83-2fff-486d-a7cc-e6cd8f475f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transform_conversations currently only for Deepseek models!\n",
      "full_tokenize currently only for Deepseek models!\n",
      "prompt tokens shape: torch.Size([1, 20])\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Explain the concept of recursion in programming.\"\n",
    "prompt = \"Tell me a Zen joke about farmer\"\n",
    "system_prompt = \"You are a helpful programming tutor.\"\n",
    "prefiller = \"\"\n",
    "\n",
    "set_transformer_early_exit_mode(model, 'sft_teacher')\n",
    "\n",
    "with torch.no_grad():\n",
    "    sft_teacher_response, (sft_teacher_generated_tokens, \n",
    "                          sft_teacher_final_layer_logprobs, \n",
    "                          gathered_early_exit_hidden_states) = generate_text(\n",
    "        model=model,\n",
    "        prompt=prompt,\n",
    "        system_prompt=system_prompt,\n",
    "        prefiller=prefiller,\n",
    "        tokenizer=tokenizer,\n",
    "        generation_config=config['generation'],\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    early_output_log_probs = model.early_exit_hidden_state_readout(gathered_early_exit_hidden_states)\n",
    "    \n",
    "    early_exit_probs = model.early_exit_target_probs(\n",
    "       early_output_log_probs=early_output_log_probs,\n",
    "       teacher_final_layer_log_probs=sft_teacher_final_layer_logprobs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8ebd870-7235-4a20-adfe-48b59262864f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<｜begin▁of▁sentence｜><｜Assistant｜> You are a helpful programming tutor.\\n<｜User｜> Tell me a Zen joke about farmer\\n<｜Assistant｜> \\nOkay, so I need to come up with a Zen joke about a farmer. Hmm, I\\'m not super familiar with Zen philosophy, but I know it\\'s about inner peace and mindfulness. So, the joke should probably have a twist or a twisty twist. Let me think about what a farmer does. They tend to work hard, maybe take risks, and deal with the world around them. \\n\\nMaybe I can play on the idea of the farmer being a hard worker but also a kind person. In Zen, there\\'s the concept of the \"soul in the earth,\" so maybe the farmer is the one who\\'s in the earth, working hard, but also the one who\\'s kind to the earth. \\n\\nLet me try to structure it. Start with something about the farmer, maybe a simple action like plowing the field. Then introduce the twist, perhaps something about the earth or the universe. Maybe the farmer is so focused on his work that he forgets the bigger picture. \\n\\nWait, that could work. So, the farmer plows the field, and then the twist is that the farmer forgets the universe is watching. That\\'s a common Zen twist, but maybe I can make it more specific. \\n\\nAlternatively, maybe the farmer is so focused on his work that he forgets the need for rest or the importance of the environment. That could be a good twist. \\n\\nLet me try to put it together. \\n\\n\"Once upon a time, in a lush green field, there lived a farmer named John. John was known for his hard work, always plowing the field with his oxen. One day, he was working his way through the field when he noticed something strange. The field was quiet, but then he saw the sun rising over the mountains. He stopped plowing and looked around, wondering what was wrong. \\n\\nSuddenly, he remembered that the farmer was the one who was in the earth, working hard, but also the one who was'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sft_teacher_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1495739b-6570-433e-987a-0ad89b872fc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5530d4-b3d8-4b44-afa5-5bfb75447b7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
